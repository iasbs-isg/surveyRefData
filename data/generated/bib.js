define({ entries : {
    "10.1117/12.2577088": {
        "abstract": "Deep learning plays a critical role in medical image segmentation. Nevertheless, manually designing a neural network for a specific segmentation problem is a very difficult and time-consuming task due to the massive hyperparameter search space, long training time and large volumetric data. Therefore, most designed networks are highly complex, task specific and over-parametrized. Recently, multiobjective neural architecture search (NAS) methods have been proposed to automate the design of accurate and efficient segmentation architectures. However, they only search for either the macro- or micro-structure of the architecture, do not use the information produced during the optimization process to increase the efficiency of the search, and do not consider the volumetric nature of medical images. In this work, we propose EMONAS, an Efficient MultiObjective Neural Architecture Search framework for 3D medical image segmentation. EMONAS is composed of a search space that considers both the macro- and micro-structure of the architecture, and a surrogate-assisted multiobjective evolutionary based algorithm that efficiently searches for the best hyperparameters using a Random Forest surrogate and guiding selection probabilities. EMONAS is evaluated on the task of cardiac segmentation from the ACDC MICCAI challenge. The architecture found is ranked within the top 10 submissions in all evaluation metrics, performing better or comparable to other approaches while reducing the search time by more than 50 and having considerably fewer number of parameters.",
        "author": "Maria Baldeon G Calisto and Susana K Lai-Yuen",
        "booktitle": "Medical Imaging 2021: Image Processing",
        "date": "2021-01-01",
        "doi": "10.1117/12.2577088",
        "editor": "Ivana I\u0161gum and Bennett A Landman",
        "keywords": "Main topic:AutoML, AI, application :healthcare",
        "organization": "International Society for Optics and Photonics",
        "pages": "22 -- 34",
        "publisher": "SPIE",
        "pubstate": "published",
        "title": "EMONAS: efficient multiobjective neural architecture search framework for 3D medical image segmentation",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://doi.org/10.1117/12.2577088",
        "volume": "11596",
        "year": "2021"
    },
    "10.3389/fnbot.2020.00036": {
        "abstract": "Biological neural network models whereby brains make minds help to understand autonomous adaptive intelligence. This article summarizes why the dynamics and emergent properties of such models for perception, cognition, emotion, and action are explainable, and thus amenable to being confidently implemented in large-scale applications. Key to their explainability is how these models combine fast activations, or short-term memory (STM) traces, and learned weights, or long-term memory (LTM) traces. Visual and auditory perceptual models have explainable conscious STM representations of visual surfaces and auditory streams in surface-shroud resonances and stream-shroud resonances, respectively. Deep Learning is often used to classify data. However, Deep Learning can experience catastrophic forgetting: At any stage of learning, an unpredictable part of its memory can collapse. Even if it makes some accurate classifications, they are not explainable and thus cannot be used with confidence. Deep Learning shares these problems with the back propagation algorithm, whose computational problems due to non-local weight transport during mismatch learning were described in the 1980s. Deep Learning became popular after very fast computers and huge online databases became available that enabled new applications despite these problems. Adaptive Resonance Theory, or ART, algorithms overcome the computational problems of back propagation and Deep Learning. ART is a self-organizing production system that incrementally learns, using arbitrary combinations of unsupervised and supervised learning and only locally computable quantities, to rapidly classify large non-stationary databases without experiencing catastrophic forgetting. ART classifications and predictions are explainable using the attended critical feature patterns in STM on which they build. The LTM adaptive weights of the fuzzy ARTMAP algorithm induce fuzzy IF-THEN rules that explain what feature combinations predict successful outcomes. ART has been successfully used in multiple large-scale real world applications, including remote sensing, medical database prediction, and social media data clustering. Also explainable are the MOTIVATOR model of reinforcement learning and cognitive-emotional interactions, and the VITE, DIRECT, DIVA, and SOVEREIGN models for reaching, speech production, spatial navigation, and autonomous adaptive intelligence. These biological models exemplify complementary computing, and use local laws for match learning and mismatch learning that avoid the problems of Deep Learning.",
        "author": "Grossberg, Stephen",
        "doi": "10.3389/fnbot.2020.00036",
        "issn": "1662-5218",
        "journal": "Frontiers in Neurorobotics",
        "keywords": "Main topic:XAI, AI",
        "pages": "36",
        "title": "A Path Toward Explainable AI and Autonomous Adaptive Intelligence: Deep Learning, Adaptive Resonance, and Models of Perception, Emotion, and Action",
        "type": "ARTICLE",
        "url": "https://www.frontiersin.org/article/10.3389/fnbot.2020.00036",
        "volume": "14",
        "year": "2020"
    },
    "10.5555/93126.94034": {
        "address": "San Francisco, CA, USA",
        "author": "Miller, Geoffrey F. and Todd, Peter M. and Hegde, Shailesh U.",
        "booktitle": "Proceedings of the Third International Conference on Genetic Algorithms",
        "isbn": "1558600063",
        "keywords": "Main topic:AutoML, AI",
        "location": "George Mason University, USA",
        "numpages": "6",
        "pages": "379\u2013384",
        "publisher": "Morgan Kaufmann Publishers Inc.",
        "title": "Designing Neural Networks Using Genetic Algorithms",
        "type": "InProceedings",
        "year": "1989"
    },
    "265960": {
        "author": "P. J. {Angeline} and G. M. {Saunders} and J. B. {Pollack}",
        "doi": "10.1109/72.265960",
        "journal": "IEEE Transactions on Neural Networks",
        "keywords": "Main topic:AutoML, AI",
        "number": "1",
        "pages": "54-65",
        "title": "An evolutionary algorithm that constructs recurrent neural networks",
        "type": "Article",
        "volume": "5",
        "year": "1994"
    },
    "8560892": {
        "abstract": "We propose a cause-effect reasoning mechanism with which an autonomous system can justify planned actions to a human end user. The mechanism is based on a structure we call a \"causal plan graph,\" which encodes the causal relationships between the actions, intentions, and goals of the autonomous system. Causal chains within this graph can potentially serve as intuitive, human-friendly justifications for the autonomous system's planned actions. A prototype of this mechanism is tested in simulation on a set of planning problems from an autonomous maintenance scenario. We demonstrate empirically that shortest path algorithms can effectively reduce a very large number of possible causal chains to a small, intelligible subset that might reasonably be inspected and ranked by a human. Consequently this work can serve as the basis for an experimental platform for future end user studies with human participants.",
        "author": "Katz, Garrett E. and Dullnig, Dale and Davis, Gregory P. and Gentili, Rodolphe J. and Reggia, James A.",
        "booktitle": "2017 International Conference on Computational Science and Computational Intelligence (CSCI)",
        "doi": "10.1109/CSCI.2017.133",
        "issn": "",
        "keywords": "Main topic:XAI, AI",
        "month": "Dec",
        "number": "",
        "pages": "772-778",
        "title": "Autonomous Causally-Driven Explanation of Actions",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2017"
    },
    "8790093": {
        "author": "W. {Irwin-Harris} and Y. {Sun} and B. {Xue} and M. {Zhang}",
        "booktitle": "2019 IEEE Congress on Evolutionary Computation (CEC)",
        "doi": "10.1109/CEC.2019.8790093",
        "keywords": "Main topic:AutoML, AI",
        "pages": "546-553",
        "title": "A Graph-Based Encoding for Evolutionary Convolutional Neural Network Architecture Design",
        "type": "InProceedings",
        "year": "2019"
    },
    "9156411": {
        "abstract": "We present APQ, a novel design methodology for efficient deep learning deployment. Unlike previous methods that separately optimize the neural network architecture, pruning policy, and quantization policy, we design to optimize them in a joint manner. To deal with the larger design space it brings, we devise to train a quantization-aware accuracy predictor that is fed to the evolutionary search to select the best fit. Since directly training such a predictor requires time-consuming quantization data collection, we propose to use predictor-transfer technique to get the quantization-aware predictor: we first generate a large dataset of \u3008NN architecture, ImageNet accuracy\u3009 pairs by sampling a pretrained unified once-for-all network and doing direct evaluation; then we use these data to train an accuracy predictor without quantization, followed by transferring its weights to train the quantization-aware predictor, which largely reduces the quantization data collection time. Extensive experiments on ImageNet show the benefits of this joint design methodology: the model searched by our method maintains the same level accuracy as ResNet34 8-bit model while saving 8\u00d7 BitOps; we achieve 2\u00d7/1.3\u00d7 latency/energy saving compared to MobileNetV2+HAQ [30, 36] while obtaining the same level accuracy; the marginal search cost ofjoint optimization for a new deployment scenario outperforms separate optimizations using ProxylessNAS+AMC+HAQ [5, 12, 36] by 2.3 accuracy while reducing orders of magnitude GPU hours and CO 2 emission with respect to the training cost.",
        "author": "Wang, Tianzhe and Wang, Kuan and Cai, Han and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Lin, Yujun and Han, Song",
        "booktitle": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "doi": "10.1109/CVPR42600.2020.00215",
        "keywords": "Main topic:AutoML, AI",
        "pages": "2075-2084",
        "title": "APQ: Joint Search for Network Architecture, Pruning and Quantization Policy",
        "type": "InProceedings",
        "year": "2020"
    },
    "9321372": {
        "abstract": "A number of algorithms in the field of artificial intelligence offer poorly interpretable decisions. To disclose the reasoning behind such algorithms, their output can be explained by means of so-called evidence-based (or factual) explanations. Alternatively, contrastive and counterfactual explanations justify why the output of the algorithms is not any different and how it could be changed, respectively. It is of crucial importance to bridge the gap between theoretical approaches to contrastive and counterfactual explanation and the corresponding computational frameworks. In this work we conduct a systematic literature review which provides readers with a thorough and reproducible analysis of the interdisciplinary research field under study. We first examine theoretical foundations of contrastive and counterfactual accounts of explanation. Then, we report the state-of-the-art computational frameworks for contrastive and counterfactual explanation generation. In addition, we analyze how grounded such frameworks are on the insights from the inspected theoretical approaches. As a result, we highlight a variety of properties of the approaches under study and reveal a number of shortcomings thereof. Moreover, we define a taxonomy regarding both theoretical and practical approaches to contrastive and counterfactual explanation.",
        "author": "Stepin, Ilia and Alonso, Jose M. and Catala, Alejandro and Pereira-Fari\u00f1a, Mart\u00edn",
        "doi": "10.1109/ACCESS.2021.3051315",
        "issn": "2169-3536",
        "journal": "IEEE Access",
        "keywords": "Main topic:XAI Main topic:XAI, AI",
        "month": "",
        "number": "",
        "pages": "11974-12001",
        "title": "A Survey of Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial Intelligence",
        "type": "ARTICLE",
        "volume": "9",
        "year": "2021"
    },
    "Anand_2020": {
        "abstract": "We introduce Auto-Surprise, an Automated Recommender System library. Auto-Surprise is an extension of the Surprise recommender system library and eases the algorithm selection and configuration process. Compared to out-of-the-box Surprise library, Auto-Surprise performs better when evaluated with MovieLens, Book Crossing and Jester Datasets. It may also result in the selection of an algorithm with significantly lower runtime. Compared to Surprise's grid search, Auto-Surprise performs equally well or slightly better in terms of RMSE, and is notably faster in finding the optimum hyperparameters.",
        "author": "Anand, Rohan and Beel, Joeran",
        "doi": "10.1145/3383313.3411467",
        "isbn": "9781450375832",
        "journal": "Fourteenth ACM Conference on Recommender Systems",
        "keywords": "Main topic:AutoML, AI",
        "month": "Sep",
        "publisher": "ACM",
        "title": "Auto-Surprise: An Automated Recommender-System (AutoRecSys) Library with Tree of Parzens Estimator (TPE) Optimization",
        "type": "Article",
        "url": "http://dx.doi.org/10.1145/3383313.3411467",
        "year": "2020"
    },
    "Arya2019": {
        "abstract": "As artificial intelligence and machine learning algorithms make further inroads into society, calls are increasing from multiple stakeholders for these algorithms to explain their outputs. At the same time, these stakeholders, whether they be affected citizens, government regulators, domain experts, or system developers, present different requirements for explanations. Toward addressing these needs, we introduce AI Explainability 360 (this http URL), an open-source software toolkit featuring eight diverse and state-of-the-art explainability methods and two evaluation metrics. Equally important, we provide a taxonomy to help entities requiring explanations to navigate the space of explanation methods, not only those in the toolkit but also in the broader literature on explainability. For data scientists and other users of the toolkit, we have implemented an extensible software architecture that organizes methods according to their place in the AI modeling pipeline. We also discuss enhancements to bring research innovations closer to consumers of explanations, ranging from simplified, more accessible versions of algorithms, to tutorials and an interactive web demo to introduce AI explainability to different audiences and application domains. Together, our toolkit and taxonomy can help identify gaps where more explainability methods are needed and provide a platform to incorporate them as they are developed.",
        "author": "Vijay Arya and Rachel K. E. Bellamy and Pin-Yu Chen and Amit Dhurandhar and Michael Hind and Samuel C. Hoffman and Stephanie Houde and Q. Vera Liao and Ronny Luss and Aleksandra Mojsilovi\u0107 and Sami Mourad and Pablo Pedemonte and Ramya Raghavendra and John Richards and Prasanna Sattigeri and Karthikeyan Shanmugam and Moninder Singh and Kush R. Varshney and Dennis Wei and Yunfeng Zhang",
        "date": "2019-09-06",
        "eprint": "http://arxiv.org/abs/1909.03012v2",
        "eprintclass": "cs.AI",
        "eprinttype": "arXiv",
        "file": ":http\\://arxiv.org/pdf/1909.03012v2:PDF",
        "keywords": "Main topic:XAI",
        "title": "one explanation does not fit All: A Toolkit and Taxonomy of AI Explainability Techniques",
        "type": "Article"
    },
    "Calisto2020_jpy": {
        "abstract": "Fully Convolutional Networks (FCNs) have emerged as powerful segmentation models but are usually designed manually, which requires extensive time and can result in large and complex architectures. There is a growing interest to automatically design efficient architectures that can accurately segment 3D medical images. However, most approaches either do not fully exploit volumetric information or do not optimize the model\u2019s size. To address these problems, we propose a self-adaptive 2D\u20133D ensemble of FCNs called AdaEn-Net for 3D medical image segmentation that incorporates volumetric data and adapts to a particular dataset by optimizing both the model\u2019s performance and size. The AdaEn-Net consists of a 2D FCN that extracts intra-slice information and a 3D FCN that exploits inter-slice information. The architecture and hyperparameters of the 2D and 3D architectures are found through a multiobjective evolutionary based algorithm that maximizes the expected segmentation accuracy and minimizes the number of parameters in the network. The main contribution of this work is a model that fully exploits volumetric information and automatically searches for a high-performing and efficient architecture. The AdaEn-Net was evaluated for prostate segmentation on the PROMISE12 Grand Challenge and for cardiac segmentation on the MICCAI ACDC challenge. In the first challenge, the AdaEn-Net ranks 9 out of 297 submissions and surpasses the performance of an automatically-generated segmentation network while producing an architecture with 13 fewer parameters. In the second challenge, the proposed model is ranked within the top 8 submissions and outperforms an architecture designed with reinforcement learning while having 1.25 fewer parameters.",
        "author": "Maria Baldeon G Calisto and Susana K Lai-Yuen",
        "date": "2020-01-01",
        "doi": "10.1016/J.NEUNET.2020.03.007",
        "key": "journals/nn/CalistoL20",
        "keywords": "Main topic:AutoML, AI, application :healthcare",
        "pages": "76-94",
        "pubstate": "published",
        "title": "AdaEn-Net - An ensemble of adaptive 2D-3D Fully Convolutional Networks for medical image segmentation",
        "tppubtype": "article",
        "type": "Article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0893608020300848",
        "volume": "126",
        "year": "2020"
    },
    "Calisto2020_ndy": {
        "abstract": "Adapting an existing convolutional neural network architecture to a specific dataset for medical image segmentation remains a challenging task that requires extensive expertise and time to fine-tune the hyperparameters. Hyperparameter optimization approaches that automate the search have been proposed but have mainly focused on optimizing the segmentation performance. However, optimizing the network size is also important to prevent unnecessary and costly computational operations. In this paper, we present a multiobjective adaptive convolutional neural network (AdaResU-Net) for medical image segmentation that is able to automatically adapt to new datasets while minimizing the size of the network. The proposed AdaResU-Net is comprised of a fixed architecture that combines the structure of the state-of-the-art U-Net with a residual learning framework to improve information propagation and promote an efficient training. Then, a multiobjective evolutionary algorithm (MEA) that optimizes both segmentation accuracy and model size is proposed to evolve the AdaResU-Net networks with different hyperparameters. The presented model is tested on two publically available medical image datasets and compared with the U-Net. Results show that the AdaResU-Net achieves better segmentation performance with less than 30 the number of trainable parameters. Additionally, the MEA algorithm generated configurations that are smaller and perform better or equally well than configurations generated with a Bayesian hyperparameter optimization approach.",
        "author": "Maria Baldeon G Calisto and Susana K Lai-Yuen",
        "date": "2020-01-01",
        "doi": "10.1016/J.NEUCOM.2019.01.110",
        "key": "journals/ijon/CalistoL20",
        "keywords": "Main topic:AutoML, AI",
        "pages": "325-340",
        "pubstate": "published",
        "title": "AdaResU-Net - Multiobjective adaptive convolutional neural network for medical image segmentation",
        "tppubtype": "article",
        "type": "Article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0925231219304679",
        "volume": "392",
        "year": "2020"
    },
    "Calisto2020_qjn": {
        "abstract": "Segmentation is a critical step in medical image analysis. Fully Convolutional Networks (FCNs) have emerged as powerful segmentation models achieving state-of-the-art results in various medical image datasets. Network architectures are usually designed manually for a specific segmentation task so applying them to other medical datasets requires extensive experience and time. Moreover, the segmentation requires handling large volumetric data that results in big and complex architectures. Recently, methods that automatically design neural networks for medical image segmentation have been presented; however, most approaches either do not fully consider volumetric information or do not optimize the size of the network. In this paper, we propose a novel self-adaptive 2D-3D ensemble of FCNs for medical image segmentation that incorporates volumetric information and optimizes both the model's performance and size. The model is composed of an ensemble of a 2D FCN that extracts intra-slice information, and a 3D FCN that exploits inter-slice information. The architectures of the 2D and 3D FCNs are automatically adapted to a medical image dataset using a multiobjective evolutionary based algorithm that minimizes both the segmentation error and number of parameters in the network. The proposed 2D-3D FCN ensemble was tested on the task of prostate segmentation on the image dataset from the PROMISE12 Grand Challenge. The resulting network is ranked in the top 10 submissions, surpassing the performance of other automatically-designed architectures while being considerably smaller in size.",
        "author": "Maria Baldeon G Calisto and Susana K Lai-Yuen",
        "date": "2020-01-01",
        "doi": "10.1117/12.2543810",
        "key": "conf/miip/CalistoL20",
        "keywords": "Main topic:AutoML, AI, application :healthcare, adaptability :Self-configuration",
        "pages": "113131W",
        "pubstate": "published",
        "title": "Self-adaptive 2D-3D ensemble of fully convolutional networks for medical image segmentation",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://arxiv.org/abs/1907.11587",
        "year": "2020"
    },
    "DBLP:conf/iclr/LiuSY19": {
        "author": "Hanxiao Liu and Karen Simonyan and Yiming Yang",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/conf/iclr/LiuSY19.bib",
        "booktitle": "7th International Conference on Learning Representations, {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019",
        "keywords": "Main topic:AutoML, AI",
        "publisher": "OpenReview.net",
        "timestamp": "Thu, 25 Jul 2019 14:25:55 +0200",
        "title": "{DARTS:} Differentiable Architecture Search",
        "type": "InProceedings",
        "url": "https://openreview.net/forum?id",
        "year": "2019"
    },
    "DBLP:conf/iclr/ZophL17": {
        "author": "Barret Zoph and Quoc V. Le",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/conf/iclr/ZophL17.bib",
        "booktitle": "5th International Conference on Learning Representations, {ICLR} 2017",
        "keywords": "Main topic:AutoML, AI",
        "timestamp": "Thu, 04 Apr 2019 13:20:08 +0200",
        "title": "Neural Architecture Search with Reinforcement Learning",
        "type": "InProceedings",
        "url": "https://openreview.net/forum?id",
        "year": "2017"
    },
    "DBLP:journals/corr/BakerGNR16": {
        "archiveprefix": "arXiv",
        "author": "Bowen Baker and Otkrist Gupta and Nikhil Naik and Ramesh Raskar",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/journals/corr/BakerGNR16.bib",
        "eprint": "1611.02167",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "timestamp": "Mon, 13 Aug 2018 16:47:42 +0200",
        "title": "Designing Neural Network Architectures using Reinforcement Learning",
        "type": "Article",
        "url": "http://arxiv.org/abs/1611.02167",
        "volume": "abs/1611.02167",
        "year": "2016"
    },
    "DBLP:journals/corr/abs-1711-00436": {
        "archiveprefix": "arXiv",
        "author": "Hanxiao Liu and Karen Simonyan and Oriol Vinyals and Chrisantha Fernando and Koray Kavukcuoglu",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/journals/corr/abs-1711-00436.bib",
        "eprint": "1711.00436",
        "journal": "The International Conference on Learning Representations (ICLR) 2018",
        "keywords": "Main topic:AutoML, AI",
        "timestamp": "Mon, 13 Aug 2018 16:47:28 +0200",
        "title": "Hierarchical Representations for Efficient Architecture Search",
        "type": "Article",
        "url": "http://arxiv.org/abs/1711.00436",
        "volume": "abs/1711.00436",
        "year": "2017"
    },
    "DBLP:journals/corr/abs-1802-03268": {
        "archiveprefix": "arXiv",
        "author": "Hieu Pham and Melody Y. Guan and Barret Zoph and Quoc V. Le and Jeff Dean",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/journals/corr/abs-1802-03268.bib",
        "eprint": "1802.03268",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "timestamp": "Mon, 13 Aug 2018 16:47:58 +0200",
        "title": "Efficient Neural Architecture Search via Parameter Sharing",
        "type": "Article",
        "url": "http://arxiv.org/abs/1802.03268",
        "volume": "abs/1802.03268",
        "year": "2018"
    },
    "DBLP:journals/corr/abs-1802-07191": {
        "archiveprefix": "arXiv",
        "author": "Kirthevasan Kandasamy and Willie Neiswanger and Jeff Schneider and Barnab{\\'{a}}s P{\\'{o}}czos and Eric P. Xing",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/journals/corr/abs-1802-07191.bib",
        "eprint": "1802.07191",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "timestamp": "Tue, 17 Nov 2020 16:08:03 +0100",
        "title": "Neural Architecture Search with Bayesian Optimisation and Optimal Transport",
        "type": "Article",
        "url": "http://arxiv.org/abs/1802.07191",
        "volume": "abs/1802.07191",
        "year": "2018"
    },
    "DBLP:journals/corr/abs-1806-10332": {
        "archiveprefix": "arXiv",
        "author": "Chi{-}Hung Hsu and Shu{-}Huan Chang and Da{-}Cheng Juan and Jia{-}Yu Pan and Yu{-}Ting Chen and Wei Wei and Shih{-}Chieh Chang",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/journals/corr/abs-1806-10332.bib",
        "eprint": "1806.10332",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "timestamp": "Wed, 08 Jan 2020 11:59:23 +0100",
        "title": "{MONAS:} Multi-Objective Neural Architecture Search using Reinforcement Learning",
        "type": "Article",
        "url": "http://arxiv.org/abs/1806.10332",
        "volume": "abs/1806.10332",
        "year": "2018"
    },
    "DBLP:journals/corr/abs-1903-10979": {
        "archiveprefix": "arXiv",
        "author": "Yukang Chen and Tong Yang and Xiangyu Zhang and Gaofeng Meng and Chunhong Pan and Jian Sun",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/journals/corr/abs-1903-10979.bib",
        "eprint": "1903.10979",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "timestamp": "Fri, 24 May 2019 12:50:22 +0200",
        "title": "DetNAS: Neural Architecture Search on Object Detection",
        "type": "Article",
        "url": "http://arxiv.org/abs/1903.10979",
        "volume": "abs/1903.10979",
        "year": "2019"
    },
    "DBLP:journals/corr/abs-1905-04919": {
        "archiveprefix": "arXiv",
        "author": "Hongpeng Zhou and Minghao Yang and Jun Wang and Wei Pan",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/journals/corr/abs-1905-04919.bib",
        "eprint": "1905.04919",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "timestamp": "Wed, 21 Oct 2020 08:40:04 +0200",
        "title": "BayesNAS: {A} Bayesian Approach for Neural Architecture Search",
        "type": "Article",
        "url": "http://arxiv.org/abs/1905.04919",
        "volume": "abs/1905.04919",
        "year": "2019"
    },
    "DBLP:journals/corr/abs-2102-04040": {
        "abstract": "Text to speech (TTS) has been broadly used to synthesize natural and intelligible speech in different scenarios. Deploying TTS in various end devices such as mobile phones or embedded devices requires extremely small memory usage and inference latency. While non-autoregressive TTS models such as FastSpeech have achieved significantly faster inference speed than autoregressive models, their model size and inference latency are still large for the deployment in resource constrained devices. In this paper, we propose LightSpeech, which leverages neural architecture search~(NAS) to automatically design more lightweight and efficient models based on FastSpeech. We first profile the components of current FastSpeech model and carefully design a novel search space containing various lightweight and potentially effective architectures. Then NAS is utilized to automatically discover well performing architectures within the search space. Experiments show that the model discovered by our method achieves 15x model compression ratio and 6.5x inference speedup on CPU with on par voice quality. Audio demos are provided at this https URL.",
        "author": "Renqian Luo and Xu Tan and Rui Wang and Tao Qin and Jinzhu Li and Sheng Zhao and Enhong Chen and Tie -",
        "date": "2021-01-01",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "pubstate": "published",
        "title": "LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search",
        "tppubtype": "techreport",
        "type": "TechReport",
        "url": "https://arxiv.org/abs/2102.04040",
        "volume": "abs/2102.04040",
        "year": "2021"
    },
    "DBLP:journals/corr/abs-2103-15954": {
        "abstract": "Recently, neural architecture search (NAS) has been applied to automatically search high-performance networks for medical image segmentation. The NAS search space usually contains a network topology level (controlling connections among cells with different spatial scales) and a cell level (operations within each cell). Existing methods either require long searching time for large-scale 3D image datasets, or are limited to pre-defined topologies (such as U-shaped or single-path). In this work, we focus on three important aspects of NAS in 3D medical image segmentation: flexible multi-path network topology, high search efficiency, and budgeted GPU memory usage. A novel differentiable search framework is proposed to support fast gradient-based search within a highly flexible network topology search space. The discretization of the searched optimal continuous model in differentiable scheme may produce a sub-optimal final discrete model (discretization gap). Therefore, we propose a topology loss to alleviate this problem. In addition, the GPU memory usage for the searched 3D model is limited with budget constraints during search. Our Differentiable Network Topology Search scheme (DiNTS) is evaluated on the Medical Segmentation Decathlon (MSD) challenge, which contains ten challenging segmentation tasks. Our method achieves the state-of-the-art performance and the top ranking on the MSD challenge leaderboard.",
        "author": "Yufan He and Dong Yang and Holger Roth and Can Zhao and Daguang Xu",
        "date": "2021-01-01",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "pubstate": "published",
        "title": "DiNTS: Differentiable Neural Network Topology Search for 3D Medical Image Segmentation",
        "tppubtype": "techreport",
        "type": "TechReport",
        "url": "https://arxiv.org/abs/2103.15954",
        "volume": "abs/2103.15954",
        "year": "2021"
    },
    "DBLP:journals/corr/abs-2104-04141": {
        "abstract": "Recently, some Neural Architecture Search (NAS) techniques are proposed for the automatic design of Graph Convolutional Network (GCN) architectures. They bring great convenience to the use of GCN, but could hardly apply to the Federated Learning (FL) scenarios with distributed and private datasets, which limit their applications. Moreover, they need to train many candidate GCN models from scratch, which is inefficient for FL. To address these challenges, we propose FL-AGCNS, an efficient GCN NAS algorithm suitable for FL scenarios. FL-AGCNS designs a federated evolutionary optimization strategy to enable distributed agents to cooperatively design powerful GCN models while keeping personal information on local devices. Besides, it applies the GCN SuperNet and a weight sharing strategy to speed up the evaluation of GCN models. Experimental results show that FL-AGCNS can find better GCN models in short time under the FL framework, surpassing the state-of-the-arts NAS methods and GCN models.",
        "author": "Chunnan Wang and Bozhou Chen and Geng Li and Hongzhi Wang",
        "date": "2021-01-01",
        "journal": "CoRR",
        "keywords": "Main topic:AutoML, AI",
        "pubstate": "published",
        "title": "FL-AGCNS: Federated Learning Framework for Automatic Graph Convolutional Network Search",
        "tppubtype": "techreport",
        "type": "TechReport",
        "url": "https://arxiv.org/abs/2104.04141",
        "volume": "abs/2104.04141",
        "year": "2021"
    },
    "GIUDICI2021114104": {
        "abstract": "Explainability of artificial intelligence methods has become a crucial issue, especially in the most regulated fields, such as health and finance. In this paper, we provide a global explainable AI method which is based on Lorenz decompositions, thus extending previous contributions based on variance decompositions. This allows the resulting Shapley-Lorenz decomposition to be more generally applicable, and provides a unifying variable importance criterion that combines predictive accuracy with explainability, using a normalised and easy to interpret metric. The proposed decomposition is illustrated within the context of a real financial problem: the prediction of bitcoin prices.",
        "author": "Paolo Giudici and Emanuela Raffinetti",
        "doi": "https://doi.org/10.1016/j.eswa.2020.114104",
        "issn": "0957-4174",
        "journal": "Expert Systems with Applications",
        "keywords": "Shapley values, Lorenz Zonoids, Predictive accuracy Main topic:XAI",
        "pages": "114104",
        "title": "Shapley-Lorenz eXplainable Artificial Intelligence",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0957417420308575",
        "volume": "167",
        "year": "2021"
    },
    "Ghiasi_2019_CVPR": {
        "author": "Ghiasi, Golnaz and Lin, Tsung-Yi and Le, Quoc V.",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "keywords": "Main topic:AutoML, AI",
        "month": "June",
        "title": "NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection",
        "type": "InProceedings",
        "year": "2019"
    },
    "Gou2020_hxj": {
        "author": "Yuanbiao Gou and Boyun Li and Zitao Liu and Songfan Yang and Xi Peng",
        "date": "2020-01-01",
        "key": "conf/nips/GouLLY020",
        "keywords": "Main topic:AutoML, AI, application :industry",
        "pubstate": "published",
        "title": "CLEARER - Multi-Scale Neural Architecture Search for Image Restoration",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://papers.nips.cc/paper/2020/file/c6e81542b125c36346d9167691b8bd09-Paper.pdf",
        "year": "2020"
    },
    "Guo2020_bsk": {
        "abstract": "Deep neural networks have exhibited promising performance in image super-resolution (SR). Most SR models follow a hierarchical architecture that contains both the cell-level design of computational blocks and the network-level design of the positions of upsampling blocks. However, designing SR models heavily relies on human expertise and is very labor-intensive. More critically, these SR models often contain a huge number of parameters and may not meet the requirements of computation resources in real-world applications. To address the above issues, we propose a Hierarchical Neural Architecture Search (HNAS) method to automatically design promising architectures with different requirements of computation cost. To this end, we design a hierarchical SR search space and propose a hierarchical controller for architecture search. Such a hierarchical controller is able to simultaneously find promising cell-level blocks and network-level positions of upsampling layers. Moreover, to design compact architectures with promising performance, we build a joint reward by considering both the performance and computation cost to guide the search process. Extensive experiments on five benchmark datasets demonstrate the superiority of our method over existing methods.",
        "author": "Yong Guo and Yongsheng Luo and Zhenhao He and Jin Huang and Jian Chen",
        "date": "2020-01-01",
        "doi": "10.1109/LSP.2020.3003517",
        "key": "journals/spl/GuoLHHC20",
        "keywords": "Main topic:AutoML, AI, application :industry",
        "pages": "1255-1259",
        "pubstate": "published",
        "title": "Hierarchical Neural Architecture Search for Single Image Super-Resolution",
        "tppubtype": "article",
        "type": "Article",
        "url": "https://arxiv.org/abs/2003.04619",
        "volume": "27",
        "year": "2020"
    },
    "HongyangGu2021_bui": {
        "abstract": "In the field of person re-identification (ReID), multi-branch models are more effective in learning robust features than single-branch models. The current popular multi-branch models are based on ResNet or GoogleNet. These networks are designed initially to solve classification problems. There is an essential difference between ReID and classification problems, so it is particularly important to find a corresponding multi-branch backbone for ReID tasks. We propose to automatically search for a multi-branch convolutional neural network (CNN) for ReID tasks utilizing neural architecture search (NAS). First, we designed a multi-resolution, multi-branch macro search architecture that can extract more abundant scale information. Then in the searching process, the early stopping mechanism is proposed to improve the effectiveness and efficiency of the entire searching process. Finally, we experimentally prove on four mainstream datasets that the searched model can achieve state-of-the-art performance with only 5.7 million parameters.",
        "author": "Hongyang Gu and Guangyuan Fu and Jianmin Li and Jun Zhu",
        "date": "2021-01-01",
        "doi": "https://doi.org/10.1016/j.neucom.2020.12.105",
        "issn": "0925-2312",
        "journal": "Neurocomputing",
        "keywords": "Main topic:AutoML, AI, application :industry",
        "pages": "53-66",
        "pubstate": "published",
        "title": "Auto-ReID+: Searching for a multi-branch ConvNet for person re-identification",
        "tppubtype": "article",
        "type": "Article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0925231220320178",
        "volume": "435",
        "year": "2021"
    },
    "JMLR:v20:18-598": {
        "author": "Thomas Elsken and Jan Hendrik Metzen and Frank Hutter",
        "journal": "Journal of Machine Learning Research",
        "keywords": "Main topic:AutoML, AI",
        "number": "55",
        "pages": "1-21",
        "title": "Neural Architecture Search: A Survey",
        "type": "Article",
        "url": "http://jmlr.org/papers/v20/18-598.html",
        "volume": "20",
        "year": "2019"
    },
    "Lee2020_kcx": {
        "abstract": "Recent works in single-image perceptual super-resolution (SR) have demonstrated unprecedented performance in generating realistic textures by means of deep convolutional networks. However, these convolutional models are excessively large and expensive, hindering their effective deployment to end devices. In this work, we propose a neural architecture search (NAS) approach that integrates NAS and generative adversarial networks (GANs) with recent advances in perceptual SR and pushes the efficiency of small perceptual SR models to facilitate on-device execution. Specifically, we search over the architectures of both the generator and the discriminator sequentially, highlighting the unique challenges and key observations of searching for an SR-optimized discriminator and comparing them with existing discriminator architectures in the literature. Our tiny perceptual SR (TPSR) models outperform SRGAN and EnhanceNet on both full-reference perceptual metric (LPIPS) and distortion metric (PSNR) while being up to 26.4\\times more memory efficient and 33.6\\times more compute efficient respectively.",
        "author": "Royson Lee and Lukasz Dudziak and Mohamed S Abdelfattah and Stylianos I Venieris and Hyeji Kim and Hongkai Wen and Nicholas D Lane",
        "date": "2020-01-01",
        "doi": "10.1007/978-3-030-58574-7_6",
        "key": "conf/eccv/LeeDAVK0L20",
        "keywords": "Main topic:AutoML, AI",
        "pages": "85-102",
        "pubstate": "published",
        "title": "Journey Towards Tiny Perceptual Super-Resolution",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://arxiv.org/abs/2007.04356",
        "year": "2020"
    },
    "Li2020_xye": {
        "abstract": "Graphs play an important role in many applications. Recently, Graph Neural Networks (GNNs) have achieved promising results in graph analysis tasks. Some state-of-the-art GNN models have been proposed, e.g., Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), etc. Despite these successes, most of the GNNs only have shallow structure. This causes the low expressive power of the GNNs. To fully utilize the power of the deep neural network, some deep GNNs have been proposed recently. However, the design of deep GNNs requires significant architecture engineering. In this work, we propose a method to automate the deep GNNs design. In our proposed method, we add a new type of skip connection to the GNNs search space to encourage feature reuse and alleviate the vanishing gradient problem. We also allow our evolutionary algorithm to increase the layers of GNNs during the evolution to generate deeper networks. We evaluate our method in the graph node classification task. The experiments show that the GNNs generated by our method can obtain state-of-the-art results in Cora, Citeseer, Pubmed and PPI datasets.",
        "author": "Yaoman Li and Irwin King",
        "date": "2020-01-01",
        "doi": "10.1007/978-3-030-63833-7_16",
        "key": "conf/iconip/LiK20",
        "keywords": "Main topic:AutoML, AI",
        "pages": "189-201",
        "pubstate": "published",
        "title": "AutoGraph - Automated Graph Neural Network",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://link.springer.com/chapter/10.1007/978-3-030-63833-7_16",
        "year": "2020"
    },
    "NEURIPS2019_4efc9e02": {
        "abstract": "Reducing the model redundancy is an important task to deploy complex deep learning models to resource-limited or time-sensitive devices. Directly regularizing or modifying weight values makes pruning procedure less robust and sensitive to the choice of hyperparameters, and it also requires prior knowledge to tune different hyperparameters for different models. To build a better generalized and easy-to-use pruning method, we propose AutoPrune, which prunes the network through optimizing a set of trainable auxiliary parameters instead of original weights. The instability and noise during training on auxiliary parameters will not directly affect weight values, which makes pruning process more robust to noise and less sensitive to hyperparameters. Moreover, we design gradient update rules for auxiliary parameters to keep them consistent with pruning tasks. Our method can automatically eliminate network redundancy with recoverability, relieving the complicated prior knowledge required to design thresholding functions, and reducing the time for trial and error. We evaluate our method with LeNet and VGG-like on MNIST and CIFAR-10 datasets, and with AlexNet, ResNet and MobileNet on ImageNet to establish the scalability of our work. Results show that our model achieves state-of-the-art sparsity, e.g. 7, 23 FLOPs and 310x, 75x compression ratio for LeNet5 and VGG-like structure without accuracy drop, and 200M and 100M FLOPs for MobileNet V2 with accuracy 73.32 and 66.83 respectively.",
        "author": "XIAO, XIA and Wang, Zigeng and Rajasekaran, Sanguthevar",
        "booktitle": "Advances in Neural Information Processing Systems",
        "editor": "H. Wallach and H. Larochelle and A. Beygelzimer and F. d\\textquotesingle Alch\\'{e}-Buc and E. Fox and R. Garnett",
        "keywords": "Main topic:AutoML, AI",
        "publisher": "Curran Associates, Inc.",
        "title": "AutoPrune: Automatic Network Pruning by Regularizing Auxiliary Parameters",
        "type": "InProceedings",
        "url": "https://proceedings.neurips.cc/paper/2019/file/4efc9e02abdab6b6166251918570a307-Paper.pdf",
        "volume": "32",
        "year": "2019"
    },
    "NIPS1988_f2217062": {
        "author": "Tenorio, Manoel and Lee, Wei-Tsih",
        "booktitle": "Advances in Neural Information Processing Systems",
        "editor": "D. Touretzky",
        "keywords": "Main topic:AutoML, AI, adaptability :Self-configuration",
        "pages": "57--64",
        "publisher": "Morgan-Kaufmann",
        "title": "Self Organizing Neural Networks for the Identification Problem",
        "type": "InProceedings",
        "url": "https://proceedings.neurips.cc/paper/1988/file/f2217062e9a397a1dca429e7d70bc6ca-Paper.pdf",
        "volume": "1",
        "year": "1989"
    },
    "Nunes2020_etq": {
        "abstract": "Performing analytical tasks over graph data has become increasingly interesting due to the ubiquity and large availability of relational information. However, unlike images or sentences, there is no notion of sequence in networks. Nodes (and edges) follow no absolute order, and it is hard for traditional machine learning (ML) algorithms to recognize a pattern and generalize their predictions on this type of data. Graph Neural Networks (GNN) successfully tackled this problem. They became popular after the generalization of the convolution concept to the graph domain. However, they possess a large number of hyperparameters and their design and optimization is currently hand-made, based on heuristics or empirical intuition. Neural Architecture Search (NAS) methods appear as an interesting solution to this problem. In this direction, this paper compares two NAS methods for optimizing GNN: one based on reinforcement learning and a second based on evolutionary algorithms. Results consider 7 datasets over two search spaces and show that both methods obtain similar accuracies to a random search, raising the question of how many of the search space dimensions are actually relevant to the problem.",
        "author": "Matheus Nunes and Gisele L Pappa",
        "date": "2020-01-01",
        "doi": "10.1007/978-3-030-61377-8_21",
        "key": "conf/bracis/NunesP20",
        "keywords": "Main topic:AutoML, AI",
        "pages": "302-317",
        "pubstate": "published",
        "title": "Neural Architecture Search in Graph Neural Networks",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://arxiv.org/abs/2008.00077",
        "year": "2020"
    },
    "STREICH2020217": {
        "abstract": "\"Human population growth and accelerated climate change necessitate agricultural improvements using designer crop ideotypes (idealized plants that can grow in niche environments). Diverse and highly skilled research groups must integrate efforts to bridge the gaps needed to achieve international goals toward sustainable agriculture. Given the scale of global agricultural needs and the breadth of multiple types of omics data needed to optimize these efforts, explainable artificial intelligence (AI with a decipherable decision making process that provides a meaningful explanation to humans) and exascale computing (computers that can perform 1018 floating-point operations per second, or exaflops) are crucial. Accurate phenotyping and daily-resolution climatype associations are equally important for refining ideotype production to specific environments at various levels of granularity. We review advances toward tackling technological hurdles to solve multiple United Nations Sustainable Development Goals and discuss a vision to overcome gaps between research and policy.\",",
        "author": "\"Jared Streich and Jonathon Romero and Jo\u00e3o Gabriel Felipe Machado Gazolla and David Kainer and Ashley Cliff and Erica Teixeira Prates and James B Brown and Sacha Khoury and Gerald A Tuskan and Michael Garvin and Daniel Jacobson and Antoine L Harfouche\",",
        "doi": "\"https://doi.org/10.1016/j.copbio.2020.01.010\",",
        "issn": "\"0958-1669\",",
        "journal": "\"Current Opinion in Biotechnology\",",
        "keywords": "Main topic:XAI",
        "note": "\"Plant Biotechnology \u25cf Food Biotechnology\",",
        "pages": "\"217 - 225\",",
        "title": "\"Can exascale computing and explainable artificial intelligence applied to plant biology deliver on the United Nations sustainable development goals?\",",
        "type": "article",
        "url": "\"http://www.sciencedirect.com/science/article/pii/S0958166920300100\",",
        "volume": "\"61\",",
        "year": "\"2020\","
    },
    "Saikia2019_dmh": {
        "abstract": "Much research work in computer vision is being spent on optimizing existing network architectures to obtain a few more percentage points on benchmarks. Recent AutoML approaches promise to relieve us from this effort. However, they are mainly designed for comparatively small-scale classification tasks. In this work, we show how to use and extend existing AutoML techniques to efficiently optimize large-scale U-Net-like encoder-decoder architectures. In particular, we leverage gradient-based neural architecture search and Bayesian optimization for hyperparameter search. The resulting optimization does not require a large-scale compute cluster. We show results on disparity estimation that clearly outperform the manually optimized baseline and reach state-of-the-art performance.",
        "author": "Tonmoy Saikia and Yassine Marrakchi and Arber Zela and Frank Hutter and Thomas Brox",
        "date": "2019-01-01",
        "doi": "10.1109/ICCV.2019.00190",
        "key": "conf/iccv/SaikiaMZHB19",
        "keywords": "Main topic:AutoML, AI",
        "pages": "1812-1823",
        "pubstate": "published",
        "title": "AutoDispNet - Improving Disparity Estimation With AutoML",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://arxiv.org/abs/1905.07443",
        "year": "2019"
    },
    "Samek2017": {
        "abstract": "With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks.",
        "author": "Wojciech Samek and Thomas Wiegand and Klaus-Robert M\u00fcller",
        "date": "2017-08-28",
        "eprint": "http://arxiv.org/abs/1708.08296v1",
        "eprintclass": "cs.AI",
        "eprinttype": "arXiv",
        "file": ":http\\://arxiv.org/pdf/1708.08296v1:PDF",
        "keywords": "Main topic:XAI",
        "title": "Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models",
        "type": "Article",
        "year": "2017"
    },
    "Song2020_qso": {
        "abstract": "Although remarkable progress has been made on single image super-resolution due to the revival of deep convolutional neural networks, deep learning methods are confronted with the challenges of computation and memory consumption in practice, especially for mobile devices. Focusing on this issue, we propose an efficient residual dense block search algorithm with multiple objectives to hunt for fast, lightweight and accurate networks for image super-resolution. Firstly, to accelerate super-resolution network, we exploit the variation of feature scale adequately with the proposed efficient residual dense blocks. In the proposed evolutionary algorithm, the locations of pooling and upsampling operator are searched automatically. Secondly, network architecture is evolved with the guidance of block credits to acquire accurate super-resolution network. The block credit reflects the effect of current block and is earned during model evaluation process. It guides the evolution by weighing the sampling probability of mutation to favor admirable blocks. Extensive experimental results demonstrate the effectiveness of the proposed searching method and the found efficient super-resolution models achieve better performance than the state-of-the-art methods with limited number of parameters and FLOPs.",
        "author": "Dehua Song and Chang Xu and Xu Jia and Yiyi Chen and Chunjing Xu and Yunhe Wang",
        "date": "2020-01-01",
        "key": "conf/aaai/Song0JCXW20",
        "keywords": "Main topic:AutoML, AI",
        "pages": "12007-12014",
        "pubstate": "published",
        "title": "Efficient Residual Dense Block Search for Image Super-Resolution",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://arxiv.org/abs/1909.11409",
        "year": "2020"
    },
    "Tan2018": {
        "abstract": "Designing convolutional neural networks (CNN) for mobile devices is challenging because mobile models need to be small and fast, yet still accurate. Although significant efforts have been dedicated to design and improve mobile CNNs on all dimensions, it is very difficult to manually balance these trade-offs when there are so many architectural possibilities to consider. In this paper, we propose an automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency. Unlike previous work, where latency is considered via another, often inaccurate proxy (e.g., FLOPS), our approach directly measures real-world inference latency by executing the model on mobile phones. To further strike the right balance between flexibility and search space size, we propose a novel factorized hierarchical search space that encourages layer diversity throughout the network. Experimental results show that our approach consistently outperforms state-of-the-art mobile CNN models across multiple vision tasks. On the ImageNet classification task, our MnasNet achieves 75.2{\\%} top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8x faster than MobileNetV2 [29] with 0.5{\\%} higher accuracy and 2.3x faster than NASNet [36] with 1.2{\\%} higher accuracy. Our MnasNet also achieves better mAP quality than MobileNets for COCO object detection. Code is at https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet",
        "archiveprefix": "arXiv",
        "arxivid": "1807.11626",
        "author": "Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V.",
        "eprint": "1807.11626",
        "file": ":C$\\backslash$:/Users/Amirreza/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan et al. - 2018 - MnasNet Platform-Aware Neural Architecture Search for Mobile.pdf:pdf",
        "keywords": "Main topic:AutoML, AI, concentration :learning, Main topic:AutoML, AI",
        "pages": "2820--2828",
        "title": "{MnasNet: Platform-Aware Neural Architecture Search for Mobile}",
        "type": "Article",
        "url": "http://arxiv.org/abs/1807.11626",
        "year": "2018"
    },
    "Tjoa_2020": {
        "abstract": "Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning. Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the deep learning is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide \"obviously\" interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that (1) clinicians and practitioners can subsequently approach these methods with caution, (2) insights into interpretability will be born with more considerations for medical practices, and (3) initiatives to push forward data-based, mathematically- and technically-grounded medical education are encouraged.",
        "author": "Tjoa, Erico and Guan, Cuntai",
        "doi": "10.1109/tnnls.2020.3027314",
        "issn": "2162-2388",
        "journal": "IEEE Transactions on Neural Networks and Learning Systems",
        "keywords": "Main topic:XAI, AI",
        "pages": "1\u201321",
        "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
        "title": "A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI",
        "type": "article",
        "url": "http://dx.doi.org/10.1109/TNNLS.2020.3027314",
        "year": "2020"
    },
    "WANG2020249": {
        "abstract": "Automatic architecture search is efficient to discover novel neural networks while it is mostly employed for pure vision or natural language tasks. However, cross-modality tasks are highly emphasized on the associative mechanisms between visual and language models rather than merely convolutional neural network\u00a0(CNN) or recurrent neural network\u00a0(RNN) with the best performance. In this work, the intermediary associative connection is approximated to the topological inner structure of RNN cell, which is further evolved by an evolutionary algorithm on the proxy of image captioning task. On the MSCOCO dataset, the proposed algorithm, starting from scratch, discovers more than 100 RNN variants with the performances all above 100 on CIDEr and 31 on BLEU4, and the top performance achieves 101.4 and 32.6 accordingly. Additionally, several unknown interesting patterns as well as many existing powerful structures are found in the generated RNNs. The patterns of operation and connection in the generated architecture are analyzed to understand the language modeling of cross-modality compared with general RNNs.",
        "author": "Hanzhang Wang and Hanli Wang and Kaisheng Xu",
        "doi": "https://doi.org/10.1016/j.neucom.2020.03.087",
        "issn": "0925-2312",
        "journal": "Neurocomputing",
        "keywords": "Image captioning, Evolutionary algorithm, Multimodal learning, Main topic:AutoML, AI, application :industry",
        "pages": "249-256",
        "title": "Evolutionary recurrent neural network for image captioning",
        "type": "Article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0925231220304744",
        "volume": "401",
        "year": "2020"
    },
    "Wu_2019_CVPR": {
        "author": "Wu, Bichen and Dai, Xiaoliang and Zhang, Peizhao and Wang, Yanghan and Sun, Fei and Wu, Yiming and Tian, Yuandong and Vajda, Peter and Jia, Yangqing and Keutzer, Kurt",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "keywords": "Main topic:AutoML, AI, NAS",
        "month": "June",
        "title": "FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search",
        "type": "InProceedings",
        "year": "2019"
    },
    "Wyk2019_ikq": {
        "abstract": "Convolutional neural network (CNN) architectures have traditionally been explored by human experts in a manual search process that is time-consuming and ineffectively explores the massive space of potential solutions. Neural architecture search (NAS) methods automatically search the space of neural network hyperparameters in order to find optimal task-specific architectures. NAS methods have discovered CNN architectures that achieve state-of-the-art performance in image classification among other tasks, however the application of NAS to image-to-image regression problems such as image restoration is sparse. This paper proposes a NAS method that performs computationally efficient evolutionary search of a minimally constrained network architecture search space. The performance of architectures discovered by the proposed method is evaluated on a variety of image restoration tasks applied to the ImageNet64x64 dataset, and compared with human-engineered CNN architectures. The best neural architectures discovered using only 2 GPU-hours of evolutionary search exhibit comparable performance to the human-engineered baseline architecture.",
        "author": "Gerard Jacques van Wyk and Anna Sergeevna Bosman",
        "date": "2019-01-01",
        "doi": "10.1109/IJCNN.2019.8852417",
        "key": "conf/ijcnn/WykB19",
        "keywords": "Main topic:AutoML, AI, application :industry, Image Restoration, NAS",
        "pages": "1-8",
        "pubstate": "published",
        "title": "Evolutionary Neural Architecture Search for Image Restoration",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://arxiv.org/abs/1812.05866",
        "year": "2019"
    },
    "Xu2020_gtf": {
        "abstract": "Data augmentation is an effective and universal technique for improving generalization performance of deep neural networks. It could enrich diversity of training samples that is essential in medical image segmentation tasks because 1) the scale of medical image dataset is typically smaller, which may increase the risk of overfitting; 2) the shape and modality of different objects such as organs or tumors are unique, thus requiring customized data augmentation policy. However, most data augmentation implementations are hand-crafted and suboptimal in medical image processing. To fully exploit the potential of data augmentation, we propose an efficient algorithm to automatically search for the optimal augmentation strategies. We formulate the coupled optimization w.r.t. network weights and augmentation parameters into a differentiable form by means of stochastic relaxation. This formulation allows us to apply alternative gradient-based methods to solve it, i.e. stochastic natural gradient method with adaptive step-size. To the best of our knowledge, it is the first time that differentiable automatic data augmentation is employed in medical image segmentation tasks. Our numerical experiments demonstrate that the proposed approach significantly outperforms existing build-in data augmentation of state-of-the-art models.",
        "author": "Ju Xu and Mengzhang Li and Zhanxing Zhu",
        "date": "2020-01-01",
        "doi": "10.1007/978-3-030-59710-8_37",
        "key": "conf/miccai/XuLZ20",
        "keywords": "Main topic:AutoML, AI, Image Segmentation",
        "pages": "378-387",
        "pubstate": "published",
        "title": "Automatic Data Augmentation for 3D Medical Image Segmentation",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://link.springer.com/chapter/10.1007/978-3-030-59710-8_37",
        "year": "2020"
    },
    "Xu_2020_CVPR": {
        "abstract": "A new paradigm is proposed for autonomous driving. The new paradigm lies between the end-to-end and pipelined approaches, and is inspired by how humans solve the problem. While it relies on scene understanding, the latter only considers objects that could originate hazard. These are denoted as action-inducing, since changes in their state should trigger vehicle actions. They also define a set of explanations for these actions, which should be produced jointly with the latter. An extension of the BDD100K dataset, annotated for a set of 4 actions and 21 explanations, is proposed. A new multi-task formulation of the problem, which optimizes the accuracy of both action commands and explanations, is then introduced. A CNN architecture is finally proposed to solve this problem, by combining reasoning about action inducing objects and global scene context. Experimental results show that the requirement of explanations improves the recognition of action-inducing objects, which in turn leads to better action predictions.",
        "author": "Xu, Yiran and Yang, Xiaoyin and Gong, Lihang and Lin, Hsuan-Chu and Wu, Tz-Ying and Li, Yunsheng and Vasconcelos, Nuno",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "keywords": "Main topic:XAI, AI",
        "month": "June",
        "title": "Explainable Object-Induced Action Decision for Autonomous Vehicles",
        "type": "InProceedings",
        "year": "2020"
    },
    "Yan2020_qis": {
        "abstract": "The recent breakthroughs of Neural Architecture Search (NAS) have motivated various applications in medical image segmentation. However, most existing work either simply rely on hyper-parameter tuning or stick to a fixed network backbone, thereby limiting the underlying search space to identify more efficient architecture. This paper presents a Multi-Scale NAS (MS-NAS) framework that is featured with multi-scale search space from network backbone to cell operation, and multi-scale fusion capability to fuse features with different sizes. To mitigate the computational overhead due to the larger search space, a partial channel connection scheme and a two-step decoding method are utilized to reduce computational overhead while maintaining optimization quality. Experimental results show that on various datasets for segmentation, MS-NAS outperforms the state-of-the-art methods and achieves 0.6-5.4 mIOU and 0.4-3.5 DSC improvements, while the computational resource consumption is reduced by 18.0-24.9.",
        "author": "Xingang Yan and Weiwen Jiang and Yiyu Shi and Cheng Zhuo",
        "date": "2020-01-01",
        "doi": "10.1007/978-3-030-59710-8_38",
        "key": "conf/miccai/YanJSZ20",
        "keywords": "Main topic:AutoML, AI, Image Segmentation",
        "pages": "388-397",
        "pubstate": "published",
        "title": "MS-NAS - Multi-scale Neural Architecture Search for Medical Image Segmentation",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://arxiv.org/abs/2007.06151",
        "year": "2020"
    },
    "Ying2019": {
        "abstract": "Recent advances in neural architecture search (NAS) demand tremendous computational resources, which makes it difficult to reproduce experiments and imposes a barrier-to-entry to researchers without access to large-scale computation. We aim to ameliorate these problems by introducing NAS-Bench-101, the first public architecture dataset for NAS research. To build NAS-Bench-101, we carefully constructed a compact, yet expressive, search space, exploiting graph isomorphisms to identify 423k unique convolutional architectures. We trained and evaluated all of these architectures multiple times on CIFAR-10 and compiled the results into a large dataset of over 5 million trained models. This allows researchers to evaluate the quality of a diverse range of models in milliseconds by querying the pre-computed dataset. We demonstrate its utility by analyzing the dataset as a whole and by benchmarking a range of architecture optimization algorithms.",
        "archiveprefix": "arXiv",
        "arxivid": "1902.09635",
        "author": "Ying, Chris and Klein, Aaron and Real, Esteban and Christiansen, Eric and Murphy, Kevin and Hutter, Frank",
        "eprint": "1902.09635",
        "file": ":C$\\backslash$:/Users/Amirreza/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ying et al. - 2019 - NAS-Bench-101 Towards Reproducible Neural Architecture Search.pdf:pdf",
        "keywords": "Main topic:AutoML, AI",
        "title": "{NAS-Bench-101: Towards Reproducible Neural Architecture Search}",
        "type": "Article",
        "url": "http://arxiv.org/abs/1902.09635",
        "year": "2019"
    },
    "Zhang2019_gsf": {
        "abstract": "Most of the existing person re-identification (ReID) methods use a classification network pre-trained on external data as the backbone and then fine-tune it, which results in a network architecture that is fixed and dependent on pre-training of external data. There are also some methods that are specifically designed by human experts for ReID, but manual network design becomes more difficult as network requirements increase and often fails to achieve optimal settings. In this paper, we consider using emerging neural architecture search (NAS) technology as a tool to solve above problems. However, most of NAS methods deal with classification tasks, which causes NAS to not be directly extended to ReID. In order to coordinate the inconsistency between the two optimization goals, we propose to establish an objective function with the assistant of the triplet loss to guide the direction of architecture search. Finally, it is no longer dependent on external data to automatically generate a ReID network with excellent performance using NAS directly on the target dataset. The experimental results on three public datasets validate that our method can automatically and efficiently find the network architecture suitable for ReID.",
        "author": "Shizhou Zhang and Rui Cao and Xing Wei and Peng Wang and Yanning Zhang",
        "date": "2019-01-01",
        "doi": "10.1007/978-3-030-31654-9_46",
        "key": "conf/prcv/ZhangCWWZ19",
        "keywords": "Main topic:AutoML, AI, application :industry, NAS",
        "pages": "540-551",
        "pubstate": "published",
        "title": "Person Re-identification with Neural Architecture Search",
        "tppubtype": "inproceedings",
        "type": "InProceedings",
        "url": "https://link.springer.com/chapter/10.1007/978-3-030-31654-9_46",
        "year": "2019"
    },
    "Zhao2020_bvp": {
        "abstract": "User behavior and feature interactions are crucial in deep learning-based recommender systems. There has been a diverse set of behavior modeling and interaction exploration methods in the literature. Nevertheless, the design of task-aware recommender systems still requires feature engineering and architecture engineering from domain experts. In this work, we introduce AMER, namely Automatic behavior Modeling and interaction Exploration in Recommender systems with Neural Architecture Search (NAS). The core contributions of AMER include the three-stage search space and the tailored three-step searching pipeline. In the first step, AMER searches for residual blocks that incorporate commonly used operations in the block-wise search space of stage 1 to model sequential patterns in user behavior. In the second step, it progressively investigates useful low-order and high-order feature interactions in the non-sequential interaction space of stage 2. Finally, an aggregation multi-layer perceptron (MLP) with shortcut connection is selected from flexible dimension settings of stage~3 to combine features extracted from the previous steps. For efficient and effective NAS, AMER employs the one-shot random search in all three steps. Further analysis reveals that AMER's search space could cover most of the representative behavior extraction and interaction investigation methods, which demonstrates the universality of our design. The extensive experimental results over various scenarios reveal that AMER could outperform competitive baselines with elaborate feature engineering and architecture engineering, indicating both effectiveness and robustness of the proposed method.",
        "author": "Pengyu Zhao and Kecheng Xiao and Yuanxing Zhang and Kaigui Bian and Wei Yan",
        "date": "2020-01-01",
        "key": "journals/corr/abs-2006-05933",
        "keywords": "Main topic:AutoML, AI, Recommender System",
        "pubstate": "published",
        "title": "AMER - Automatic Behavior Modeling and Interaction Exploration in Recommender System",
        "tppubtype": "techreport",
        "type": "TechReport",
        "url": "https://arxiv.org/abs/2006.05933",
        "volume": "abs/2006.05933",
        "year": "2020"
    },
    "Zhu2020_otr": {
        "abstract": "Image captioning transforms complex visual information into abstract natural language for representation, which can help computers understanding the world quickly. However, due to the complexity of the real environment, it needs to identify key objects and realize their connections, and further generate natural language. The whole process involves a visual understanding module and a language generation module, which brings more challenges to the design of deep neural networks than other tasks. Neural Architecture Search (NAS) has shown its important role in a variety of image recognition tasks. Besides, RNN plays an essential role in the image captioning task. We introduce a AutoCaption method to better design the decoder module of the image captioning where we use the NAS to design the decoder module called AutoRNN automatically. We use the reinforcement learning method based on shared parameters for automatic design the AutoRNN efficiently. The search space of the AutoCaption includes connections between the layers and the operations in layers both, and it can make AutoRNN express more architectures. In particular, RNN is equivalent to a subset of our search space. Experiments on the MSCOCO datasets show that our AutoCaption model can achieve better performance than traditional hand-design methods. Our AutoCaption obtains the best published CIDEr performance of 135.8 on COCO Karpathy test split. When further using ensemble technology, CIDEr is boosted up to 139..",
        "author": "Xinxin Zhu and Weining Wang and Longteng Guo and Jing Liu",
        "date": "2020-01-01",
        "key": "journals/corr/abs-2012-09742",
        "keywords": "Main topic:AutoML, AI, application :industry, Image Captioning",
        "pubstate": "published",
        "title": "AutoCaption - Image Captioning with Neural Architecture Search",
        "tppubtype": "techreport",
        "type": "TechReport",
        "url": "https://arxiv.org/abs/2012.09742",
        "volume": "abs/2012.09742",
        "year": "2020"
    },
    "Zhu2020_rtq": {
        "abstract": "Federated learning is a recently proposed distributed machine learning paradigm for privacy preservation, which has found a wide range of applications where data privacy is of primary concern. Meanwhile, neural architecture search has become very popular in deep learning for automatically tuning the architecture and hyperparameters of deep neural networks. While both federated learning and neural architecture search are faced with many open challenges, searching for optimized neural architectures in the federated learning framework is particularly demanding. This survey paper starts with a brief introduction to federated learning, including both horizontal, vertical, and hybrid federated learning. Then, neural architecture search approaches based on reinforcement learning, evolutionary algorithms and gradient-based are presented. This is followed by a description of federated neural architecture search that has recently been proposed, which is categorized into online and offline implementations, and single- and multi-objective search approaches. Finally, remaining open research questions are outlined and promising research topics are suggested.",
        "author": "Hangyu Zhu and Haoyu Zhang and Yaochu Jin",
        "date": "2020-01-01",
        "key": "journals/corr/abs-2009-05868",
        "keywords": "Main topic:AutoML, AI, survey, NAS",
        "pubstate": "published",
        "title": "From Federated Learning to Federated Neural Architecture Search - A Survey",
        "tppubtype": "techreport",
        "type": "TechReport",
        "url": "https://arxiv.org/pdf/2009.05868.pdf",
        "volume": "abs/2009.05868",
        "year": "2020"
    },
    "abbas2021using": {
        "author": "Abbas, Abdallah and Beqiri, Sara and Wagner, Siegfried and Korot, Edward and Singh, Ritvij and Struyven, Robbert and Keane, Pearse",
        "journal": "Investigative Ophthalmology \\& Visual Science",
        "number": "8",
        "pages": "291--291",
        "publisher": "The Association for Research in Vision and Ophthalmology",
        "title": "Using the What-if Tool to perform nearest counterfactual analysis on an AutoML model that predicts visual acuity outcomes in patients receiving treatment for wet age-related macular degeneration",
        "type": "article",
        "volume": "62",
        "year": "2021"
    },
    "agrawal2006autoadmin": {
        "author": "\"Agrawal, Sanjay and Bruno, Nicolas and Chaudhuri, Surajit and Narasayya, Vivek R\",",
        "journal": "\"IEEE Data Eng. Bull.\",",
        "number": "\"3\",",
        "pages": "\"7--15\",",
        "title": "\"AutoAdmin: Self-Tuning Database SystemsTechnology.\",",
        "type": "article",
        "volume": "\"29\",",
        "year": "\"2006\""
    },
    "aguilar2020cold": {
        "abstract": "Multiple Machine Learning solutions in Industry exist where interpretability is required. In retail, this is especially important when dealing with cold-start forecasting of promotional sales. In the planning phase of these promotions, retailers produce sales predictions that are scrutinised by both forecasting experts and managers. In this paper, we combine the predictive benefits of Gradient Boosted Decision Trees regressors and the interpretability of contrastive explanations. These are implicitly generated by the manner we shape data. Our method presents the cold-start forecasts in relation to the observed promotional sales of other products, which we call neighbours. They are selected based on a measure of closeness to the predicted promotion, which is derived from the variable importance calculated during the training of the regressors. With this information, the expert reviewer adjusts the cold-start prediction by simply varying the contribution of the neighbours. To validate our results we test our method on a surrogate model, as well as on real-market data. The results on the surrogate model demonstrate that our method is able to accurately identify the features that contribute to sales and then select the closest neighbours to produce a contrastive explanation. The results on real-market data also show that the proposed method performs at a similar level to widespread methods such as conventional CatBoost, NGBoost or AutoGluon, and has the advantage of providing interpretability.",
        "author": "Aguilar-Palacios, Carlos and Mu{\\~n}oz-Romero, Sergio and luis Rojo-{\\'A}lvarez, Jos{\\'e}",
        "journal": "IEEE Access",
        "keywords": "Main topic:XAI, AI",
        "pages": "137574--137586",
        "publisher": "IEEE",
        "title": "Cold-Start Promotional Sales Forecasting Through Gradient Boosted-Based Contrastive Explanations",
        "type": "article",
        "volume": "8",
        "year": "2020"
    },
    "ailandscape2020": {
        "addendum": "\"(accessed: 02.13.2021)\",",
        "keywords": "\"ai,landscape2020\"",
        "title": "\"AI Landscape dashboard\",",
        "type": "online",
        "url": "\"https://knowledge4policy.ec.europa.eu/ai-watch/ai-landscape-dashboard_en\","
    },
    "allach2021recognition": {
        "author": "Allach, Samir and Ahmed, Mohamed Ben and Boudhir, Anouar Abdelhakim",
        "booktitle": "Emerging Trends in ICT for Sustainable Development",
        "pages": "219--225",
        "publisher": "Springer",
        "title": "Recognition and Reconstruction of Road Marking with Generative Adversarial Networks (GANs)",
        "type": "incollection",
        "year": "2021"
    },
    "amer2021deep": {
        "author": "Amer, Karim and Samy, Mohamed and Shaker, Mahmoud and ElHelw, Mohamed",
        "booktitle": "Thirteenth International Conference on Machine Vision",
        "organization": "International Society for Optics and Photonics",
        "pages": "1160503",
        "title": "Deep convolutional neural network based autonomous drone navigation",
        "type": "inproceedings",
        "volume": "11605",
        "year": "2021"
    },
    "arrieta2020explainable": {
        "abstract": "In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.",
        "author": "Arrieta, Alejandro Barredo and D{\\'\\i}az-Rodr{\\'\\i}guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc{\\'\\i}a, Salvador and Gil-L{\\'o}pez, Sergio and Molina, Daniel and Benjamins, Richard and others",
        "journal": "Information Fusion",
        "keywords": "Main topic:XAI, AI",
        "pages": "82--115",
        "publisher": "Elsevier",
        "title": "Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI",
        "type": "article",
        "volume": "58",
        "year": "2020"
    },
    "athavale2020ai": {
        "author": "Athavale, Jyotika and Baldovin, Andrea and Graefe, Ralf and Paulitsch, Michael and Rosales, Rafael",
        "booktitle": "2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)",
        "organization": "IEEE",
        "pages": "74--77",
        "title": "AI and Reliability Trends in Safety-Critical Autonomous Systems on Ground and Air",
        "type": "inproceedings",
        "year": "2020"
    },
    "automl_book": {
        "editor": "Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin",
        "keywords": "Main topic:AutoML, AI",
        "note": "In press, available at http://automl.org/book.",
        "publisher": "Springer",
        "title": "Automated Machine Learning: Methods, Systems, Challenges",
        "type": "Book",
        "year": "2018"
    },
    "avhistoory2020": {
        "addendum": "\"(accessed: 02.13.2021)\",",
        "keywords": "\"AV,history\"",
        "title": "\"History of self-driving cars\",",
        "type": "online",
        "url": "\"https://en.wikipedia.org/wiki/History_of_self-driving_cars\","
    },
    "babaoglu2002anthill": {
        "author": "Babaoglu, Ozalp and Meling, Hein and Montresor, Alberto",
        "booktitle": "Proceedings 22nd International Conference on Distributed Computing Systems",
        "organization": "IEEE",
        "pages": "15--22",
        "title": "Anthill: A framework for the development of agent-based peer-to-peer systems",
        "type": "inproceedings",
        "year": "2002"
    },
    "bach2015pixel": {
        "abstract": "Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.",
        "author": "Bach, Sebastian and Binder, Alexander and Montavon, Gr{\\'e}goire and Klauschen, Frederick and M{\\\"u}ller, Klaus-Robert and Samek, Wojciech",
        "journal": "PloS one",
        "keywords": "Main topic:XAI",
        "number": "7",
        "pages": "e0130140",
        "publisher": "Public Library of Science",
        "title": "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation",
        "type": "article",
        "volume": "10",
        "year": "2015"
    },
    "balda2018generation": {
        "abstract": "It has been observed that deep learning architectures tend to make erroneous decisions with high reliability for particularly designed adversarial instances. In this work, we show that the perturbation analysis of these architectures provides a framework for generating adversarial instances by convex programming which, for classification tasks, is able to recover variants of existing non-adaptive adversarial methods. The proposed framework can be used for the design of adversarial noise under various desirable constraints and different types of networks. Moreover, this framework is capable of explaining various existing adversarial methods and can be used to derive new algorithms as well. We make use of these results to obtain novel algorithms. The experiments show the competitive performance of the obtained solutions, in terms of fooling ratio, when benchmarked with well-known adversarial methods.",
        "author": "Balda, Emilio Rafael and Behboodi, Arash and Mathar, Rudolf",
        "booktitle": "2018 52nd Asilomar Conference on Signals, Systems, and Computers",
        "keywords": "Main topic:XAI",
        "organization": "IEEE",
        "pages": "60--65",
        "title": "On generation of adversarial examples using convex programming",
        "type": "inproceedings",
        "year": "2018"
    },
    "baron2020counterfactual": {
        "abstract": "Our goal in this paper is to extend counterfactual accounts of scientific explanation to mathematics. Our focus, in particular, is on intra-mathematical explanations: explanations of one mathematical fact in terms of another. We offer a basic counterfactual theory of intra-mathematical explanations, before modelling the explanatory structure of a test case using counterfactual machinery. We finish by considering the application of counterpossibles to mathematical explanation, and explore a second test case along these lines.",
        "author": "Baron, Sam and Colyvan, Mark and Ripley, David",
        "journal": "Philosophia Mathematica",
        "keywords": "Main topic:XAI, AI",
        "number": "1",
        "pages": "1--34",
        "publisher": "Oxford University Press",
        "title": "A counterfactual approach to explanation in mathematics",
        "type": "article",
        "volume": "28",
        "year": "2020"
    },
    "barricelli2020human": {
        "abstract": "Our research work describes a team of human Digital Twins (DTs), each tracking fitness-related measurements describing an athlete\u2019s behavior in consecutive days (e.g. food income, activity, sleep). After collecting enough measurements, the DT firstly predicts the physical twin performance during training and, in case of non-optimal result, it suggests modifications in the athlete\u2019s behavior. The athlete\u2019s team is integrated into SmartFit, a software framework for supporting trainers and coaches in monitoring and manage athletes\u2019 fitness activity and results. Through IoT sensors embedded in wearable devices and applications for manual logging (e.g. mood, food income), SmartFit continuously captures measurements, initially treated as the dynamic data describing the current physical twins\u2019 status. Dynamic data allows adapting each DT\u2019s status and triggering the DT\u2019s predictions and suggestions. The analyzed measurements are stored as the historical data, further processed by the DT to update (increase) its knowledge and ability to provide reliable predictions. Results show that, thanks to the team of DTs, SmartFit computes trustable predictions of the physical twins\u2019 conditions and produces understandable suggestions which can be used by trainers to trigger optimization actions in the athletes\u2019 behavior. Though applied in the sport context, SmartFit can be easily adapted to other monitoring tasks.",
        "author": "Barricelli, Barbara Rita and Casiraghi, Elena and Gliozzo, Jessica and Petrini, Alessandro and Valtolina, Stefano",
        "journal": "Ieee Access",
        "keywords": "Main topic:XAI, AI",
        "pages": "26637--26664",
        "publisher": "IEEE",
        "title": "Human digital twin for fitness management",
        "type": "article",
        "volume": "8",
        "year": "2020"
    },
    "baudivs2015modeling": {
        "abstract": "We briefly survey the current state of art in the field of Question Answering and present the YodaQA system, an open source framework for this task and a baseline pipeline with reasonable performance. We take a holistic approach, reviewing and aiming to integrate many different question answering task definitions and approaches concerning classes of knowledge bases, question representation and answer generation. To ease performance comparisons of general-purpose QA systems, we also propose an effort in building a new reference QA testing corpus which is a curated and extended version of the TREC corpus.",
        "author": "Baudi{\\v{s} Petr and {\\v{S}}ediv{\\`y Jan",
        "booktitle": "International Conference of the Cross-Language Evaluation Forum for European Languages",
        "keywords": "Main topic:NLP,   Experiments data:real , QA, dataset:CuratedTrec,  AI",
        "organization": "Springer",
        "pages": "222--228",
        "title": "Modeling of the question answering task in the yodaqa system",
        "type": "inproceedings",
        "year": "2015"
    },
    "baudivs2015yodaqa": {
        "abstract": "Question Answering as a sub-field of information retrieval and information extraction is recently enjoying renewed popularity, triggered by the publicized success of IBM Watson in the Jeopardy! competition. But Question Answering research is now proceeding in several semi-independent tiers depending on the precise task formulation and constraints on the knowledge base, and new researchers entering the field can focus only on various restricted sub-tasks as no modern full-scale software system for QA has been openly available until recently. By our YodaQA system that we introduce here, we seek to re-unite and boost research efforts in Question Answering, providing a modular, open source pipeline for this task \u2014 allowing integration of various knowledge base paradigms, answer production and analysis strategies and using a machine learned models to rank the answers. Within this pipeline,we also supply a baseline QA system inspired by Deep QA with solid performance and propose a reference experimental setup for easy future performance comparisons.In this paper, we review the available open QA platforms,present the architecture of our pipeline, the components of the baseline QA system, and also analyze the system performance on the reference dataset.",
        "author": "Baudi{\\v{s} Petr",
        "booktitle": "POSTER 2015-19th International Student Conference on Electrical Engineering",
        "keywords": "Main topic:NLP,   Experiments data:real , QA, AI",
        "pages": "1156--1165",
        "title": "YodaQA: a modular question answering system pipeline",
        "type": "inproceedings",
        "year": "2015"
    },
    "beck2015visual": {
        "author": "Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "number": "1",
        "pages": "180--189",
        "publisher": "IEEE",
        "title": "Visual analysis and dissemination of scientific literature collections with SurVis",
        "type": "article",
        "volume": "22",
        "year": "2015"
    },
    "berant2013semantic": {
        "abstract": "In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs.  The main challenge in this setting is narrowing down the huge number of possible logical predicates fora given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus.Second, we use a bridging operation to generate additional predicates based on neighboring predicates.On the dataset of Cai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser.Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline.",
        "author": "Berant, Jonathan and Chou, Andrew and Frostig, Roy and Liang, Percy",
        "booktitle": "Proceedings of the 2013 conference on empirical methods in natural language processing",
        "keywords": "Main topic:NLP, Experiments data:real , QA, dataset:WebQuestions, AI",
        "pages": "1533--1544",
        "title": "Semantic parsing on freebase from question-answer pairs",
        "type": "inproceedings",
        "year": "2013"
    },
    "bergstra2013making": {
        "author": "Bergstra, James and Yamins, Daniel and Cox, David",
        "booktitle": "International conference on machine learning",
        "keywords": "Main topic:AutoML, AI",
        "organization": "PMLR",
        "pages": "115--123",
        "title": "Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures",
        "type": "InProceedings",
        "year": "2013"
    },
    "bertram2013towards": {
        "author": "Bertram, Volker",
        "publisher": "DNV GL: https://www. ntnu. edu/documents/20587845/1266707380/UnmannedShips~\u2026",
        "title": "Towards the Unmanned Ship",
        "type": "misc",
        "year": "2013"
    },
    "bibel2010general": {
        "author": "Bibel, Wolfgang",
        "booktitle": "Intelligent autonomous systems",
        "organization": "Springer",
        "pages": "5--27",
        "title": "General aspects of intelligent autonomous systems",
        "type": "inproceedings",
        "year": "2010"
    },
    "brock2017smash": {
        "author": "Brock, Andrew and Lim, Theodore and Ritchie, James M and Weston, Nick",
        "journal": "The International Conference on Learning Representations (ICLR) 2018",
        "keywords": "Main topic:AutoML, AI",
        "title": "Smash: one-shot model architecture search through hypernetworks",
        "type": "Article",
        "year": "2017"
    },
    "cai2018path": {
        "author": "Cai, Han and Yang, Jiacheng and Zhang, Weinan and Han, Song and Yu, Yong",
        "booktitle": "International Conference on Machine Learning",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "organization": "PMLR",
        "pages": "678--687",
        "title": "Path-level network transformation for efficient architecture search",
        "type": "InProceedings",
        "year": "2018"
    },
    "cai2018proxylessnas": {
        "author": "Cai, Han and Zhu, Ligeng and Han, Song",
        "journal": "arXiv preprint arXiv:1812.00332",
        "keywords": "Main topic:AutoML, AI",
        "title": "Proxylessnas: Direct neural architecture search on target task and hardware",
        "type": "Article",
        "year": "2018"
    },
    "calvaresi2020explainable": {
        "author": "Calvaresi, Davide and Najjar, Amro and Winikoff, Michael and Fr{\\\"a}mling, Kary",
        "keywords": "Main topic:XAI",
        "publisher": "Springer",
        "title": "Explainable, Transparent Autonomous Agents and Multi-Agent Systems",
        "type": "book",
        "year": "2020"
    },
    "cao2019deqa": {
        "abstract": "Today there is no effective support for device-wide question answering on mobile devices. State-of-the-art QA models are deep learning behemoths designed for the cloud which run extremely slow and require more memory than available on phones. We present DeQA, a suite of latency- and memory- optimizations that adapts existing QA systems to run completely locally on mobile phones. Specifically, we design two latency optimizations that (1) stops processing documents if further processing cannot improve answer quality, and (2) identifies computation that does not depend on the question and moves it offline. These optimizations do not depend on the QA model internals and can be applied to several existing QA models. DeQA also implements a set of memory optimizations by (i) loading partial indexes in memory, (ii) working with smaller units of data, and (iii) replacing in-memory lookups with a key-value database. We use DeQA to port three state-of-the-art QA systems to the mobile device and evaluate over three datasets. The first is a large scale SQuAD dataset defined over Wikipedia collection. We also create two on-device QA datasets, one over a publicly available email data collection and the other using a cross-app data collection we obtain from two users. Our evaluations show that DeQA can run QA models with only a few hundred MBs of memory and provides at least 13x speedup on average on the mobile phone across all three datasets.\\% with less than a 1\\% drop in accuracy.",
        "author": "Cao, Qingqing and Weber, Noah and Balasubramanian, Niranjan and Balasubramanian, Aruna",
        "booktitle": "Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services",
        "keywords": "Information-systems, Experiments data:real ,  Main topic:NLP, QA, Human-centered_computing, Mobile-computing, Mobile-devices, AI",
        "pages": "27--40",
        "title": "Deqa: On-device question answering",
        "type": "inproceedings",
        "year": "2019"
    },
    "car2020conversational": {
        "author": "Car, Lorainne Tudor and Dhinagaran, Dhakshenya Ardhithy and Kyaw, Bhone Myint and Kowatsch, Tobias and Joty, Shafiq and Theng, Yin-Leng and Atun, Rifat",
        "journal": "Journal of medical Internet research",
        "keywords": "Main topic:NLP, concentration:perception , application:healthcare, chatbots,  AI",
        "number": "8",
        "pages": "e17158",
        "publisher": "JMIR Publications Inc., Toronto, Canada",
        "title": "Conversational agents in health care: Scoping review and conceptual analysis",
        "type": "article",
        "volume": "22",
        "year": "2020"
    },
    "carvalho2019machine": {
        "abstract": "Machine learning systems are becoming increasingly ubiquitous. These systems\u2019s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.",
        "author": "Carvalho, Diogo V and Pereira, Eduardo M and Cardoso, Jaime S",
        "journal": "Electronics",
        "keywords": "Main topic:XAI, AI",
        "number": "8",
        "pages": "832",
        "publisher": "Multidisciplinary Digital Publishing Institute",
        "title": "Machine learning interpretability: A survey on methods and metrics",
        "type": "article",
        "volume": "8",
        "year": "2019"
    },
    "cavier1993ai": {
        "doi": "https://doi.org/10.1002/1520-6696(199507)31:3<273::AID-JHBS2300310314>3.0.CO;2-1",
        "journal": "Journal of the History of the Behavioral Sciences",
        "number": "3",
        "pages": "273-278",
        "title": "Daniel Crevier. AI: The tumultuous history of the search for artificial intelligence. NY: Basic Books, 1993. 432 pp. (Reviewed by Charles Fair)",
        "type": "article",
        "volume": "31"
    },
    "chae2017autonomous": {
        "author": "Chae, Hyunmin and Kang, Chang Mook and Kim, ByeoungDo and Kim, Jaekyum and Chung, Chung Choo and Choi, Jun Won",
        "booktitle": "2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)",
        "organization": "IEEE",
        "pages": "1--6",
        "title": "Autonomous braking system via deep reinforcement learning",
        "type": "inproceedings",
        "year": "2017"
    },
    "chakraborti2020robotic": {
        "abstract": "In this survey, we study how recent advances in machine intelligence are disrupting the world of business processes. Over the last decade, there has been steady progress towards the automation of business processes under the umbrella of \u201crobotic process automation\u201d (RPA). However, we are currently at an inflection point in this evolution, as a new paradigm called \u201cIntelligent Process Automation\u201d (IPA) emerges, bringing machine learning (ML) and artificial intelligence (AI) technologies to bear in order to improve business process outcomes. The purpose of this paper is to provide a survey of this emerging theme and identify key open research challenges at the intersection of AI and business processes. We hope that this emerging theme will spark engaging conversations at the RPA Forum.",
        "author": "Chakraborti, Tathagata and Isahagian, Vatche and Khalaf, Rania and Khazaeni, Yasaman and Muthusamy, Vinod and Rizk, Yara and Unuvar, Merve",
        "booktitle": "International Conference on Business Process Management",
        "keywords": " Main topic:NLP, concentration:perception , application:Robotic Process Automation (RPA), Intelligent Process Automation (IPA), AI",
        "organization": "Springer",
        "pages": "215--228",
        "title": "From Robotic Process Automation to Intelligent Process Automation",
        "type": "inproceedings",
        "year": "2020"
    },
    "charisi2017moral": {
        "abstract": "Both the ethics of autonomous systems and the problems of their technical implementation have by now been studied in some detail. Less attention has been given to the areas in which these two separate concerns meet. This paper, written by both philosophers and engineers of autonomous systems, addresses a number of issues in machine ethics that are located at precisely the intersection between ethics and engineering. We first discuss the main challenges which, in our view, machine ethics posses to moral philosophy. We them consider different approaches towards the conceptual design of autonomous systems and their implications on the ethics implementation in such systems. Then we examine problematic areas regarding the specification and verification of ethical behavior in autonomous systems, particularly with a view towards the requirements of future legislation. We discuss transparency and accountability issues that will be crucial for any future wide deployment of autonomous systems in society. Finally we consider the, often overlooked, possibility of intentional misuse of AI systems and the possible dangers arising out of deliberately unethical design, implementation, and use of autonomous robots.",
        "archiveprefix": "arXiv",
        "author": "Vicky Charisi and Louise Dennis and Michael Fisher and Robert Lieck and Andreas Matthias and Marija Slavkovik and Janina Sombetzki and Alan F. T. Winfield and Roman Yampolskiy",
        "eprint": "1703.04741",
        "keywords": "Main topic:XAI, AI",
        "primaryclass": "cs.AI",
        "title": "Towards Moral Autonomous Systems",
        "type": "misc",
        "year": "2017"
    },
    "chen2015net2net": {
        "author": "Chen, Tianqi and Goodfellow, Ian and Shlens, Jonathon",
        "journal": "The International Conference on Learning Representations (ICLR) 2016",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Net2net: Accelerating learning via knowledge transfer",
        "type": "Article",
        "year": "2015"
    },
    "chen2016thorough": {
        "abstract": "Enabling a computer to understand a document so that it can answer comprehension questions is a central, yet unsolved goal of NLP. A key factor impeding its solution by machine learned systems is the limited availability of human-annotated data. Hermann et al. (2015) seek to solve this problem by creating over a million training examples by pairing CNN and Daily Mail news articles with their summarized bullet points, and show that a neural network can then be trained to give good performance on this task. In this paper, we conduct a thorough examination of this new reading comprehension task. Our primary aim is to understand what depth of language understanding is required to do well on this task. We approach this from one side by doing a careful hand-analysis of a small subset of the problems and from the other by showing that simple, carefully designed systems can obtain accuracies of 73.6\\% and 76.6\\% on these two datasets, exceeding current state-of-the-art results by 7-10\\% and approaching what we believe is the ceiling for performance on this task.",
        "author": "Chen, Danqi and Bolton, Jason and Manning, Christopher D",
        "journal": "arXiv preprint arXiv:1606.02858",
        "keywords": "Main topic:NLP,   Experiments data:real , RC,QA, AI",
        "title": "A thorough examination of the cnn/daily mail reading comprehension task",
        "type": "article",
        "year": "2016"
    },
    "chen2017reading": {
        "abstract": "This paper proposes to tackle open- domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.",
        "author": "Chen, Danqi and Fisch, Adam and Weston, Jason and Bordes, Antoine",
        "booktitle": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "keywords": " Main topic:NLP, Experiments data:real ,  TQA, AI",
        "pages": "1870--1879",
        "title": "Reading Wikipedia to Answer Open-Domain Questions",
        "type": "inproceedings",
        "year": "2017"
    },
    "chen2019progressive": {
        "author": "Chen, Xin and Xie, Lingxi and Wu, Jun and Tian, Qi",
        "booktitle": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "1294--1303",
        "title": "Progressive differentiable architecture search: Bridging the depth gap between search and evaluation",
        "type": "InProceedings",
        "year": "2019"
    },
    "chen2021robotic": {
        "author": "Chen, Mu-Yen and Wei, Wei and Chao, Han-Chieh and Li, Yi-Fen",
        "journal": "IEEE Sensors Journal",
        "publisher": "IEEE",
        "title": "Robotic Musicianship Based on Least Squares and Sequence Generative Adversarial Networks",
        "type": "article",
        "year": "2021"
    },
    "chiyah-garcia-etal-2018-explainable": {
        "abstract": "\"As unmanned vehicles become more autonomous, it is important to maintain a high level of transparency regarding their behaviour and how they operate. This is particularly important in remote locations where they cannot be directly observed. Here, we describe a method for generating explanations in natural language of autonomous system behaviour and reasoning. Our method involves deriving an interpretable model of autonomy through having an expert {`}speak aloud{'} and providing various levels of detail based on this model. Through an online evaluation study with operators, we show it is best to generate explanations with multiple possible reasons but tersely worded. This work has implications for designing interfaces for autonomy as well as for explainable AI and operator training.\",",
        "address": "\"Tilburg University, The Netherlands\",",
        "author": "\"Chiyah Garcia, Francisco Javier  and Robb, David A.  and Liu, Xingkun  and Laskov, Atanas  and Patron, Pedro  and Hastie, Helen\",",
        "booktitle": "\"Proceedings of the 11th International Conference on Natural Language Generation\",",
        "doi": "\"10.18653/v1/W18-6511\",",
        "keywords": "Main topic:XAI, AI",
        "month": "nov,",
        "pages": "\"99--108\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"Explainable Autonomy: A Study of Explanation Styles for Building Clear Mental Models\",",
        "type": "inproceedings",
        "url": "\"https://www.aclweb.org/anthology/W18-6511\",",
        "year": "\"2018\","
    },
    "clark2017simple": {
        "abstract": "We consider the problem of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Our proposed solution trains models to produce well calibrated confidence scores for their results on individual paragraphs. We sample multiple paragraphs from the documents during training, and use a shared-normalization training objective that encourages the model to produce globally correct output. We combine this method with a state-of-the-art pipeline for training models on document QA data. Experiments demonstrate strong performance on several document QA datasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion of TriviaQA, a large improvement from the 56.7 F1 of the previous best system.",
        "author": "Clark, Christopher and Gardner, Matt",
        "booktitle": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "keywords": "Main topic:NLP,Experiments data:real , RC, TQA, Multi-hop,  AI",
        "pages": "845--855",
        "title": "Simple and Effective Multi-Paragraph Reading Comprehension",
        "type": "inproceedings",
        "year": "2017"
    },
    "clark2018simple": {
        "abstract": "We introduce a method of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Most current question answering models cannot scale to document or multi-document input, and naively applying these models to each paragraph independently often results in them being distracted by irrelevant text. We show that it is possible to significantly improve performance by using a modified training scheme that teaches the model to ignore non-answer containing paragraphs. Our method involves sampling multiple paragraphs from each document, and using an objective function that requires the model to produce globally correct output. We additionally identify and improve upon a number of other design decisions that arise when working with document-level data. Experiments on TriviaQA and SQuAD shows our method advances the state of the art, including a 10 point gain on TriviaQA.",
        "author": "Clark, Christopher and Gardner, Matt",
        "booktitle": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "keywords": "  Main topic:NLP,TQA , Experiments data:real , RC, AI , Multi-hop",
        "pages": "845--855",
        "title": "Simple and Effective Multi-Paragraph Reading Comprehension",
        "type": "inproceedings",
        "year": "2018"
    },
    "clark2019electra": {
        "abstract": "Masked language modeling (MLM) pre-training methods such as BERT corrupt the input by replacing some tokens with [MASK] and then train a model to reconstruct the original tokens. While they produce good results when transferred to downstream NLP tasks, they generally require large amounts of compute to be effective. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the task is defined over all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by BERT given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where it performs comparably to RoBERTa and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute.",
        "author": "Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D",
        "booktitle": "International Conference on Learning Representations",
        "keywords": "Main topic:NLP, Language-Model,Experiments data:real , AI",
        "title": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators",
        "type": "inproceedings",
        "year": "2019"
    },
    "ctan": {
        "author": "\"George D. Greenwade\",",
        "journal": "\"TUGBoat\",",
        "keywords": "\"latex\"",
        "number": "\"3\",",
        "pages": "\"342--351\",",
        "title": "\"The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})\",",
        "type": "article",
        "volume": "\"14\",",
        "year": "\"1993\","
    },
    "cui2019fast": {
        "author": "Cui, Jiequan and Chen, Pengguang and Li, Ruiyu and Liu, Shu and Shen, Xiaoyong and Jia, Jiaya",
        "booktitle": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "6509--6518",
        "title": "Fast and practical neural architecture search",
        "type": "InProceedings",
        "year": "2019"
    },
    "devlin2018bert": {
        "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\\% (7.7\\% point absolute improvement), MultiNLI accuracy to 86.7\\% (4.6\\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
        "author": "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina",
        "journal": "arXiv preprint arXiv:1810.04805",
        "keywords": "  Main topic:NLP,Experiments data:real ,  QA, Language-Model, AI",
        "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "type": "article",
        "year": "2018"
    },
    "dhingra2017quasar": {
        "abstract": "We present two new large-scale datasets aimed at evaluating systems designed to comprehend a natural language query and extract its answer from a large corpus of text. The Quasar-S dataset consists of 37000 cloze-style (fill-in-the-gap) queries constructed from definitions of software entity tags on the popular website Stack Overflow. The posts and comments on the website serve as the background corpus for answering the cloze questions. The Quasar-T dataset consists of 43000 open-domain trivia questions and their answers obtained from various internet sources. ClueWeb09 serves as the background corpus for extracting these answers. We pose these datasets as a challenge for two related subtasks of factoid Question Answering: (1) searching for relevant pieces of text that include the correct answer to a query, and (2) reading the retrieved text to answer the query. We also describe a retrieval system for extracting relevant sentences and documents from the corpus given a query, and include these in the release for researchers wishing to only focus on (2). We evaluate several baselines on both datasets, ranging from simple heuristics to powerful neural models, and show that these lag behind human performance by 16.4\\% and 32.1\\% for Quasar-S and -T respectively. The datasets are available at https://github.com/bdhingra/quasar",
        "author": "Dhingra, Bhuwan and Mazaitis, Kathryn and Cohen, William W",
        "journal": "arXiv preprint arXiv:1707.03904",
        "keywords": "Main topic:NLP,   Experiments data:real , dataset:Quasar, QA, AI",
        "title": "Quasar: Datasets for question answering by search and reading",
        "type": "article",
        "year": "2017"
    },
    "diefenbach2018core": {
        "abstract": "The Semantic Web contains an enormous amount of information in the form of knowledge bases (KB). To make this information available, many question answering (QA) systems over KBs were created in the last years. Building a QA system over KBs is difficult because there are many different challenges to be solved. In order to address these challenges, QA systems generally combine techniques from natural language processing, information retrieval, machine learning and Semantic Web. The aim of this survey is to give an overview of the techniques used in current QA systems over KBs. We present the techniques used by the QA systems which were evaluated on a popular series of benchmarks: Question Answering over Linked Data. Techniques that solve the same task are first grouped together and then described. The advantages and disadvantages are discussed for each technique. This allows a direct comparison of similar techniques. Additionally, we point to techniques that are used over WebQuestions and SimpleQuestions, which are two other popular benchmarks for QA systems.",
        "author": "Diefenbach, Dennis and Lopez, Vanessa and Singh, Kamal and Maret, Pierre",
        "journal": "Knowledge and Information systems",
        "keywords": "KB, Main topic:NLP, QA, AI",
        "number": "3",
        "pages": "529--569",
        "publisher": "Springer",
        "title": "Core techniques of question answering systems over knowledge bases: a survey",
        "type": "article",
        "volume": "55",
        "year": "2018"
    },
    "domhan2015speeding": {
        "author": "Domhan, Tobias and Springenberg, Jost Tobias and Hutter, Frank",
        "booktitle": "Twenty-fourth international joint conference on artificial intelligence",
        "keywords": "Main topic:AutoML, AI, Main topic:AutoML, AI",
        "title": "Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves",
        "type": "InProceedings",
        "year": "2015"
    },
    "dong2019one": {
        "author": "Dong, Xuanyi and Yang, Yi",
        "booktitle": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "3681--3690",
        "title": "One-shot neural architecture search via self-evaluated template network",
        "type": "InProceedings",
        "year": "2019"
    },
    "dong2019searching": {
        "author": "Dong, Xuanyi and Yang, Yi",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "1761--1770",
        "title": "Searching for a robust neural architecture in four gpu hours",
        "type": "InProceedings",
        "year": "2019"
    },
    "dong2020fast": {
        "author": "Dong, Xiaoyun and Niu, Jianwei and Cui, Jiahe and Fu, Zongkai and Ouyang, Zhenchao",
        "booktitle": "International Conference on Algorithms and Architectures for Parallel Processing",
        "organization": "Springer",
        "pages": "259--273",
        "title": "Fast Segmentation-Based Object Tracking Model for Autonomous Vehicles",
        "type": "inproceedings",
        "year": "2020"
    },
    "ehsan2020human": {
        "abstract": "Explanations--a form of post-hoc interpretability--play an instrumental role in making systems accessible as AI continues to proliferate complex and sensitive sociotechnical systems. In this paper, we introduce Human-centered Explainable AI (HCXAI) as an approach that puts the human at the center of technology design. It develops a holistic understanding of \"who\" the human is by considering the interplay of values, interpersonal dynamics, and the socially situated nature of AI systems. In particular, we advocate for a reflective sociotechnical approach. We illustrate HCXAI through a case study of an explanation system for non-technical end-users that shows how technical advancements and the understanding of human factors co-evolve. Building on the case study, we lay out open research questions pertaining to further refining our understanding of \"who\" the human is and extending beyond 1-to-1 human-computer interactions. Finally, we propose that a reflective HCXAI paradigm-mediated through the perspective of Critical Technical Practice and supplemented with strategies from HCI, such as value-sensitive design and participatory design--not only helps us understand our intellectual blind spots, but it can also open up new design and research spaces.",
        "author": "Ehsan, Upol and Riedl, Mark O",
        "journal": "arXiv preprint arXiv:2002.01092",
        "keywords": "Main topic:XAI",
        "title": "Human-centered Explainable AI: Towards a Reflective Sociotechnical Approach",
        "type": "article",
        "year": "2020"
    },
    "elsken2018efficient": {
        "author": "Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank",
        "journal": "arXiv preprint arXiv:1804.09081",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Efficient multi-objective neural architecture search via lamarckian evolution",
        "type": "Article",
        "year": "2018"
    },
    "emmert2020explainable": {
        "abstract": "We are used to the availability of big data generated in nearly all fields of science as a consequence of technological progress. However, the analysis of such data possess vast challenges. One of these relates to the explainability of artificial intelligence (AI) or machine learning methods. Currently, many of such methods are non-transparent with respect to their working mechanism and for this reason are called black box models, most notably deep learning methods. However, it has been realized that this constitutes severe problems for a number of fields including the health sciences and criminal justice and arguments have been brought forward in favor of an explainable AI. In this paper, we do not assume the usual perspective presenting explainable AI as it should be, but rather we provide a discussion what explainable AI can be. The difference is that we do not present wishful thinking but reality grounded properties in relation to a scientific theory beyond physics.",
        "author": "Emmert-Streib, Frank and Yli-Harja, Olli and Dehmer, Matthias",
        "journal": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery",
        "keywords": "Main topic:XAI",
        "number": "6",
        "pages": "e1368",
        "publisher": "Wiley Online Library",
        "title": "Explainable artificial intelligence and machine learning: A reality rooted perspective",
        "type": "article",
        "volume": "10",
        "year": "2020"
    },
    "esposito2020hybrid": {
        "abstract": "Question Answering (QA) systems based on Information Retrieval return precise answers to natural language questions, extracting relevant sentences from document collections. However, questions and sentences cannot be aligned terminologically, generating errors in the sentence retrieval. In order to augment the effectiveness in retrieving relevant sentences from documents, this paper proposes a hybrid Query Expansion (QE) approach, based on lexical resources and word embeddings, for QA systems. In detail, synonyms and hypernyms of relevant terms occurring in the question are first extracted from MultiWordNet and, then, contextualized to the document collection used in the QA system. Finally, the resulting set is ranked and filtered on the basis of wording and sense of the question, by employing a semantic similarity metric built on the top of a Word2Vec model. This latter is locally trained on an extended corpus pertaining the same topic of the documents used in the QA system. This QE approach is implemented into an existing QA system and experimentally evaluated, with respect to different possible configurations and selected baselines, for the Italian language and in the Cultural Heritage domain, assessing its effectiveness in retrieving sentences containing proper answers to questions belonging to four different categories.",
        "author": "Esposito, Massimo and Damiano, Emanuele and Minutolo, Aniello and De Pietro, Giuseppe and Fujita, Hamido",
        "journal": "Information Sciences",
        "keywords": " Main topic:NLP, QA, AI",
        "pages": "88--105",
        "publisher": "Elsevier",
        "title": "Hybrid query expansion using lexical resources and word embeddings for sentence retrieval in question answering",
        "type": "article",
        "volume": "514",
        "year": "2020"
    },
    "faes2019automated": {
        "abstract": "Deep learning has the potential to transform health care; however, substantial expertise is required to train such models. We sought to evaluate the utility of automated deep learning software to develop medical image diagnostic classifiers by health-care professionals with no coding\u2014and no deep learning\u2014expertise.",
        "author": "Faes, Livia and Wagner, Siegfried K and Fu, Dun Jack and Liu, Xiaoxuan and Korot, Edward and Ledsam, Joseph R and Back, Trevor and Chopra, Reena and Pontikos, Nikolas and Kern, Christoph and others",
        "journal": "The Lancet Digital Health",
        "keywords": "Main topic:AutoML, AI, application :healthcare",
        "number": "5",
        "pages": "e232--e242",
        "publisher": "Elsevier",
        "title": "Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study",
        "type": "Article",
        "volume": "1",
        "year": "2019"
    },
    "feldman2019multi": {
        "abstract": "This paper is concerned with the task of multi-hop open-domain Question Answering (QA). This task is particularly challenging since it requires the simultaneous performance of textual reasoning and efficient searching. We present a method for retrieving multiple supporting paragraphs, nested amidst a large knowledge base, which contain the necessary evidence to answer a given question. Our method iteratively retrieves supporting paragraphs by forming a joint vector representation of both a question and a paragraph. The retrieval is performed by considering contextualized sentence-level representations of the paragraphs in the knowledge source. Our method achieves state-of-the-art performance over two well-known datasets, SQuAD-Open and HotpotQA, which serve as our single- and multi-hop open-domain QA benchmarks, respectively.",
        "author": "Feldman, Yair and El-Yaniv, Ran",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": " Main topic:NLP, Experiments data:real ,  TBQA, AI",
        "pages": "2296--2309",
        "title": "Multi-Hop Paragraph Retrieval for Open-Domain Question Answering",
        "type": "inproceedings",
        "year": "2019"
    },
    "feng2020deep": {
        "author": "Feng, Di and Haase-Schuetz, Christian and Rosenbaum, Lars and Hertlein, Heinz and Glaeser, Claudius and Timm, Fabian and Wiesbeck, Werner and Dietmayer, Klaus",
        "journal": "IEEE Transactions on Intelligent Transportation Systems",
        "publisher": "IEEE",
        "title": "Deep multi-modal object detection and semantic segmentation for autonomous driving: Datasets, methods, and challenges",
        "type": "article",
        "year": "2020"
    },
    "floreano2008neuroevolution": {
        "author": "Floreano, Dario and D{\\\"u}rr, Peter and Mattiussi, Claudio",
        "journal": "Evolutionary intelligence",
        "keywords": "Main topic:AutoML, AI",
        "number": "1",
        "pages": "47--62",
        "publisher": "Springer",
        "title": "Neuroevolution: from architectures to learning",
        "type": "Article",
        "volume": "1",
        "year": "2008"
    },
    "folkers2019controlling": {
        "author": "Folkers, Andreas and Rick, Matthias and B{\\\"u}skens, Christof",
        "booktitle": "2019 IEEE Intelligent Vehicles Symposium (IV)",
        "organization": "IEEE",
        "pages": "2025--2031",
        "title": "Controlling an autonomous vehicle with deep reinforcement learning",
        "type": "inproceedings",
        "year": "2019"
    },
    "gartner2019": {
        "addendum": "\"(accessed: 02.13.2021)\",",
        "author": "\" David, Smith and Brian, Burke \",",
        "keywords": "\"gartner,hypecycle 2019\"",
        "title": "\"Hype Cycle for Emerging Technologies, 2019 \",",
        "type": "online",
        "url": "\"https://www.gartner.com/en/documents/3956015/hype-cycle-for-emerging-technologies-2019\","
    },
    "gartner2019b": {
        "addendum": "\"(accessed: 02.13.2021)\",",
        "author": "\"  Svetlana Sicular ,  Jim Hare ,  Kenneth Brant\",",
        "keywords": "\"gartner, AI, hypecycle 2019\"",
        "title": "\"Hype Cycle for Artificial Intelligence, 2019 \",",
        "type": "online",
        "url": "\"https://www.gartner.com/en/documents/3953603/hype-cycle-for-artificial-intelligence-2019\","
    },
    "gartner2020": {
        "addendum": "\"(accessed: 02.13.2021)\",",
        "author": "\" Kasey Panetta\",",
        "keywords": "\"gartner,hypecycle 2019\"",
        "title": "\"5 Trends Drive the Gartner Hype Cycle for Emerging Technologies, 2020\",",
        "type": "online",
        "url": "\"https://www.gartner.com/smarterwithgartner/5-trends-drive-the-gartner-hype-cycle-for-emerging-technologies-2020/\","
    },
    "gastaldi2017shake": {
        "author": "Gastaldi, Xavier",
        "journal": "arXiv preprint arXiv:1705.07485",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Shake-shake regularization",
        "type": "Article",
        "year": "2017"
    },
    "glomsrud2019trustworthy": {
        "abstract": "Trust, the firm belief in the reliability, truth, or ability of someone or something, underlies all social and economic relations and is central for the acceptance and adoption of autonomous vessels both by the maritime community and the general public. Trust requires explanations but is a much broader concept facilitating interaction among people and between people and technologies. Autonomous vessels are facilitated by artificial intelligence (AI), automating tasks previously performed by people, meaning that roles, responsibility, authority and decision making are delegated to data and algorithms. The need for trust, however, remains unchanged, but people become dependent as well as changed by these technologies. Simultaneously, multiple layers of interaction between people and technologies will likely continue to exist. People need valid explanations and causal reasoning for trusting critical, surprising or unexpected behaviour or decision making, also in the context of autonomous vessels, as incorrect behaviours or decisions can quickly translate into critical consequences. Such trust also depends on technical assurance processes where we emphasize that explanations can and need to play a role as valid evidence. We argue that the current methods for explaining AI are insufficient in providing trust in autonomous vessels and are too narrowly framed towards developers of AI. With the multiple points of interaction between people and autonomy, we argue that it is urgent to identify and mature explanation methods suitable for all types of interactions during development, assurance or operation. Explanations should be adapted to roles and responsibilities, and aspects such as context, cognitive skills, alertness, contextual knowledge, and time available to act by the user. We propose four types of explanations to suit the developer, assurance, end-user, and external explanation needs, which must be mapped out before the design such that trustworthy, interacting autonomous vessels can emerge.",
        "author": "Glomsrud, Jon Arne and {\\O}deg{\\aa}rdstuen, Andr{\\'e} and Clair, Asun Lera St and Smogeli, {\\O}yvind",
        "booktitle": "Proceedings of the International Seminar on Safety and Security of Autonomous Vessels (ISSAV) and European STAMP Workshop and Conference (ESWC)",
        "keywords": "Main topic:XAI, AI",
        "pages": "37--47",
        "title": "Trustworthy versus explainable AI in autonomous vessels",
        "type": "inproceedings",
        "year": "2019"
    },
    "gu2021chaincqg": {
        "abstract": "    Conversational systems enable numerous valuable applications, and question-answering is an important component underlying many of these. However, conversational question-answering remains challenging due to the lack of realistic, domain-specific training data. Inspired by this bottleneck, we focus on conversational question generation as a means to generate synthetic conversations for training and evaluation purposes. We present a number of novel strategies to improve conversational flow and accommodate varying question types and overall fluidity. Specifically, we design ChainCQG as a two-stage architecture that learns question-answer representations across multiple dialogue turns using a flow propagation training strategy.ChainCQG significantly outperforms both answer-aware and answer-unaware SOTA baselines (e.g., up to 48\\% BLEU-1 improvement). Additionally, our model is able to generate different types of questions, with improved fluidity and coreference alignment.",
        "author": "Gu, Jing and Mirshekari, Mostafa and Yu, Zhou and Sisto, Aaron",
        "booktitle": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
        "keywords": "Main topic:NLP,   Experiments data:real , CQA",
        "pages": "2061--2070",
        "title": "ChainCQG: Flow-Aware Conversational Question Generation",
        "type": "inproceedings",
        "year": "2021"
    },
    "guo2019irlas": {
        "author": "Guo, Minghao and Zhong, Zhao and Wu, Wei and Lin, Dahua and Yan, Junjie",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "keywords": "Main topic:AutoML, AI",
        "pages": "9021--9029",
        "title": "Irlas: Inverse reinforcement learning for architecture search",
        "type": "InProceedings",
        "year": "2019"
    },
    "guo2020explainable": {
        "abstract": "As the 5th Generation (5G) mobile networks are bringing about global societal benefits, the design phase for the 6th Generation (6G) has started. 6G will need to enable greater levels of autonomy, improve human machine interfacing, and achieve deep connectivity in more diverse environments. The need for increased explainability to enable trust is critical for 6G as it manages a wide range of mission critical services (e.g. autonomous driving) to safety critical tasks (e.g. remote surgery). As we migrate from traditional model-based optimisation to deep learning, the trust we have in our optimisation modules decrease. This loss of trust means we cannot understand the impact of: 1) poor/bias/malicious data, and 2) neural network design on decisions; nor can we explain to the engineer or the public the network's actions. In this review, we outline the core concepts of Explainable Artificial Intelligence (XAI) for 6G, including: public and legal motivations, definitions of explainability, performance vs. explainability trade-offs, methods to improve explainability, and frameworks to incorporate XAI into future wireless systems. Our review is grounded in cases studies for both PHY and MAC layer optimisation, and provide the community with an important research area to embark upon.",
        "author": "Guo, Weisi",
        "journal": "IEEE Communications Magazine",
        "keywords": "Main topic:XAI",
        "number": "6",
        "pages": "39--45",
        "publisher": "IEEE",
        "title": "Explainable artificial intelligence for 6G: Improving trust between human and machine",
        "type": "article",
        "volume": "58",
        "year": "2020"
    },
    "gurumoorthy2019efficient": {
        "abstract": "Prototypical examples that best summarizes and compactly represents an underlying complex data distribution communicate meaningful insights to humans in domains where simple explanations are hard to extract. In this paper we present algorithms with strong theoretical guarantees to mine these data sets and select prototypes a.k.a. representatives that optimally describes them. Our work notably generalizes the recent work by Kim et al. (2016) where in addition to selecting prototypes, we also associate non-negative weights which are indicative of their importance. This extension provides a single coherent framework under which both prototypes and criticisms (i.e. outliers) can be found. Furthermore, our framework works for any symmetric positive definite kernel thus addressing one of the key open questions laid out in Kim et al. (2016). By establishing that our objective function enjoys a key property of that of weak submodularity, we present a fast ProtoDash algorithm and also derive approximation guarantees for the same. We demonstrate the efficacy of our method on diverse domains such as retail, digit recognition (MNIST) and on publicly available 40 health questionnaires obtained from the Center for Disease Control (CDC) website maintained by the US Dept. of Health. We validate the results quantitatively as well as qualitatively based on expert feedback and recently published scientific studies on public health, thus showcasing the power of our technique in providing actionability (for retail), utility (for MNIST) and insight (on CDC datasets) which arguably are the hallmarks of an effective data mining method.",
        "author": "Gurumoorthy, Karthik S and Dhurandhar, Amit and Cecchi, Guillermo and Aggarwal, Charu",
        "booktitle": "2019 IEEE International Conference on Data Mining (ICDM)",
        "keywords": "Main topic:XAI, AI",
        "organization": "IEEE",
        "pages": "260--269",
        "title": "Efficient data representation by selecting prototypes with importance weights",
        "type": "inproceedings",
        "year": "2019"
    },
    "guu2020realm": {
        "abstract": "Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16\\% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.",
        "author": "Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei",
        "journal": "arXiv preprint arXiv:2002.08909",
        "keywords": " Main topic:NLP,Experiments data:real ,  QA , IR, AI",
        "title": "Realm: Retrieval-augmented language model pre-training",
        "type": "article",
        "year": "2020"
    },
    "han2017deep": {
        "author": "Han, Dongyoon and Kim, Jiwhan and Kim, Junmo",
        "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "5927--5935",
        "title": "Deep pyramidal residual networks",
        "type": "InProceedings",
        "year": "2017"
    },
    "hancock2019learning": {
        "abstract": " The majority of conversations a dialogue agent sees over its lifetime occur after it has already been trained and deployed, leaving a vast store of potential training signal untapped. In this work, we propose the self-feeding chatbot, a dialogue agent with the ability to extract new training examples from the conversations it participates in. As our agent engages in conversation, it also estimates user satisfaction in its responses. When the conversation appears to be going well, the user's responses become new training examples to imitate. When the agent believes it has made a mistake, it asks for feedback; learning to predict the feedback that will be given improves the chatbot's dialogue abilities further. On the PersonaChat chit-chat dataset with over 131k training examples, we find that learning from dialogue with a self-feeding chatbot significantly improves performance, regardless of the amount of traditional supervision.",
        "author": "Hancock, Braden and Bordes, Antoine and Mazar{\\'e Pierre-Emmanuel and Weston, Jason",
        "booktitle": "ACL (1)",
        "keywords": "Main topic:NLP, Experiments data:real , dialogue-systems,  AI",
        "title": "Learning from Dialogue after Deployment: Feed Yourself, Chatbot!",
        "type": "inproceedings",
        "year": "2019"
    },
    "he2016deep": {
        "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
        "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "770--778",
        "title": "Deep residual learning for image recognition",
        "type": "InProceedings",
        "year": "2016"
    },
    "he2016identity": {
        "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
        "booktitle": "European conference on computer vision",
        "keywords": "Main topic:AutoML, AI",
        "organization": "Springer",
        "pages": "630--645",
        "title": "Identity mappings in deep residual networks",
        "type": "InProceedings",
        "year": "2016"
    },
    "he2020milenas": {
        "author": "He, Chaoyang and Ye, Haishan and Shen, Li and Zhang, Tong",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "11993--12002",
        "title": "Milenas: Efficient neural architecture search via mixed-level reformulation",
        "type": "InProceedings",
        "year": "2020"
    },
    "he2021noniid": {
        "abstract": "Federated Learning (FL) has been proved to be an effective learning framework when data cannot be centralized due to privacy, communication costs, and regulatory restrictions. When training deep learning models under an FL setting, people employ the predefined model architecture discovered in the centralized environment. However, this predefined architecture may not be the optimal choice because it may not fit data with non-identical and independent distribution (non-IID). Thus, we advocate automating federated learning (AutoFL) to improve model accuracy and reduce the manual design effort. We specifically study AutoFL via Neural Architecture Search (NAS), which can automate the design process. We propose a Federated NAS (FedNAS) algorithm to help scattered workers collaboratively searching for a better architecture with higher accuracy. We also build a system based on FedNAS. Our experiments on non-IID dataset show that the architecture searched by FedNAS can outperform the manually predefined architecture.",
        "archiveprefix": "arXiv",
        "author": "Chaoyang He and Murali Annavaram and Salman Avestimehr",
        "eprint": "2004.08546",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "primaryclass": "cs.LG",
        "title": "Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep Learning via Neural Architecture Search",
        "type": "Misc",
        "year": "2021"
    },
    "henderson2019training": {
        "abstract": "application being the low-data regime of most task-oriented dialogue tasks. Inspired by the recent success of pretraining in language modelling, we propose an effective method for deploying response selection in task-oriented dialogue. To train response selection models for task-oriented dialogue tasks, we propose a novel method which: 1) pretrains the response selection model on large general-domain conversational corpora; and then 2) fine-tunes the pretrained model for the target dialogue domain, relying only on the small in-domain dataset to capture the nuances of the given dialogue domain. Our evaluation on six diverse application domains, ranging from e-commerce to banking, demonstrates the effectiveness of the proposed training method.",
        "author": "Henderson, Matthew and Vuli{\\'c Ivan and Gerz, Daniela and Casanueva, I{\\~n}igo and Budzianowski, Pawe{\\l} and Coope, Sam and Spithourakis, Georgios and Wen, Tsung-Hsien and Mrk{\\v{s}}i{\\'c Nikola and Su, Pei-Hao",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP, Experiments data:real , dialogue-systems,  AI",
        "pages": "5392--5404",
        "title": "Training Neural Response Selection for Task-Oriented Dialogue Systems",
        "type": "inproceedings",
        "year": "2019"
    },
    "herzig2021open": {
        "abstract": "Recent advances in open-domain QA have led to strong models based on dense retrieval, but only focused on retrieving textual passages. In this work, we tackle open-domain QA over tables for the first time, and show that retrieval can be improved by a retriever designed to handle tabular context. We present an effective pre-training procedure for our retriever and improve retrieval quality with mined hard negatives. As relevant datasets are missing, we extract a subset of Natural Questions (Kwiatkowski et al., 2019) into a Table QA dataset. We find that our retriever improves retrieval results from 72.0 to 81.1 recall@10 and end-to-end QA results from 33.8 to 37.7 exact match, over a BERT based retriever.",
        "author": "Herzig, Jonathan and M{\\\"u}ller, Thomas and Krichene, Syrine and Eisenschlos, Julian Martin",
        "journal": "arXiv e-prints",
        "keywords": "Main topic:NLP,   Experiments data:real , QA",
        "pages": "arXiv--2103",
        "title": "Open Domain Question Answering over Tables via Dense Retrieval",
        "type": "article",
        "year": "2021"
    },
    "hind2019ted": {
        "abstract": "Artificial intelligence systems are being increasingly deployed due to their potential to increase the efficiency, scale, consistency, fairness, and accuracy of decisions. However, as many of these systems are opaque in their operation, there is a growing demand for such systems to provide explanations for their decisions. Conventional approaches to this problem attempt to expose or discover the inner workings of a machine learning model with the hope that the resulting explanations will be meaningful to the consumer. In contrast, this paper suggests a new approach to this problem. It introduces a simple, practical framework, called Teaching Explanations for Decisions (TED), that provides meaningful explanations that match the mental model of the consumer. We illustrate the generality and effectiveness of this approach with two different examples, resulting in highly accurate explanations with no loss of prediction accuracy for these two examples.",
        "author": "Hind, Michael and Wei, Dennis and Campbell, Murray and Codella, Noel CF and Dhurandhar, Amit and Mojsilovi{\\'c Aleksandra and Natesan Ramamurthy, Karthikeyan and Varshney, Kush R",
        "booktitle": "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society",
        "keywords": "Main topic:XAI, AI",
        "pages": "123--129",
        "title": "TED: Teaching AI to explain its decisions",
        "type": "inproceedings",
        "year": "2019"
    },
    "hodge2021deep": {
        "author": "Hodge, Victoria J and Hawkins, Richard and Alexander, Rob",
        "journal": "Neural Computing and Applications",
        "number": "6",
        "pages": "2015--2033",
        "publisher": "Springer",
        "title": "Deep reinforcement learning for drone navigation using sensor data",
        "type": "article",
        "volume": "33",
        "year": "2021"
    },
    "hohman2019gamut": {
        "abstract": "Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data.",
        "author": "Hohman, Fred and Head, Andrew and Caruana, Rich and DeLine, Robert and Drucker, Steven M",
        "booktitle": "Proceedings of the 2019 CHI conference on human factors in computing systems",
        "keywords": "Main topic:XAI, AI",
        "pages": "1--13",
        "title": "Gamut: A design probe to understand how data scientists understand machine learning models",
        "type": "inproceedings",
        "year": "2019"
    },
    "holen2020road": {
        "author": "Holen, Martin and Saha, Rupsa and Goodwin, Morten and Omlin, Christian W and Sandsmark, Knut Eivind",
        "booktitle": "Proceedings of the 2020 The 3rd International Conference on Information Science and System",
        "pages": "67--71",
        "title": "Road detection for reinforcement learning based autonomous car",
        "type": "inproceedings",
        "year": "2020"
    },
    "horn2001autonomic": {
        "author": "\"Horn, Paul\",",
        "keywords": "application:, architecture: ,adaptability: {Self-configuration, Self-protection, Self-optimization, Self-healing} , Experiments data: ,dataset: , concentration: , Main topic:ASs",
        "publisher": "\"New York\"",
        "title": "\"Autonomic computing: IBM\u2019s perspective on the state of information technology\",",
        "type": "article",
        "year": "\"2001\","
    },
    "huang2017densely": {
        "author": "Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q",
        "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "4700--4708",
        "title": "Densely connected convolutional networks",
        "type": "InProceedings",
        "year": "2017"
    },
    "huang2020tracking": {
        "author": "\"Arnold, Zachary and Rahkovsky, Ilya and Huang, Tina\",",
        "title": "\"Tracking AI Investment\",",
        "type": "article",
        "year": "\"2020\""
    },
    "hundt2019sharpdarts": {
        "author": "Hundt, Andrew and Jain, Varun and Hager, Gregory D",
        "journal": "arXiv preprint arXiv:1903.09900",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "sharpdarts: Faster and more accurate differentiable architecture search",
        "type": "Article",
        "year": "2019"
    },
    "hussain2021explainable": {
        "abstract": "The remarkable advancements in Deep Learning (DL) algorithms have fueled enthusiasm for using Artificial Intelligence (AI) technologies in almost every domain; however, the opaqueness of these algorithms put a question mark on their applications in safety-critical systems. In this regard, the `explainability' dimension is not only essential to both explain the inner workings of black-box algorithms, but it also adds accountability and transparency dimensions that are of prime importance for regulators, consumers, and service providers. eXplainable Artificial Intelligence (XAI) is the set of techniques and methods to convert the so-called black-box AI algorithms to white-box algorithms, where the results achieved by these algorithms and the variables, parameters, and steps taken by the algorithm to reach the obtained results, are transparent and explainable. To complement the existing literature on XAI, in this paper, we take an `engineering' approach to illustrate the concepts of XAI. We discuss the stakeholders in XAI and describe the mathematical contours of XAI from engineering perspective. Then we take the autonomous car as a use-case and discuss the applications of XAI for its different components such as object detection, perception, control, action decision, and so on. This work is an exploratory study to identify new avenues of research in the field of XAI.",
        "author": "Hussain, F and Hussain, R and Hossain, E",
        "journal": "arXiv preprint arXiv:2101.03613",
        "keywords": "Main topic:XAI",
        "title": "Explainable Artificial Intelligence (XAI): An Engineering Perspective",
        "type": "article",
        "year": "2021"
    },
    "ijcai2019-876": {
        "abstract": "Counterfactuals about what could have happened are increasingly used in an array of Artificial Intelligence (AI) applications, and especially in explainable AI (XAI). Counterfactuals can aid the provision of interpretable models to make the decisions of inscrutable systems intelligible to developers and users. However, not all counterfactuals are equally helpful in assisting human comprehension. Discoveries about the nature of the counterfactuals that humans create are a helpful guide to maximize the effectiveness of counterfactual use in AI.",
        "author": "Byrne, Ruth M. J.",
        "booktitle": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, {IJCAI-19}",
        "doi": "10.24963/ijcai.2019/876",
        "keywords": "Main topic:XAI, AI",
        "month": "7",
        "pages": "6276--6282",
        "publisher": "International Joint Conferences on Artificial Intelligence Organization",
        "title": "Counterfactuals in Explainable Artificial Intelligence (XAI): Evidence from Human Reasoning",
        "type": "inproceedings",
        "url": "https://doi.org/10.24963/ijcai.2019/876",
        "year": "2019"
    },
    "imagenet_cvpr09": {
        "author": "Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.",
        "bibsource": "http://www.image-net.org/papers/imagenet_cvpr09.bib",
        "booktitle": "CVPR09",
        "keywords": "Main topic:AutoML, AI, dataset",
        "title": "{ImageNet: A Large-Scale Hierarchical Image Database}",
        "type": "InProceedings",
        "year": "2009"
    },
    "isola2017image": {
        "author": "Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A",
        "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
        "pages": "1125--1134",
        "title": "Image-to-image translation with conditional adversarial networks",
        "type": "inproceedings",
        "year": "2017"
    },
    "izacard2020leveraging": {
        "abstract": "Generative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can benefit from retrieving text passages, potentially containing evidence. We obtain state-of-the-art results on the Natural Questions and TriviaQA open benchmarks. Interestingly, we observe that the performance of this method significantly improves when increasing the number of retrieved passages. This is evidence that generative models are good at aggregating and combining evidence from multiple passages.",
        "author": "Izacard, Gautier and Grave, Edouard",
        "journal": "arXiv preprint arXiv:2007.01282",
        "keywords": "Main topic:NLP,   Experiments data:real , IR, QA, AI",
        "title": "Leveraging passage retrieval with generative models for open domain question answering",
        "type": "article",
        "year": "2020"
    },
    "jimenez2020drug": {
        "abstract": "Deep learning bears promise for drug discovery, including advanced image analysis, prediction of molecular structure and function, and automated generation of innovative chemical entities with bespoke properties. Despite the growing number of successful prospective applications, the underlying mathematical models often remain elusive to interpretation by the human mind. There is a demand for 'explainable' deep learning methods to address the need for a new narrative of the machine language of the molecular sciences. This review summarizes the most prominent algorithmic concepts of explainable artificial intelligence, and dares a forecast of the future opportunities, potential applications, and remaining challenges.",
        "author": "Jim{\\'e}nez-Luna, Jos{\\'e} and Grisoni, Francesca and Schneider, Gisbert",
        "journal": "Nature Machine Intelligence",
        "keywords": "Main topic:XAI",
        "number": "10",
        "pages": "573--584",
        "publisher": "Nature Publishing Group",
        "title": "Drug discovery with explainable artificial intelligence",
        "type": "article",
        "volume": "2",
        "year": "2020"
    },
    "jin2019auto": {
        "author": "Jin, Haifeng and Song, Qingquan and Hu, Xia",
        "booktitle": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining",
        "keywords": "Main topic:AutoML, AI",
        "pages": "1946--1956",
        "title": "Auto-keras: An efficient neural architecture search system",
        "type": "InProceedings",
        "year": "2019"
    },
    "joshi2017triviaqa": {
        "abstract": "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23\\% and 40\\% vs. 80\\%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at http://nlp.cs.washington.edu/triviaqa/. ,",
        "author": "Joshi, Mandar and Choi, Eunsol and Weld, Daniel S and Zettlemoyer, Luke",
        "booktitle": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "keywords": "Main topic:NLP, Experiments data:real , dataset:TriviaQA  , QA , RC, AI",
        "pages": "1601--1611",
        "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
        "type": "inproceedings",
        "year": "2017"
    },
    "joshi2020spanbert": {
        "abstract": "We present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms BERT and our better-tuned baselines, with substantial gains on span selection tasks such as question answering and coreference resolution. In particular, with the same training data and model size as BERTlarge, our single model obtains 94.6\\% and 88.7\\% F1 on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6\\% F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE.",
        "author": "Joshi, Mandar and Chen, Danqi and Liu, Yinhan and Weld, Daniel S and Zettlemoyer, Luke and Levy, Omer",
        "journal": "Transactions of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP,   Experiments data:real , Language-Model,  AI",
        "pages": "64--77",
        "publisher": "MIT Press",
        "title": "Spanbert: Improving pre-training by representing and predicting spans",
        "type": "article",
        "volume": "8",
        "year": "2020"
    },
    "journals/PPNA/Weng21": {
        "abstract": "Deep learning has shown prominent superiority over other machine learning algorithms in Single Image Super-Resolution (SISR). In order to reduce the efforts and resources cost on manually designing deep architecture, we use differentiable neural architecture search (DARTS) on SISR. Since neural architecture search was originally used for classification tasks, our experiments show that direct usage of DARTS on super-resolutions tasks will give rise to many skip connections in the search architecture, which results in the poor performance of final architecture. Thus, it is necessary for DARTS to have made some improvements for the application in the field of SISR. According to characteristics of SISR, we remove redundant operations and redesign some operations in the cell to achieve an improved DARTS. Then we use the improved DARTS to search convolution cells as a nonlinear mapping part of super-resolution network. The new super-resolution architecture shows its effectiveness on benchmark datasets and DIV2K dataset.",
        "author": "Yu Weng and Zehua Chen and Tianbao Zhou",
        "date": "2021-01-01",
        "doi": "10.1007/s12083-020-01048-4",
        "journal": "Peer-to-Peer Networking and Applications",
        "keywords": "Main topic:AutoML, AI, application :industry",
        "pubstate": "published",
        "title": "Improved differentiable neural architecture search for single image super-resolution",
        "tppubtype": "article",
        "type": "Article",
        "url": "https://doi.org/10.1007/s12083-020-01048-4",
        "year": "2021"
    },
    "kandasamy2018neural": {
        "author": "Kandasamy, Kirthevasan and Neiswanger, Willie and Schneider, Jeff and Poczos, Barnabas and Xing, Eric",
        "journal": "Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Neural architecture search with bayesian optimisation and optimal transport",
        "type": "Article",
        "year": "2018"
    },
    "kaplan2019siri": {
        "author": "Kaplan, Andreas and Haenlein, Michael",
        "journal": "Business Horizons",
        "number": "1",
        "pages": "15--25",
        "publisher": "Elsevier",
        "title": "Siri, Siri, in my hand: Who\u2019s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence",
        "type": "article",
        "volume": "62",
        "year": "2019"
    },
    "karpukhin2020dense": {
        "abstract": "Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9\\%-19\\% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.",
        "author": "Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau",
        "booktitle": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
        "keywords": "  Main topic:NLP,Experiments data:real , QA , IR, AI",
        "pages": "6769--6781",
        "title": "Dense Passage Retrieval for Open-Domain Question Answering",
        "type": "inproceedings",
        "year": "2020"
    },
    "keane2020good": {
        "abstract": "Recently, a groundswell of research has identified the use of counterfactual explanations as a potentially significant solution to the Explainable AI (XAI) problem. It is argued that (a) technically, these counterfactual cases can be generated by permuting problem-features until a class change is found, (b) psychologically, they are much more causally informative than factual explanations, (c) legally, they are GDPR-compliant. However, there are issues around the finding of good counterfactuals using current techniques (e.g. sparsity and plausibility). We show that many commonly-used datasets appear to have few good counterfactuals for explanation purposes. So, we propose a new case based approach for generating counterfactuals using novel ideas about the counterfactual potential and explanatory coverage of a case-base. The new technique reuses patterns of good counterfactuals, present in a case-base, to generate analogous counterfactuals that can explain new problems and their solutions. Several experiments show how this technique can improve the counterfactual potential and explanatory coverage of case-bases that were previously found wanting.",
        "author": "Keane, Mark T and Smyth, Barry",
        "booktitle": "International Conference on Case-Based Reasoning",
        "keywords": "Main topic:XAI, AI",
        "organization": "Springer",
        "pages": "163--178",
        "title": "Good counterfactuals and where to find them: A case-based technique for generating counterfactuals for explainable ai (xai)",
        "type": "inproceedings",
        "year": "2020"
    },
    "kephart2003vision": {
        "author": "\"Kephart, Jeffrey O and Chess, David M\",",
        "journal": "\"Computer\",",
        "number": "\"1\",",
        "pages": "\"41--50\",",
        "publisher": "\"IEEE\"",
        "title": "\"The vision of autonomic computing\",",
        "type": "article",
        "volume": "\"36\",",
        "year": "\"2003\","
    },
    "khattab2020relevance": {
        "abstract": "    Systems for Open-Domain Question Answering (OpenQA) generally depend on a retriever for finding candidate passages in a large corpus and a reader for extracting answers from those passages. In much recent work, the retriever is a learned component that uses coarse-grained vector representations of questions and passages. We argue that this modeling choice is insufficiently expressive for dealing with the complexity of natural language questions. To address this, we define ColBERT-QA, which adapts the scalable neural retrieval model ColBERT to OpenQA. ColBERT creates fine-grained interactions between questions and passages. We propose a weak supervision strategy that iteratively uses ColBERT to create its own training data. This greatly improves OpenQA retrieval on both Natural Questions and TriviaQA, and the resulting end-to-end OpenQA system attains state-of-the-art performance on both of those datasets.",
        "author": "Khattab, Omar and Potts, Christopher and Zaharia, Matei",
        "journal": "arXiv preprint arXiv:2007.00814",
        "keywords": "Main topic:NLP,  Experiments data:real ,  QA, AI",
        "title": "Relevance-guided supervision for openqa with colbert",
        "type": "article",
        "year": "2020"
    },
    "kim2020choice": {
        "author": "Kim, Sang Hyun",
        "journal": "Journal of Air Transport Management",
        "pages": "101785",
        "publisher": "Elsevier",
        "title": "Choice model based analysis of consumer preference for drone delivery service",
        "type": "article",
        "volume": "84",
        "year": "2020"
    },
    "knuth-acp": {
        "author": "\"Donald E. Knuth\",",
        "keywords": "\"knuth,programming\"",
        "note": "\"Seven volumes planned\",",
        "publisher": "\"Addison-Wesley\",",
        "series": "\"Four volumes\",",
        "title": "\"The Art of Computer Programming\",",
        "type": "book",
        "year": "\"1968\","
    },
    "knuth-fa": {
        "author": "\"Donald E. Knuth\",",
        "chapter": "\"1.2\",",
        "keywords": "\"knuth,programming\"",
        "publisher": "\"Addison-Wesley\",",
        "title": "\"Fundamental Algorithms\",",
        "type": "inbook",
        "year": "\"1973\","
    },
    "kratzwald2019rankqa": {
        "abstract": "The conventional paradigm in neural question answering (QA) for narrative content is limited to a two-stage process: first, relevant text passages are retrieved and, subsequently, a neural network for machine comprehension extracts the likeliest answer. However, both stages are largely isolated in the status quo and, hence, information from the two phases is never properly fused. In contrast, this work proposes RankQA: RankQA extends the conventional two-stage process in neural QA with a third stage that performs an additional answer re-ranking. The re-ranking leverages different features that are directly extracted from the QA pipeline, i.e., a combination of retrieval and comprehension features. While our intentionally simple design allows for an efficient, data-sparse estimation, it nevertheless outperforms more complex QA systems by a significant margin: in fact, RankQA achieves state-of-the-art performance on 3 out of 4 benchmark datasets. Furthermore, its performance is especially superior in settings where the size of the corpus is dynamic. Here the answer re-ranking provides an effective remedy against the underlying noise-information trade-off due to a variable corpus size. As a consequence, RankQA represents a novel, powerful, and thus challenging baseline for future research in content-based QA.",
        "author": "Kratzwald, Bernhard and Eigenmann, Anna and Feuerriegel, Stefan",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP,   Experiments data:real , QA, AI",
        "pages": "6076--6085",
        "title": "RankQA: Neural Question Answering with Answer Re-Ranking",
        "type": "inproceedings",
        "year": "2019"
    },
    "krizhevsky2009learning": {
        "author": "Krizhevsky, Alex and Hinton, Geoffrey and others",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "publisher": "Citeseer",
        "title": "Learning multiple layers of features from tiny images",
        "type": "Article",
        "year": "2009"
    },
    "krizhevsky2017imagenet": {
        "author": "Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E",
        "journal": "Communications of the ACM",
        "keywords": "Main topic:AutoML, AI",
        "number": "6",
        "pages": "84--90",
        "publisher": "ACM New York, NY, USA",
        "title": "Imagenet classification with deep convolutional neural networks",
        "type": "Article",
        "volume": "60",
        "year": "2017"
    },
    "kundu2018question": {
        "abstract": "Neural network models recently proposed for question answering (QA) primarily focus on capturing the passage-question relation. However, they have minimal capability to link relevant facts distributed across multiple sentences which is crucial in achieving deeper understanding, such as performing multi-sentence reasoning, co-reference resolution, etc. They also do not explicitly focus on the question and answer type which often plays a critical role in QA. In this paper, we propose a novel end-to-end question-focused multi-factor attention network for answer extraction. Multi-factor attentive encoding using tensor-based transformation aggregates meaningful facts even when they are located in multiple sentences. To implicitly infer the answer type, we also propose a max-attentional question aggregation mechanism to encode a question vector based on the important words in a question. During prediction, we incorporate sequence-level encoding of the first wh-word and its immediately following word as an additional source of question type information. Our proposed model achieves significant improvements over the best prior state-of-the-art results on three large-scale challenging QA datasets, namely NewsQA, TriviaQA, and SearchQA.",
        "author": "Kundu, Souvik and Ng, Hwee Tou",
        "booktitle": "Thirty-Second AAAI Conference on Artificial Intelligence",
        "keywords": " Main topic:NLP, Experiments data:real ,  QA, AI",
        "title": "A question-focused multi-factor attention network for question answering",
        "type": "inproceedings",
        "year": "2018"
    },
    "kuutti2021a": {
        "author": "Kuutti, Sampo and Bowden, Richard and Jin, Yaochu and Barber, Phil and Fallah, Saber",
        "journal": "IEEE Trans. Intell. Transp. Syst.",
        "pages": "712--733",
        "title": "A Survey of Deep Learning Applications to Autonomous Vehicle Control",
        "type": "article",
        "year": "2021"
    },
    "kwiatkowski2019natural": {
        "abstract": "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.",
        "author": "Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others",
        "journal": "Transactions of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP, Experiments data:real , QA , dataset:NaturalQuestions, AI",
        "pages": "453--466",
        "publisher": "MIT Press",
        "title": "Natural questions: a benchmark for question answering research",
        "type": "article",
        "volume": "7",
        "year": "2019"
    },
    "labaien2020contrastive": {
        "abstract": "In the last decade, with the irruption of Deep Learning (DL), artificial intelligence has risen a step concerning previous years. Although Deep Learning models have gained strength in many fields like image classification, speech recognition, time-series anomaly detection, etc. these models are often difficult to understand because of their lack of interpretability. In recent years an effort has been made to understand DL models, creating a new research area called Explainable Artificial Intelligence (XAI). Most of the research in XAI has been done for image data, and little research has been done in the time-series data field. In this paper, a model-agnostic method called Contrastive Explanation Method (CEM) is used for interpreting a DL model for time-series classification. Even though CEM has been validated in tabular data and image data, the obtained experimental results show that CEM is also suitable for interpreting deep learning models that work with time-series data.",
        "author": "Labaien, Jokin and Zugasti, Ekhi and De Carlos, Xabier",
        "booktitle": "International Conference on Big Data Analytics and Knowledge Discovery",
        "keywords": "Main topic:XAI, AI",
        "organization": "Springer",
        "pages": "235--244",
        "title": "Contrastive Explanations for a Deep Learning Model on Time-Series Data",
        "type": "inproceedings",
        "year": "2020"
    },
    "lamy_sekar_guezennec_bouaud_s\u00e9roussi_2019": {
        "abstract": "Case-Based Reasoning (CBR) is a form of analogical reasoning in which the solution for a (new) query case is determined using a database of previous known cases with their solutions. Cases similar to the query are retrieved from the database, and then their solutions are adapted to the query. In medicine, a case usually corresponds to a patient and the problem consists of classifying the patient in a class of diagnostic or therapy. Compared to \u201cblack box\u201d algorithms such as deep learning, the responses of CBR systems can be justified easily using the similar cases as examples. However, this possibility is often under-exploited and the explanations provided by most CBR systems are limited to the display of the similar cases.",
        "author": "Lamy, Jean-Baptiste and Sekar, Boomadevi and Guezennec, Gilles and Bouaud, Jacques and S\u00e9roussi, Brigitte",
        "doi": "10.1016/j.artmed.2019.01.001",
        "file": ":30 Articles/good.pdf:PDF",
        "journal": "Artificial Intelligence in Medicine",
        "keywords": "Main topic:XAI",
        "pages": "42\u201353",
        "title": "Explainable artificial intelligence for breast cancer: A visual case-based reasoning approach",
        "type": "Article",
        "volume": "94",
        "year": "2019"
    },
    "langley2017explainable": {
        "abstract": "As intelligent agents become more autonomous, sophisticated, and prevalent, it becomes increasingly important that humans interact with them effectively. Machine learning is now used regularly to acquire expertise, but common techniques produce opaque content whose behavior is difficult to interpret. Before they will be trusted by humans, autonomous agents must be able to explain their decisions and the reasoning that produced their choices. We will refer to this general ability as explainable agency.",
        "author": "Langley, Pat and Meadows, Ben and Sridharan, Mohan and Choi, Dongkyu",
        "booktitle": "AAAI",
        "keywords": "Main topic:XAI",
        "pages": "4762--4763",
        "title": "Explainable Agency for Intelligent Autonomous Systems.",
        "type": "InProceedings",
        "volume": "17",
        "year": "2017"
    },
    "larsson2016fractalnet": {
        "author": "Larsson, Gustav and Maire, Michael and Shakhnarovich, Gregory",
        "journal": "arXiv preprint arXiv:1605.07648",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Fractalnet: Ultra-deep neural networks without residuals",
        "type": "Article",
        "year": "2016"
    },
    "le2013building": {
        "author": "\"Le, Quoc V\",",
        "booktitle": "\"2013 IEEE international conference on acoustics, speech and signal processing\",",
        "keywords": "concentration:learning",
        "organization": "\"IEEE\"",
        "pages": "\"8595--8598\",",
        "title": "\"Building high-level features using large scale unsupervised learning\",",
        "type": "inproceedings",
        "year": "\"2013\","
    },
    "le2020grace": {
        "abstract": "Despite the recent development in the topic of explainable AI/ML for image and text data, the majority of current solutions are not suitable to explain the prediction of neural network models when the datasets are tabular and their features are in high-dimensional vectorized formats. To mitigate this limitation, therefore, we borrow two notable ideas (i.e., \"explanation by intervention\" from causality and \"explanation are contrastive\" from philosophy) and propose a novel solution, named as GRACE, that better explains neural network models' predictions for tabular datasets. In particular, given a model's prediction as label X, GRACE intervenes and generates a minimally-modified contrastive sample to be classified as Y, with an intuitive textual explanation, answering the question of \"Why X rather than Y?\" We carry out comprehensive experiments using eleven public datasets of different scales and domains (e.g., # of features ranges from 5 to 216) and compare GRACE with competing baselines on different measures: fidelity, conciseness, info-gain, and influence. The user-studies show that our generated explanation is not only more intuitive and easy-to-understand but also facilitates end-users to make as much as 60\\% more accurate post-explanation decisions than that of Lime.",
        "author": "Le, Thai and Wang, Suhang and Lee, Dongwon",
        "booktitle": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining",
        "keywords": "Main topic:XAI, AI",
        "pages": "238--248",
        "title": "GRACE: Generating Concise and Informative Contrastive Sample to Explain Neural Network Model's Prediction",
        "type": "inproceedings",
        "year": "2020"
    },
    "le2021reinforcement": {
        "author": "Le, Anh Vu and Kyaw, Phone Thiha and Veerajagadheswar, Prabakaran and Muthugala, MA Viraj J and Elara, Mohan Rajesh and Kumar, Madhu and Nhan, Nguyen Huu Khanh",
        "journal": "Ocean Engineering",
        "pages": "108477",
        "publisher": "Elsevier",
        "title": "Reinforcement learning-based optimal complete water-blasting for autonomous ship hull corrosion cleaning system",
        "type": "article",
        "volume": "220",
        "year": "2021"
    },
    "lecun1998gradient": {
        "author": "LeCun, Yann and Bottou, L{\\'e}on and Bengio, Yoshua and Haffner, Patrick",
        "journal": "Proceedings of the IEEE",
        "number": "11",
        "pages": "2278--2324",
        "publisher": "Ieee",
        "title": "Gradient-based learning applied to document recognition",
        "type": "article",
        "volume": "86",
        "year": "1998"
    },
    "lecun2015deep": {
        "author": "LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey",
        "journal": "nature",
        "keywords": "Main topic:AutoML, AI",
        "number": "7553",
        "pages": "436--444",
        "publisher": "Nature Publishing Group",
        "title": "Deep learning",
        "type": "Article",
        "volume": "521",
        "year": "2015"
    },
    "lee2019latent": {
        "abstract": "Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.",
        "author": "Lee, Kenton and Chang, Ming-Wei and Toutanova, Kristina",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": " Main topic:NLP, Experiments data:real , QA, IR, AI",
        "pages": "6086--6096",
        "title": "Latent Retrieval for Weakly Supervised Open Domain Question Answering",
        "type": "inproceedings",
        "year": "2019"
    },
    "lewis2020retrieval": {
        "abstract": "    Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.",
        "author": "Lewis, Patrick and Perez, Ethan and Piktus, Aleksandara and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\\\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\\\"a}schel, Tim and others",
        "journal": "arXiv preprint arXiv:2005.11401",
        "keywords": "Main topic:NLP,  Experiments data:real , IR, AI",
        "title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "type": "article",
        "year": "2020"
    },
    "li2020random": {
        "author": "Li, Liam and Talwalkar, Ameet",
        "booktitle": "Uncertainty in Artificial Intelligence",
        "organization": "PMLR",
        "pages": "367--377",
        "title": "Random search and reproducibility for neural architecture search",
        "type": "InProceedings",
        "year": "2020"
    },
    "li2020sgas": {
        "author": "Li, Guohao and Qian, Guocheng and Delgadillo, Itzel C and Muller, Matthias and Thabet, Ali and Ghanem, Bernard",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "1620--1630",
        "title": "Sgas: Sequential greedy architecture search",
        "type": "InProceedings",
        "year": "2020"
    },
    "li2021deep": {
        "author": "Li, Guofa and Yang, Yifan and Qu, Xingda and Cao, Dongpu and Li, Keqiang",
        "journal": "Knowledge-Based Systems",
        "pages": "106617",
        "publisher": "Elsevier",
        "title": "A deep learning based image enhancement approach for autonomous driving at night",
        "type": "article",
        "volume": "213",
        "year": "2021"
    },
    "li2021semantic": {
        "author": "Li, Daiqing and Yang, Junlin and Kreis, Karsten and Torralba, Antonio and Fidler, Sanja",
        "journal": "arXiv preprint arXiv:2104.05833",
        "title": "Semantic segmentation with generative models: Semi-supervised learning and strong out-of-domain generalization",
        "type": "article",
        "year": "2021"
    },
    "liang2021querying": {
        "abstract": "Knowledge graphs are a powerful concept for querying large amounts of data. These knowledge graphs are typically enormous and are often not easily accessible to end-users because they require specialized knowledge in query languages such as SPARQL. Moreover, end-users need a deep understanding of the structure of the underlying data models often based on the Resource Description Framework (RDF). This drawback has led to the development of Question-Answering (QA) systems that enable end-users to express their information needs in natural language. While existing systems simplify user access, there is still room for improvement in the accuracy of these systems. In this paper we propose a new QA system for translating natural language questions into SPARQL queries. The key idea is to break up the translation process into 5 smaller, more manageable sub-tasks and use ensemble machine learning methods as well as Tree-LSTM-based neural network models to automatically learn and translate a natural language question into a SPARQL query. The performance of our proposed QA system is empirically evaluated using the two renowned benchmarks-the 7th Question Answering over Linked Data Challenge (QALD-7) and the Large-Scale Complex Question Answering Dataset (LC-QuAD). Experimental results show that our QA system outperforms the state-of-art systems by 15\\% on the QALD-7 dataset and by 48\\% on the LC-QuAD dataset, respectively. In addition, we make our source code available.",
        "author": "Liang, Shiqi and Stockinger, Kurt and de Farias, Tarcisio Mendes and Anisimova, Maria and Gil, Manuel",
        "journal": "Journal of Big Data",
        "keywords": "Main topic:NLP,  Experiments data:real ,  QA",
        "number": "1",
        "pages": "1--23",
        "publisher": "Springer",
        "title": "Querying knowledge graphs in natural language",
        "type": "article",
        "volume": "8",
        "year": "2021"
    },
    "lin2018amc": {
        "author": "Lin, Ji and Liu, Zhijian and Wang, Hanrui and Han, Song",
        "keywords": "Main topic:AutoML, AI, application :industry",
        "publisher": "Springer Science and Business Media LLC",
        "title": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices",
        "type": "Article",
        "year": "2018"
    },
    "lin2018denoising": {
        "abstract": "Distantly supervised open-domain question answering (DS-QA) aims to find answers in collections of unlabeled text. Existing DS-QA models usually retrieve related paragraphs from a large-scale corpus and apply reading comprehension technique to extract answers from the most relevant paragraph. They ignore the rich information contained in other paragraphs. Moreover, distant supervision data inevitably accompanies with the wrong labeling problem, and these noisy data will substantially degrade the performance of DS-QA. To address these issues, we propose a novel DS-QA model which employs a paragraph selector to filter out those noisy paragraphs and a paragraph reader to extract the correct answer from those denoised paragraphs. Experimental results on real-world datasets show that our model can capture useful information from noisy data and achieve significant improvements on DS-QA as compared to all baselines.",
        "author": "Lin, Yankai and Ji, Haozhe and Liu, Zhiyuan and Sun, Maosong",
        "booktitle": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "keywords": "Main topic:NLP,   Experiments data:real , QA, AI",
        "pages": "1736--1745",
        "title": "Denoising distantly supervised open-domain question answering",
        "type": "inproceedings",
        "year": "2018"
    },
    "liu2018deep": {
        "author": "Liu, Daochang and Jiang, Tingting",
        "booktitle": "International conference on medical image computing and computer-assisted intervention",
        "organization": "Springer",
        "pages": "247--255",
        "title": "Deep reinforcement learning for surgical gesture segmentation and classification",
        "type": "inproceedings",
        "year": "2018"
    },
    "liu2018progressive": {
        "author": "Liu, Chenxi and Zoph, Barret and Neumann, Maxim and Shlens, Jonathon and Hua, Wei and Li, Li-Jia and Fei-Fei, Li and Yuille, Alan and Huang, Jonathan and Murphy, Kevin",
        "booktitle": "Proceedings of the European Conference on Computer Vision (ECCV)",
        "keywords": "Main topic:AutoML, AI",
        "pages": "19--34",
        "title": "Progressive neural architecture search",
        "type": "InProceedings",
        "year": "2018"
    },
    "liu2021autonomous": {
        "author": "Liu, Mingjie and Deng, Xutao and Lei, Zhen and Jiang, Chao and Piao, Changhao",
        "journal": "Journal of Electrical Engineering \\& Technology",
        "number": "1",
        "pages": "569--578",
        "publisher": "Springer",
        "title": "Autonomous Lane Keeping System: Lane Detection, Tracking and Control on Embedded System",
        "type": "article",
        "volume": "16",
        "year": "2021"
    },
    "liu2021mixsearch": {
        "abstract": "Considering the scarcity of medical data, most datasets in medical image analysis are an order of magnitude smaller than those of natural images. However, most Network Architecture Search (NAS) approaches in medical images focused on specific datasets and did not take into account the generalization ability of the learned architectures on unseen datasets as well as different domains. In this paper, we address this point by proposing to search for generalizable U-shape architectures on a composited dataset that mixes medical images from multiple segmentation tasks and domains creatively, which is named MixSearch. Specifically, we propose a novel approach to mix multiple small-scale datasets from multiple domains and segmentation tasks to produce a large-scale dataset. Then, a novel weaved encoder-decoder structure is designed to search for a generalized segmentation network in both cell-level and network-level. The network produced by the proposed MixSearch framework achieves state-of-the-art results compared with advanced encoder-decoder networks across various datasets.",
        "author": "Luyan Liu and Zhiwei Wen and Songwei Liu and Hong-Yu Zhou and Hongwei Zhu and Weicheng Xie and Linlin Shen and Kai Ma and Yefeng Zheng",
        "date": "2021-01-01",
        "keywords": "Main topic:AutoML, AI",
        "pubstate": "published",
        "title": "MixSearch: Searching for Domain Generalized Medical Image Segmentation Architectures",
        "tppubtype": "techreport",
        "type": "TechReport",
        "url": "https://arxiv.org/abs/2102.13280",
        "year": "2021"
    },
    "loyola2020explainable": {
        "abstract": "Nowadays, the international scientific community of machine learning has an enormous campaign in favor of creating understandable models instead of black-box models. The main reason is that experts in the application area are showing reluctance due to black-box models cannot be understood by them, and consequently, their results are difficult to be explained. In unsupervised problems, where experts have not labeled objects, obtaining an explanation of the results is necessary because specialists in the application area need to understand both the applied model as well as the obtained results for finding the rationale behind each obtained clustering from a practical point of view. Hence, in this paper, we introduce a clustering based on decision trees (eUD3.5), which builds several decision trees from numerical databases. Unlike previous solutions, our proposal takes into account both separation and compactness for evaluating a feature split without decreasing time efficiency and with no empirical parameter to control the depth of the trees. We tested eUD3.5 on 40 numerical databases of UCI Machine Learning Repository, showing that our proposal builds a set of high-quality unsupervised decision trees for clustering, allowing us to obtain the best average ranking compared with other popular state-of-the-art clustering solutions. Also, from the collection of unsupervised decision trees induced by our proposal, a set of high-quality patterns are extracted for showing the main feature-value pairs describing each cluster.",
        "author": "Loyola-Gonzalez, Octavio and Gutierrez-Rodr{\\'\\i}guez, Andres Eduardo and Medina-P{\\'e}rez, Miguel Angel and Monroy, Raul and Mart{\\'\\i}nez-Trinidad, Jos{\\'e} Francisco and Carrasco-Ochoa, Jes{\\'u}s Ariel and Garcia-Borroto, Milton",
        "journal": "IEEE Access",
        "keywords": "Main topic:XAI",
        "pages": "52370--52384",
        "publisher": "IEEE",
        "title": "An Explainable Artificial Intelligence Model for Clustering Numerical Databases",
        "type": "article",
        "volume": "8",
        "year": "2020"
    },
    "lucic2020does": {
        "abstract": "In various business settings, there is an interest in using more complex machine learning techniques for sales forecasting. It is difficult to convince analysts, along with their superiors, to adopt these techniques since the models are considered to be \"black boxes,\" even if they perform better than current models in use. We examine the impact of contrastive explanations about large errors on users' attitudes towards a \"black-box'\" model. We propose an algorithm, Monte Carlo Bounds for Reasonable Predictions. Given a large error, MC-BRP determines (1) feature values that would result in a reasonable prediction, and (2) general trends between each feature and the target, both based on Monte Carlo simulations. We evaluate on a real dataset with real users by conducting a user study with 75 participants to determine if explanations generated by MC-BRP help users understand why a prediction results in a large error, and if this promotes trust in an automatically-learned model. Our study shows that users are able to answer objective questions about the model's predictions with overall 81.1\\% accuracy when provided with these contrastive explanations. We show that users who saw MC-BRP explanations understand why the model makes large errors in predictions significantly more than users in the control group. We also conduct an in-depth analysis on the difference in attitudes between Practitioners and Researchers, and confirm that our results hold when conditioning on the users' background.",
        "author": "Lucic, Ana and Haned, Hinda and de Rijke, Maarten",
        "booktitle": "Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency",
        "keywords": "Main topic:XAI, AI",
        "pages": "90--98",
        "title": "Why does my model fail? contrastive local explanations for retail forecasting",
        "type": "inproceedings",
        "year": "2020"
    },
    "luo2018neural": {
        "author": "Luo, Renqian and Tian, Fei and Qin, Tao and Chen, Enhong and Liu, Tie-Yan",
        "journal": "NIPS",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Neural architecture optimization",
        "type": "Article",
        "year": "2018"
    },
    "luo2020semisupervised": {
        "abstract": "Neural architecture search (NAS) relies on a good controller to generate better architectures or predict the accuracy of given architectures. However, training the controller requires both abundant and high-quality pairs of architectures and their accuracy, while it is costly to evaluate an architecture and obtain its accuracy. In this paper, we propose SemiNAS, a semi-supervised NAS approach that leverages numerous unlabeled architectures (without evaluation and thus nearly no cost). Specifically, SemiNAS 1) trains an initial accuracy predictor with a small set of architecture-accuracy data pairs; 2) uses the trained accuracy predictor to predict the accuracy of large amount of architectures (without evaluation); and 3) adds the generated data pairs to the original data to further improve the predictor. The trained accuracy predictor can be applied to various NAS algorithms by predicting the accuracy of candidate architectures for them. SemiNAS has two advantages: 1) It reduces the computational cost under the same accuracy guarantee. On NASBench-101 benchmark dataset, it achieves comparable accuracy with gradient-based method while using only 1/7 architecture-accuracy pairs. 2) It achieves higher accuracy under the same computational cost. It achieves 94.02 test accuracy on NASBench-101, outperforming all the baselines when using the same number of architectures. On ImageNet, it achieves 23.5 top-1 error rate (under 600M FLOPS constraint) using 4 GPU-days for search. We further apply it to LJSpeech text to speech task and it achieves 97 intelligibility rate in the low-resource setting and 15 test error rate in the robustness setting, with 9, 7 improvements over the baseline respectively.",
        "archiveprefix": "arXiv",
        "author": "Renqian Luo and Xu Tan and Rui Wang and Tao Qin and Enhong Chen and Tie-Yan Liu",
        "eprint": "2002.10389",
        "keywords": "Main topic:AutoML, AI, NAS",
        "primaryclass": "cs.LG",
        "title": "Semi-Supervised Neural Architecture Search",
        "type": "Misc",
        "year": "2020"
    },
    "luss2019generating": {
        "abstract": "As the application of deep neural networks proliferates in numerous areas such as medical imaging, video surveillance, and self driving cars, the need for explaining the decisions of these models has become a hot research topic, both at the global and local level. Locally, most explanation methods have focused on identifying relevance of features, limiting the types of explanations possible. In this paper, we investigate a new direction by leveraging latent features to generate contrastive explanations; predictions are explained not only by highlighting aspects that are in themselves sufficient to justify the classification, but also by new aspects which if added will change the classification. The key contribution of this paper lies in how we add features to rich data in a formal yet humanly interpretable way that leads to meaningful results. Our new definition of \"addition\" uses latent features to move beyond the limitations of previous explanations and resolve an open question laid out in Dhurandhar, et. al. (2018), which creates local contrastive explanations but is limited to simple datasets such as grayscale images. The strength of our approach in creating intuitive explanations that are also quantitatively superior to other methods is demonstrated on three diverse image datasets (skin lesions, faces, and fashion apparel). A user study with 200 participants further exemplifies the benefits of contrastive information, which can be viewed as complementary to other state-of-the-art interpretability methods.",
        "author": "Luss, Ronny and Chen, Pin-Yu and Dhurandhar, Amit and Sattigeri, Prasanna and Zhang, Yunfeng and Shanmugam, Karthikeyan and Tu, Chun-Chen",
        "journal": "arXiv preprint arXiv:1905.12698",
        "keywords": "Main topic:XAI, AI",
        "title": "Generating contrastive explanations with monotonic attribute functions",
        "type": "article",
        "year": "2019"
    },
    "ma2020survey": {
        "abstract": "Dialogue systems have achieved growing success in many areas thanks to the rapid advances of machine learning techniques. In the quest for generating more human-like conversations, one of the major challenges is to learn to generate responses in a more empathetic manner. In this review article, we focus on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge. Accordingly, we identify three key features that underpin such systems: emotion-awareness, personality-awareness, and knowledge-accessibility. The main goal of this review is to serve as a comprehensive guide to research and development on empathetic dialogue systems and to suggest future directions in this domain.",
        "author": "Ma, Yukun and Nguyen, Khanh Linh and Xing, Frank Z and Cambria, Erik",
        "journal": "Information Fusion",
        "keywords": "Main topic:NLP, dialogue-system, AI",
        "title": "A Survey on Empathetic Dialogue Systems",
        "type": "article",
        "year": "2020"
    },
    "ma2021replication": {
        "abstract": "Text retrieval using learned dense representations has recently emerged as a promising alternative to \"traditional\" text retrieval using sparse bag-of-words representations. One recent work that has garnered much attention is the dense passage retriever (DPR) technique proposed by Karpukhin et al. (2020) for end-to-end open-domain question answering. We present a replication study of this work, starting with model checkpoints provided by the authors, but otherwise from an independent implementation in our group's Pyserini IR toolkit and PyGaggle neural text ranking library. Although our experimental results largely verify the claims of the original paper, we arrived at two important additional findings that contribute to a better understanding of DPR: First, it appears that the original authors under-report the effectiveness of the BM25 baseline and hence also dense--sparse hybrid retrieval results. Second, by incorporating evidence from the retriever and an improved answer span scoring technique, we are able to improve end-to-end question answering effectiveness using exactly the same models as in the original work.",
        "author": "Ma, Xueguang and Sun, Kai and Pradeep, Ronak and Lin, Jimmy",
        "journal": "arXiv e-prints",
        "keywords": "Main topic:NLP,   Experiments data:real , TQA",
        "pages": "arXiv--2104",
        "title": "A Replication Study of Dense Passage Retriever",
        "type": "article",
        "year": "2021"
    },
    "madotto2019personalizing": {
        "abstract": "Existing personalized dialogue models use human designed persona descriptions to improve dialogue consistency. Collecting such descriptions from existing dialogues is expensive and requires hand-crafted feature designs. In this paper, we propose to extend Model-Agnostic Meta-Learning (MAML) (Finn et al., 2017) to personalized dialogue learning without using any persona descriptions. Our model learns to quickly adapt to new personas by leveraging only a few dialogue samples collected from the same user, which is fundamentally different from conditioning the response on the persona descriptions. Empirical results on Persona-chat dataset (Zhang et al., 2018) indicate that our solution outperforms non-meta-learning baselines using automatic evaluation metrics, and in terms of human-evaluated fluency and consistency.",
        "author": "Madotto, Andrea and Lin, Zhaojiang and Wu, Chien-Sheng and Fung, Pascale",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP, Experiments data:real , dialogue-systems,  AI",
        "pages": "5454--5459",
        "title": "Personalizing dialogue agents via meta-learning",
        "type": "inproceedings",
        "year": "2019"
    },
    "mao2020generationaugmented": {
        "abstract": "Conventional sparse retrieval methods such as TF-IDF and BM25 are simple and efficient, but solely rely on lexical overlap without semantic matching. Recent dense retrieval methods learn latent representations to tackle the lexical mismatch problem, while being more computationally expensive and insufficient for exact matching as they embed the text sequence into a single vector with limited capacity. In this paper, we present Generation-Augmented Retrieval (GAR), a query expansion method that augments a query with relevant contexts through text generation. We demonstrate on open-domain question answering that the generated contexts significantly enrich the semantics of the queries and thus GAR with sparse representations (BM25) achieves comparable or better performance than the state-of-the-art dense methods such as DPR \\cite{karpukhin2020dense}. We show that generating various contexts of a query is beneficial as fusing their results consistently yields better retrieval accuracy. Moreover, as sparse and dense representations are often complementary, GAR can be easily combined with DPR to achieve even better performance. Furthermore, GAR achieves the state-of-the-art performance on the Natural Questions and TriviaQA datasets under the extractive setting when equipped with an extractive reader, and consistently outperforms other retrieval methods when the same generative reader is used.",
        "archiveprefix": "arXiv",
        "author": "Yuning Mao and Pengcheng He and Xiaodong Liu and Yelong Shen and Jianfeng Gao and Jiawei Han and Weizhu Chen",
        "eprint": "2009.08553",
        "keywords": "Main topic:NLP,   Experiments data:real ,  IR, QA, AI",
        "primaryclass": "cs.CL",
        "title": "Generation-Augmented Retrieval for Open-domain Question Answering",
        "type": "misc",
        "year": "2020"
    },
    "mao2021reader": {
        "abstract": "Current open-domain question answering (QA) systems often follow a Retriever-Reader (R2) architecture, where the retriever first retrieves relevant passages and the reader then reads the retrieved passages to form an answer. In this paper, we propose a simple and effective passage reranking method, Reader-guIDEd Reranker (Rider), which does not involve any training and reranks the retrieved passages solely based on the top predictions of the reader before reranking. We show that Rider, despite its simplicity, achieves 10 to 20 absolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) score gains without refining the retriever or reader. In particular, Rider achieves 48.3 EM on the Natural Questions dataset and 66.4 on the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are used as the reader input.",
        "author": "Mao, Yuning and He, Pengcheng and Liu, Xiaodong and Shen, Yelong and Gao, Jianfeng and Han, Jiawei and Chen, Weizhu",
        "journal": "arXiv preprint arXiv:2101.00294",
        "keywords": "Main topic:NLP,   Experiments data:real , QA",
        "title": "Reader-Guided Passage Reranking for Open-Domain Question Answering",
        "type": "article",
        "year": "2021"
    },
    "miikkulainen2019evolving": {
        "author": "Miikkulainen, Risto and Liang, Jason and Meyerson, Elliot and Rawal, Aditya and Fink, Daniel and Francon, Olivier and Raju, Bala and Shahrzad, Hormoz and Navruzyan, Arshak and Duffy, Nigel and others",
        "booktitle": "Artificial intelligence in the age of neural networks and brain computing",
        "keywords": "Main topic:AutoML, AI",
        "pages": "293--312",
        "publisher": "Elsevier",
        "title": "Evolving deep neural networks",
        "type": "InCollection",
        "year": "2019"
    },
    "miller2016key": {
        "abstract": "Directly reading documents and being able to answer questions from them is an unsolved challenge. To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective. Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase. In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation. To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WikiMovies, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies. Our method reduces the gap between all three settings. It also achieves state-of-the-art results on the existing WikiQA benchmark.",
        "author": "Miller, Alexander H and Fisch, Adam and Dodge, Jesse and Karimi, Amir-Hossein and Bordes, Antoine and Weston, Jason",
        "booktitle": "EMNLP",
        "keywords": "Main topic:NLP,   Experiments data:real ,  RC , QA, AI",
        "title": "Key-Value Memory Networks for Directly Reading Documents",
        "type": "inproceedings",
        "year": "2016"
    },
    "min2019multi": {
        "abstract": "Multi-hop Reading Comprehension (RC) requires reasoning and aggregation across several paragraphs. We propose a system for multi-hop RC that decomposes a compositional question into simpler sub-questions that can be answered by off-the-shelf single-hop RC models. Since annotations for such decomposition are expensive, we recast sub-question generation as a span prediction problem and show that our method, trained using only 400 labeled examples, generates sub-questions that are as effective as human-authored sub-questions. We also introduce a new global rescoring approach that considers each decomposition (i.e. the sub-questions and their answers) to select the best final answer, greatly improving overall performance. Our experiments on HotpotQA show that this approach achieves the state-of-the-art results, while providing explainable evidence for its decision making in the form of sub-questions.",
        "author": "Min, Sewon and Zhong, Victor and Zettlemoyer, Luke and Hajishirzi, Hannaneh",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP, Experiments data:real , QA, RC, AI",
        "pages": "6097--6109",
        "title": "Multi-hop Reading Comprehension through Question Decomposition and Rescoring",
        "type": "inproceedings",
        "year": "2019"
    },
    "mo2021safe": {
        "author": "Mo, Shuojie and Pei, Xiaofei and Wu, Chaoxian",
        "journal": "IEEE Transactions on Intelligent Transportation Systems",
        "publisher": "IEEE",
        "title": "Safe Reinforcement Learning for Autonomous Vehicle Using Monte Carlo Tree Search",
        "type": "article",
        "year": "2021"
    },
    "moiseeva2020multipurpose": {
        "abstract": "Intelligent Process Automation (IPA) is an emerging technology with a primary goal to assist the knowledge worker by taking care of repetitive, routine and low-cognitive tasks. Conversational agents that can interact with users in a natural language are potential application for IPA systems. Such intelligent agents can assist the user by answering specific questions and executing routine tasks that are ordinarily performed in a natural language (i.e., customer support). In this work, we tackle a challenge of implementing an IPA conversational assistant in a real-world industrial setting with a lack of structured training data. Our proposed system brings two significant benefits: First, it reduces repetitive and time-consuming activities and, therefore, allows workers to focus on more intelligent processes. Second, by interacting with users, it augments the resources with structured and to some extent labeled training data. We showcase the usage of the latter by re-implementing several components of our system with Transfer Learning (TL) methods.",
        "author": "Moiseeva, Alena and Trautmann, Dietrich and Sch{\\\"u}tze, Hinrich",
        "journal": "arXiv preprint arXiv:2001.02284",
        "keywords": "Main topic:NLP, Experiments data:real , application:Intelligent Process Automation , Conversational-assistant, AI",
        "title": "Multipurpose Intelligent Process Automation via Conversational Assistant",
        "type": "article",
        "year": "2020"
    },
    "montenegro2019survey": {
        "abstract": "Artificial intelligence (AI) has transformed the world and the relationships among humans as the learning capabilities of machines have allowed for a new means of communication between humans and machines. In the field of health, there is much interest in new technologies that help to improve and automate services in hospitals. This article aims to explore the literature related to conversational agents applied to health care, searching for definitions, patterns, methods, architectures, and data types. Furthermore, this work identifies an agent application taxonomy, current challenges, and research gaps. In this work, we use a systematic literature review approach. We guide and refine this study and the research questions by applying Population, Intervention, Comparison, Outcome, and Context (PICOC) criteria. The present study investigated approximately 4145 articles involving conversational agents in health published over the last ten years. In this context, we finally selected 40 articles based on their approaches and objectives as related to our main subject. As a result, we developed a taxonomy, identified the main challenges in the field, and defined the main types of dialog and contexts related to conversational agents in health. These results contributed to discussions regarding conversational health agents, and highlighted some research gaps for future study.",
        "author": "Montenegro, Joao Luis Zeni and da Costa, Cristiano Andr{\\'e} and da Rosa Righi, Rodrigo",
        "journal": "Expert Systems with Applications",
        "keywords": "Main topic:NLP, concentration:perception , application:healthcare, chatbots,  AI",
        "pages": "56--67",
        "publisher": "Elsevier",
        "title": "Survey of conversational agents in health",
        "type": "article",
        "volume": "129",
        "year": "2019"
    },
    "moraffah2020causal": {
        "abstract": "Machine learning models have had discernible achievements in a myriad of applications. However, most of these models are black-boxes, and it is obscure how the decisions are made by them. This makes the models unreliable and untrustworthy. To provide insights into the decision making processes of these models, a variety of traditional interpretable models have been proposed. Moreover, to generate more human-friendly explanations, recent work on interpretability tries to answer questions related to causality such as \"Why does this model makes such decisions?\" or \"Was it a specific feature that caused the decision made by the model?\". In this work, models that aim to answer causal questions are referred to as causal interpretable models. The existing surveys have covered concepts and methodologies of traditional interpretability. In this work, we present a comprehensive survey on causal interpretable models from the aspects of the problems and methods. In addition, this survey provides in-depth insights into the existing evaluation metrics for measuring interpretability, which can help practitioners understand for what scenarios each evaluation metric is suitable.",
        "author": "Moraffah, Raha and Karami, Mansooreh and Guo, Ruocheng and Raglin, Adrienne and Liu, Huan",
        "journal": "ACM SIGKDD Explorations Newsletter",
        "keywords": "Main topic:XAI, AI",
        "number": "1",
        "pages": "18--33",
        "publisher": "ACM New York, NY, USA",
        "title": "Causal interpretability for machine learning-problems, methods and evaluation",
        "type": "article",
        "volume": "22",
        "year": "2020"
    },
    "nayman2019xnas": {
        "author": "Nayman, Niv and Noy, Asaf and Ridnik, Tal and Friedman, Itamar and Jin, Rong and Zelnik-Manor, Lihi",
        "journal": "arXiv preprint arXiv:1906.08031",
        "keywords": "Main topic:AutoML, AI",
        "title": "Xnas: Neural architecture search with expert advice",
        "type": "Article",
        "year": "2019"
    },
    "nie2019revealing": {
        "abstract": "Machine Reading at Scale (MRS) is a challenging task in which a system is given an input query and is asked to produce a precise output by \"reading\" information from a large knowledge base. The task has gained popularity with its natural combination of information retrieval (IR) and machine comprehension (MC). Advancements in representation learning have led to separated progress in both IR and MC; however, very few studies have examined the relationship and combined design of retrieval and comprehension at different levels of granularity, for development of MRS systems. In this work, we give general guidelines on system design for MRS by proposing a simple yet effective pipeline system with special consideration on hierarchical semantic retrieval at both paragraph and sentence level, and their potential effects on the downstream task. The system is evaluated on both fact verification and open-domain multihop QA, achieving state-of-the-art results on the leaderboard test sets of both FEVER and HOTPOTQA. To further demonstrate the importance of semantic retrieval, we present ablation and analysis studies to quantify the contribution of neural retrieval modules at both paragraph-level and sentence-level, and illustrate that intermediate semantic retrieval modules are vital for not only effectively filtering upstream information and thus saving downstream computation, but also for shaping upstream data distribution and providing better data for downstream modeling. Code/data made publicly available at: https://github.com/easonnie/semanticRetrievalMRS",
        "author": "Nie, Yixin and Wang, Songhe and Bansal, Mohit",
        "booktitle": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
        "keywords": "Main topic:NLP,  Experiments data:real , multihop, QA, IR, AI",
        "pages": "2553--2566",
        "title": "Revealing the Importance of Semantic Retrieval for Machine Reading at Scale",
        "type": "inproceedings",
        "year": "2019"
    },
    "olszewska2019designing": {
        "abstract": "To process vast amounts of visual data such as images, videos, etc. in an automatic and computationally efficient way, intelligent vision systems have been developed over the last three decades. However, with the increasing development of complex technologies like companion robots which require advanced machine vision capabilities and, on the other hand, the growing attention to data security and privacy, the design of intelligent vision systems faces new challenges such as autonomy and transparency. Hence, in this paper, we propose to define the main requirements for the new generation of intelligent vision systems (IVS) we demonstrated in a prototype.",
        "author": "Olszewska, Joanna Isabelle",
        "booktitle": "ICAART (2)",
        "keywords": "Main topic:XAI, AI",
        "pages": "850--856",
        "title": "Designing Transparent and Autonomous Intelligent Vision Systems.",
        "type": "inproceedings",
        "year": "2019"
    },
    "omeiza2021explainable": {
        "abstract": " The safe deployment of autonomous physical systems in real-world scenarios requires them to be explainable and trustworthy, especially in critical domains. In contrast with \u2018black-box\u2019 systems, explainable and trustworthy autonomous physical systems will lend themselves to easy assessments by system designers and regulators. This promises to pave ways for easy improvements that can lead to enhanced performance, and as well, increased public trust. In this one-day virtual workshop, we aim to gather a globally distributed group of researchers and practitioners to discuss the opportunities and social challenges in the design, implementation, and deployment of explainable and trustworthy autonomous physical systems, especially in a post-pandemic era. Interactions will be fostered through panel discussions and a series of spotlight talks. To ensure lasting impact of the workshop, we will conduct a pre-workshop survey which will examine the public perception of the trustworthiness of autonomous physical systems. Further, we will publish a summary report providing details about the survey as well as the identified challenges resulting from the workshop\u2019s panel discussions.",
        "address": "New York, NY, USA",
        "articleno": "88",
        "author": "Omeiza, Daniel and Anjomshoae, Sule and Kollnig, Konrad and Camburu, Oana-Maria and Fr\\\"{a}mling, Kary and Kunze, Lars",
        "booktitle": "Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems",
        "isbn": "9781450380959",
        "keywords": "Main topic:XAI, AI",
        "numpages": "3",
        "publisher": "Association for Computing Machinery",
        "title": "Towards Explainable and Trustworthy Autonomous Physical Systems",
        "type": "inbook",
        "url": "https://doi.org/10.1145/3411763.3441338",
        "year": "2021"
    },
    "payrovnaziri2020explainable": {
        "abstract": "To conduct a systematic scoping review of explainable artificial intelligence (XAI) models that use real-world electronic health record data, categorize these techniques according to different biomedical applications, identify gaps of current studies, and suggest future research directions.",
        "author": "Payrovnaziri, Seyedeh Neelufar and Chen, Zhaoyi and Rengifo-Moreno, Pablo and Miller, Tim and Bian, Jiang and Chen, Jonathan H and Liu, Xiuwen and He, Zhe",
        "journal": "Journal of the American Medical Informatics Association",
        "keywords": "Main topic:XAI",
        "number": "7",
        "pages": "1173--1185",
        "publisher": "Oxford University Press",
        "title": "Explainable artificial intelligence models using real-world electronic health record data: a systematic scoping review",
        "type": "article",
        "volume": "27",
        "year": "2020"
    },
    "pereira2020cognitive": {
        "abstract": "When speaking of moral conscience, we are referring to a function of recognizing appropriate or condemnable action, and the possibility of choice between them. In fact, it would make no sense to talk about morals or ethics, if for each situation we had only one possible answer. Morality is justified because the agent can choose among possible actions. His ability to construct possible causal sequences enables him to devise alternatives in which choosing one implies setting aside the other. This typology of internal deliberation requires certain cognitive capacities, namely that of constructing counterfactual arguments. These serve not only to analyse possible futures, being prospective, but also to analyse past situations, by imagining the gains or losses resulting from imagining alternatives to the action actually carried out. Compared to social learning, where the subject can only mimic certain behaviours, the construction of counterfactuals is much richer and more fruitful. Thus, for machines to be equipped with effective moral capacity, it is necessary to equip them with the ability to construct and analyse counterfactual situations.",
        "author": "Pereira, Lu{\\'\\i}s Moniz and Lopes, Ant{\\'o}nio Barata",
        "booktitle": "Machine Ethics",
        "keywords": "Main topic:XAI, AI",
        "pages": "97--102",
        "publisher": "Springer",
        "title": "Cognitive Prerequisites: The Special Case of Counterfactual Reasoning",
        "type": "incollection",
        "year": "2020"
    },
    "perez2018efficient": {
        "author": "Perez-Rua, Juan-Manuel and Baccouche, Moez and Pateux, Stephane",
        "journal": "The British Machine Vision Conference (BMVC) arXiv:1808.00391",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Efficient progressive neural architecture search",
        "type": "Article",
        "year": "2018"
    },
    "peters2018deep": {
        "abstract": "    We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
        "author": "Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke",
        "booktitle": "Proceedings of NAACL-HLT",
        "keywords": "Main topic:NLP, Language-Model,  AI",
        "pages": "2227--2237",
        "title": "Deep contextualized word representations",
        "type": "inproceedings",
        "year": "2018"
    },
    "poyiadzi2020face": {
        "abstract": "Work in Counterfactual Explanations tends to focus on the principle of \"the closest possible world\" that identifies small changes leading to the desired outcome. In this paper we argue that while this approach might initially seem intuitively appealing it exhibits shortcomings not addressed in the current literature. First, a counterfactual example generated by the state-of-the-art systems is not necessarily representative of the underlying data distribution, and may therefore prescribe unachievable goals(e.g., an unsuccessful life insurance applicant with severe disability may be advised to do more sports). Secondly, the counterfactuals may not be based on a \"feasible path\" between the current state of the subject and the suggested one, making actionable recourse infeasible (e.g., low-skilled unsuccessful mortgage applicants may be told to double their salary, which may be hard without first increasing their skill level). These two shortcomings may render counterfactual explanations impractical and sometimes outright offensive. To address these two major flaws, first of all, we propose a new line of Counterfactual Explanations research aimed at providing actionable and feasible paths to transform a selected instance into one that meets a certain goal. Secondly, we propose FACE: an algorithmically sound way of uncovering these \"feasible paths\" based on the shortest path distances defined via density-weighted metrics. Our approach generates counterfactuals that are coherent with the underlying data distribution and supported by the \"feasible paths\" of change, which are achievable and can be tailored to the problem at hand.",
        "author": "Poyiadzi, Rafael and Sokol, Kacper and Santos-Rodriguez, Raul and De Bie, Tijl and Flach, Peter",
        "booktitle": "Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",
        "keywords": "Main topic:XAI, AI",
        "pages": "344--350",
        "title": "FACE: feasible and actionable counterfactual explanations",
        "type": "inproceedings",
        "year": "2020"
    },
    "qi2019answering": {
        "abstract": "It is challenging for current one-step retrieve-and-read question answering (QA) systems to answer questions like \"Which novel by the author of 'Armada' will be adapted as a feature film by Steven Spielberg?\" because the question seldom contains retrievable clues about the missing entity (here, the author). Answering such a question requires multi-hop reasoning where one must gather information about the missing entity (or facts) to proceed with further reasoning. We present GoldEn (Gold Entity) Retriever, which iterates between reading context and retrieving more supporting documents to answer open-domain multi-hop questions. Instead of using opaque and computationally expensive neural retrieval models, GoldEn Retriever generates natural language search queries given the question and available context, and leverages off-the-shelf information retrieval systems to query for missing entities. This allows GoldEn Retriever to scale up efficiently for open-domain multi-hop reasoning while maintaining interpretability. We evaluate GoldEn Retriever on the recently proposed open-domain multi-hop QA dataset, HotpotQA, and demonstrate that it outperforms the best previously published model despite not using pretrained language models such as BERT.",
        "author": "Qi, Peng and Lin, Xiaowen and Mehr, Leo and Wang, Zijian and Manning, Christopher D",
        "booktitle": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
        "keywords": "  Main topic:NLP, Experiments data:real , TBQA, AI",
        "pages": "2590--2602",
        "title": "Answering Complex Open-domain Questions Through Iterative Query Generation",
        "type": "inproceedings",
        "year": "2019"
    },
    "ramos2003using": {
        "abstract": "In this paper, we examine the results of applying Term Frequency Inverse Document Frequency (TF-IDF) to determine what words in a corpus of documents might be more favorable to use in a query. As the term implies, TF-IDF calculates values for each word in a document through an inverse proportion of the frequency of the word in a particular document to the percentage of documents the word appears in. Words with high TF-IDF numbers imply  a  strong  relationship with the document they appear in, suggesting that if that word were to appear in a query, the document could be of interest to the user. We provide evidence that this simple algorithm efficiently categorizes relevant words that can enhance query retrieval",
        "author": "Ramos, Juan and others",
        "booktitle": "Proceedings of the first instructional conference on machine learning",
        "keywords": "Main topic:NLP, IR",
        "number": "1",
        "organization": "Citeseer",
        "pages": "29--48",
        "title": "Using tf-idf to determine word relevance in document queries",
        "type": "inproceedings",
        "volume": "242",
        "year": "2003"
    },
    "real2017large": {
        "author": "Real, Esteban and Moore, Sherry and Selle, Andrew and Saxena, Saurabh and Suematsu, Yutaka Leon and Tan, Jie and Le, Quoc V and Kurakin, Alexey",
        "booktitle": "International Conference on Machine Learning",
        "keywords": "Main topic:AutoML, AI",
        "organization": "PMLR",
        "pages": "2902--2911",
        "title": "Large-scale evolution of image classifiers",
        "type": "InProceedings",
        "year": "2017"
    },
    "real2018regularized": {
        "archiveprefix": "arXiv",
        "author": "Esteban Real and Alok Aggarwal and Yanping Huang and Quoc V Le",
        "comment": "Image classification competetive performance mentioned in DARTS",
        "eprint": "1802.01548",
        "primaryclass": "cs.NE",
        "title": "Regularized Evolution for Image Classifier Architecture Search",
        "type": "Misc",
        "year": "2018"
    },
    "real2019regularized": {
        "author": "Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V",
        "booktitle": "Proceedings of the aaai conference on artificial intelligence",
        "keywords": "Main topic:AutoML, AI",
        "pages": "4780--4789",
        "title": "Regularized evolution for image classifier architecture search",
        "type": "InProceedings",
        "volume": "33",
        "year": "2019"
    },
    "reddy2019coqa": {
        "abstract": "Humans gather information through conversations involving a series of interconnected questions and answers. For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions. We introduce CoQA, a novel dataset for building Conversational Question Answering systems. Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains. The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage. We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets (e.g., coreference and pragmatic reasoning). We evaluate strong dialogue and reading comprehension models on CoQA. The best system obtains an F1 score of 65.4\\%, which is 23.4 points behind human performance (88.8\\%), indicating that there is ample room for improvement. We present CoQA as a challenge to the community at https://stanfordnlp.github.io/coqa.",
        "author": "Reddy, Siva and Chen, Danqi and Manning, Christopher D",
        "journal": "Transactions of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP, Experiments data:real , CQA, dataset:Coqa,  AI",
        "pages": "249--266",
        "publisher": "MIT Press",
        "title": "Coqa: A conversational question answering challenge",
        "type": "article",
        "volume": "7",
        "year": "2019"
    },
    "ribeiro2016should": {
        "abstract": "Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "booktitle": "Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining",
        "keywords": "Main topic:XAI",
        "pages": "1135--1144",
        "title": "\" Why should I trust you?\" Explaining the predictions of any classifier",
        "type": "InProceedings",
        "year": "2016"
    },
    "rizk2020conversational": {
        "abstract": "Robotic process automation (RPA) has emerged as the leading approach to automate tasks in business processes. Moving away from back-end automation, RPA automated the mouse-click on user interfaces; this outside-in approach reduced the overhead of updating legacy software. However, its many shortcomings, namely its lack of accessibility to business users, have prevented its widespread adoption in highly regulated industries. In this work, we explore interactive automation in the form of a conversational digital assistant. It allows business users to interact with and customize their automation solutions through natural language. The framework, which creates such assistants, relies on a multi-agent orchestration model and conversational wrappers for autonomous agents including RPAs. We demonstrate the effectiveness of our proposed approach on a loan approval business process and a travel preapproval business process.",
        "author": "Rizk, Yara and Isahagian, Vatche and Boag, Scott and Khazaeni, Yasaman and Unuvar, Merve and Muthusamy, Vinod and Khalaf, Rania",
        "booktitle": "International Conference on Business Process Management",
        "keywords": " Main topic:NLP, application:Intelligent Process Automation , Conversational-assistant, AI",
        "organization": "Springer",
        "pages": "85--100",
        "title": "A Conversational Digital Assistant for Intelligent Process Automation",
        "type": "inproceedings",
        "year": "2020"
    },
    "robertson2009probabilistic": {
        "abstract": "",
        "author": "Robertson, Stephen and Zaragoza, Hugo",
        "keywords": "Main topic:NLP, IR",
        "publisher": "Now Publishers Inc",
        "title": "The probabilistic relevance framework: BM25 and beyond",
        "type": "book",
        "year": "2009"
    },
    "rojat2021explainable": {
        "abstract": "Most of state of the art methods applied on time series consist of deep learning methods that are too complex to be interpreted. This lack of interpretability is a major drawback, as several applications in the real world are critical tasks, such as the medical field or the autonomous driving field. The explainability of models applied on time series has not gather much attention compared to the computer vision or the natural language processing fields. In this paper, we present an overview of existing explainable AI (XAI) methods applied on time series and illustrate the type of explanations they produce. We also provide a reflection on the impact of these explanation methods to provide confidence and trust in the AI systems.",
        "archiveprefix": "arXiv",
        "author": "Thomas Rojat and Rapha\u00ebl Puget and David Filliat and Javier Del Ser and Rodolphe Gelin and Natalia D\u00edaz-Rodr\u00edguez",
        "eprint": "2104.00950",
        "keywords": "Main topic:XAI, AI",
        "primaryclass": "cs.LG",
        "title": "Explainable Artificial Intelligence (XAI) on TimeSeries Data: A Survey",
        "type": "misc",
        "year": "2021"
    },
    "rudin2019stop": {
        "abstract": "Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.",
        "author": "Rudin, Cynthia",
        "journal": "Nature Machine Intelligence",
        "keywords": "Main topic:XAI, AI",
        "number": "5",
        "pages": "206--215",
        "publisher": "Nature Publishing Group",
        "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
        "type": "article",
        "volume": "1",
        "year": "2019"
    },
    "russell2002artificiall": {
        "author": "\"Russell, Stuart and Norvig, Peter\",",
        "title": "\"Artificial intelligence: a modern approach\",",
        "type": "article",
        "year": "\"2002\""
    },
    "ryo2021explainable": {
        "abstract": "Species distribution models (SDMs) are widely used in ecology, biogeography and conservation biology to estimate relationships between environmental variables and species occurrence data and make predictions of how their distributions vary in space and time. During the past two decades, the field has increasingly made use of machine learning approaches for constructing and validating SDMs. Model accuracy has steadily increased as a result, but the interpretability of the fitted models, for example the relative importance of predictor variables or their causal effects on focal species, has not always kept pace. Here we draw attention to an emerging subdiscipline of artificial intelligence, explainable AI (xAI), as a toolbox for better interpreting SDMs. xAI aims at deciphering the behavior of complex statistical or machine learning models (e.g. neural networks, random forests, boosted regression trees), and can produce more transparent and understandable SDM predictions. We describe the rationale behind xAI and provide a list of tools that can be used to help ecological modelers better understand complex model behavior at different scales. As an example, we perform a reproducible SDM analysis in R on the African elephant and showcase some xAI tools such as local interpretable model-agnostic explanation (LIME) to help interpret local-scale behavior of the model. We conclude with what we see as the benefits and caveats of these techniques and advocate for their use to improve the interpretability of machine learning SDMs.",
        "author": "Ryo, Masahiro and Angelov, Boyan and Mammola, Stefano and Kass, Jamie M and Benito, Blas M and Hartig, Florian",
        "journal": "Ecography",
        "keywords": "Main topic:XAI, AI",
        "number": "2",
        "pages": "199--205",
        "publisher": "Wiley Online Library",
        "title": "Explainable artificial intelligence enhances the ecological interpretability of black-box species distribution models",
        "type": "article",
        "volume": "44",
        "year": "2021"
    },
    "sachan2020explainable": {
        "abstract": "Widespread adoption of automated decision making by artificial intelligence (AI) is witnessed due to specular advances in computation power and improvements in optimization algorithms especially in machine learning (ML). Complex ML models provide good prediction accuracy; however, the opacity of ML models does not provide sufficient assurance for their adoption in the automation of lending decisions. This paper presents an explainable AI decision-support-system to automate the loan underwriting process by belief-rule-base (BRB). This system can accommodate human knowledge and can also learn from historical data by supervised learning. The hierarchical structure of BRB can accommodates factual and heuristic rules. The system can explain the chain of events leading to a decision for a loan application by the importance of an activated rule and the contribution of antecedent attributes in the rule. A business case study on automation of mortgage underwriting is demonstrated to show that the BRB system can provide a good trade-off between accuracy and explainability. The textual explanation produced by the activation of rules could be used as a reason for denial of a loan. The decision-making process for an application can be comprehended by the significance of rules in providing the decision and contribution of its antecedent attributes.",
        "author": "Sachan, Swati and Yang, Jian-Bo and Xu, Dong-Ling and Benavides, David Eraso and Li, Yang",
        "journal": "Expert Systems with Applications",
        "keywords": "Main topic:XAI",
        "pages": "113100",
        "publisher": "Elsevier",
        "title": "An explainable AI decision-support-system to automate loan underwriting",
        "type": "article",
        "volume": "144",
        "year": "2020"
    },
    "sakai2021explainable": {
        "abstract": "Advanced communication protocols are critical to enable the coexistence of autonomous robots with humans. Thus, the development of explanatory capabilities is an urgent first step toward autonomous robots. This survey provides an overview of the various types of \"explainability\" discussed in machine learning research. Then, we discuss the definition of \"explainability\" in the context of autonomous robots (i.e., explainable autonomous robots) by exploring the question \"what is an explanation?\" We further conduct a research survey based on this definition and present some relevant topics for future research.",
        "archiveprefix": "arXiv",
        "author": "Tatsuya Sakai and Takayuki Nagai",
        "eprint": "2105.02658",
        "keywords": "Main topic:XAI, AI",
        "title": "Explainable Autonomous Robots: A Survey and Perspective",
        "type": "misc",
        "year": "2021"
    },
    "sakai2021framework": {
        "abstract": "To realize autonomous collaborative robots, it is important to increase the trust that users have in them. Toward this goal, this paper proposes an algorithm which endows an autonomous agent with the ability to explain the transition from the current state to the target state in a Markov decision process (MDP). According to cognitive science, to generate an explanation that is acceptable to humans, it is important to present the minimum information necessary to sufficiently understand an event. To meet this requirement, this study proposes a framework for identifying important elements in the decision-making process using a prediction model for the world and generating explanations based on these elements. To verify the ability of the proposed method to generate explanations, we conducted an experiment using a grid environment. It was inferred from the result of a simulation experiment that the explanation generated using the proposed method was composed of the minimum elements important for understanding the transition from the current state to the target state. Furthermore, subject experiments showed that the generated explanation was a good summary of the process of state transition, and that a high evaluation was obtained for the explanation of the reason for an action.",
        "archiveprefix": "arXiv",
        "author": "Tatsuya Sakai and Kazuki Miyazawa and Takato Horii and Takayuki Nagai",
        "eprint": "2105.02670",
        "keywords": "Main topic:XAI, AI",
        "title": "A Framework of Explanation Generation toward Reliable Autonomous Robots",
        "type": "misc",
        "year": "2021"
    },
    "salimans2016improved": {
        "author": "Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi",
        "journal": "arXiv preprint arXiv:1606.03498",
        "title": "Improved techniques for training gans",
        "type": "article",
        "year": "2016"
    },
    "sama2020extracting": {
        "author": "Sama, Kyle and Morales, Yoichi and Liu, Hailong and Akai, Naoki and Carballo, Alexander and Takeuchi, Eijiro and Takeda, Kazuya",
        "journal": "IEEE transactions on vehicular technology",
        "number": "9",
        "pages": "9315--9329",
        "publisher": "IEEE",
        "title": "Extracting human-like driving behaviors from expert driver data using deep learning",
        "type": "article",
        "volume": "69",
        "year": "2020"
    },
    "samek2016interpreting": {
        "abstract": "Complex nonlinear models such as deep neural network (DNNs) have become an important tool for image classification, speech recognition, natural language processing, and many other fields of application. These models however lack transparency due to their complex nonlinear structure and to the complex data distributions to which they typically apply. As a result, it is difficult to fully characterize what makes these models reach a particular decision for a given input. This lack of transparency can be a drawback, especially in the context of sensitive applications such as medical analysis or security. In this short paper, we summarize a recent technique introduced by Bach et al. [1] that explains predictions by decomposing the classification decision of DNN models in terms of input variables.",
        "author": "Samek, Wojciech and Montavon, Gr{\\'e}goire and Binder, Alexander and Lapuschkin, Sebastian and M{\\\"u}ller, Klaus-Robert",
        "journal": "arXiv preprint arXiv:1611.08191",
        "keywords": "Main topic:XAI",
        "title": "Interpreting the predictions of complex ml models by layer-wise relevance propagation",
        "type": "article",
        "year": "2016"
    },
    "samek_m\u00fcller_2019": {
        "abstract": "In recent years, machine learning (ML) has become a key enabling technology for the sciences and industry. Especially through improvements in methodology, the availability of large databases and increased computational power, today's ML algorithms are able to achieve excellent performance (at times even exceeding the human level) on an increasing number of complex tasks. Deep learning models are at the forefront of this development. However, due to their nested non-linear structure, these powerful models have been generally considered \"black boxes\", not providing any information about what exactly makes them arrive at their predictions. Since in many applications, e.g., in the medical domain, such lack of transparency may be not acceptable, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This introductory paper presents recent developments and applications in this field and makes a plea for a wider use of explainable learning algorithms in practice.",
        "author": "Samek, Wojciech and M{\\\"u}ller, Klaus-Robert",
        "booktitle": "Explainable AI: interpreting, explaining and visualizing deep learning",
        "keywords": "Main topic:XAI",
        "pages": "5--22",
        "publisher": "Springer",
        "title": "Towards explainable artificial intelligence",
        "type": "incollection",
        "year": "2019"
    },
    "saxena2020driving": {
        "author": "Saxena, Dhruv Mauria and Bae, Sangjae and Nakhaei, Alireza and Fujimura, Kikuo and Likhachev, Maxim",
        "booktitle": "2020 IEEE International Conference on Robotics and Automation (ICRA)",
        "organization": "IEEE",
        "pages": "5385--5392",
        "title": "Driving in dense traffic with model-free reinforcement learning",
        "type": "inproceedings",
        "year": "2020"
    },
    "shen2020explain": {
        "abstract": "Explainable AI, in the context of autonomous systems, like self driving cars, has drawn broad interests from researchers. Recent studies have found that providing explanations for an autonomous vehicle actions has many benefits, e.g., increase trust and acceptance, but put little emphasis on when an explanation is needed and how the content of explanation changes with context. In this work, we investigate which scenarios people need explanations and how the critical degree of explanation shifts with situations and driver types. Through a user experiment, we ask participants to evaluate how necessary an explanation is and measure the impact on their trust in the self driving cars in different contexts. We also present a self driving explanation dataset with first person explanations and associated measure of the necessity for 1103 video clips, augmenting the Berkeley Deep Drive Attention dataset. Additionally, we propose a learning based model that predicts how necessary an explanation for a given situation in real time, using camera data inputs. Our research reveals that driver types and context dictates whether or not an explanation is necessary and what is helpful for improved interaction and understanding.",
        "archiveprefix": "arXiv",
        "author": "Yuan Shen and Shanduojiao Jiang and Yanlin Chen and Eileen Yang and Xilun Jin and Yuliang Fan and Katie Driggs Campbell",
        "eprint": "2006.11684",
        "keywords": "Main topic:XAI, AI",
        "primaryclass": "cs.AI",
        "title": "To Explain or Not to Explain: A Study on the Necessity of Explanations for Autonomous Vehicles",
        "type": "misc",
        "year": "2020"
    },
    "shi2021transfernet": {
        "abstract": "Multi-hop Question Answering (QA) is a challenging task because it requires precise reasoning with entity relations at every step towards the answer. The relations can be represented in terms of labels in knowledge graph (e.g., \\textit{spouse}) or text in text corpus (e.g., \\textit{they have been married for 26 years}). Existing models usually infer the answer by predicting the sequential relation path or aggregating the hidden graph features. The former is hard to optimize, and the latter lacks interpretability. In this paper, we propose TransferNet, an effective and transparent model for multi-hop QA, which supports both label and text relations in a unified framework. TransferNet jumps across entities at multiple steps. At each step, it attends to different parts of the question, computes activated scores for relations, and then transfer the previous entity scores along activated relations in a differentiable way. We carry out extensive experiments on three datasets and demonstrate that TransferNet surpasses the state-of-the-art models by a large margin. In particular, on MetaQA, it achieves 100\\% accuracy in 2-hop and 3-hop questions. By qualitative analysis, we show that TransferNet has transparent and interpretable intermediate results.",
        "author": "Shi, Jiaxin and Cao, Shulin and Hou, Lei and Li, Juanzi and Zhang, Hanwang",
        "journal": "arXiv preprint arXiv:2104.07302",
        "keywords": "Main topic:NLP,   Experiments data:real , QA",
        "title": "TransferNet: An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph",
        "type": "article",
        "year": "2021"
    },
    "shin2018differentiable": {
        "author": "Shin, Richard and Packer, Charles and Song, Dawn",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Differentiable neural network architecture search",
        "type": "Article",
        "year": "2018"
    },
    "shin2019spring": {
        "author": "Shin, Youjung",
        "journal": "IEEE Annals of the History of Computing",
        "number": "4",
        "pages": "71--82",
        "publisher": "IEEE",
        "title": "The spring of artificial intelligence in its global winter",
        "type": "article",
        "volume": "41",
        "year": "2019"
    },
    "sifakis2019autonomous": {
        "author": "Sifakis, Joseph",
        "booktitle": "Models, Languages, and Tools for Concurrent and Distributed Programming",
        "pages": "388--410",
        "publisher": "Springer",
        "title": "Autonomous systems--an architectural characterization",
        "type": "incollection",
        "year": "2019"
    },
    "simonyan2013deep": {
        "abstract": "This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].",
        "author": "Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew",
        "journal": "arXiv preprint arXiv:1312.6034",
        "keywords": "Main topic:XAI",
        "title": "Deep inside convolutional networks: Visualising image classification models and saliency maps",
        "type": "article",
        "year": "2013"
    },
    "sokol2020one": {
        "abstract": "The need for transparency of predictive systems based on Machine Learning algorithms arises as a consequence of their ever-increasing proliferation in the industry. Whenever black-box algorithmic predictions influence human affairs, the inner workings of these algorithms should be scrutinised and their decisions explained to the relevant stakeholders, including the system engineers, the system\u2019s operators and the individuals whose case is being decided. While a variety of interpretability and explainability methods is available, none of them is a panacea that can satisfy all diverse expectations and competing objectives that might be required by the parties involved. We address this challenge in this paper by discussing the promises of Interactive Machine Learning for improved transparency of black-box systems using the example of contrastive explanations\u2014a state-of-the-art approach to Interpretable Machine Learning. Specifically, we show how to personalise counterfactual explanations by interactively adjusting their conditional statements and extract additional explanations by asking follow-up \u201cWhat if?\u201d questions. Our experience in building, deploying and presenting this type of system allowed us to list desired properties as well as potential limitations, which can be used to guide the development of interactive explainers. While customising the medium of interaction, i.e., the user interface comprising of various communication channels, may give an impression of personalisation, we argue that adjusting the explanation itself and its content is more important. To this end, properties such as breadth, scope, context, purpose and target of the explanation have to be considered, in addition to explicitly informing the explainee about its limitations and caveats. Furthermore, we discuss the challenges of mirroring the explainee\u2019s mental model, which is the main building block of intelligible human\u2013machine interactions. We also deliberate on the risks of allowing the explainee to freely manipulate the explanations and thereby extracting information about the underlying predictive model, which might be leveraged by malicious actors to steal or game the model. Finally, building an end-to-end interactive explainability system is a challenging engineering task; unless the main goal is its deployment, we recommend \u201cWizard of Oz\u201d studies as a proxy for testing and evaluating standalone interactive explainability algorithms.",
        "author": "Sokol, Kacper and Flach, Peter",
        "journal": "KI-K{\\\"u}nstliche Intelligenz",
        "keywords": "Main topic:XAI, AI",
        "pages": "1--16",
        "publisher": "Springer",
        "title": "One explanation does not fit all",
        "type": "article",
        "year": "2020"
    },
    "srivastava-etal-2021-complex": {
        "abstract": "\"Question answering (QA) over a knowledge graph (KG) is a task of answering a natural language (NL) query using the information stored in KG. In a real-world industrial setting, this involves addressing multiple challenges including entity linking, multi-hop reasoning over KG, etc. Traditional approaches handle these challenges in a modularized sequential manner where errors in one module lead to the accumulation of errors in downstream modules. Often these challenges are inter-related and the solutions to them can reinforce each other when handled simultaneously in an end-to-end learning setup. To this end, we propose a multi-task BERT based Neural Machine Translation (NMT) model to address these challenges. Through experimental analysis, we demonstrate the efficacy of our proposed approach on one publicly available and one proprietary dataset.\",",
        "address": "\"Online\",",
        "author": "\"Srivastava, Saurabh  and Patidar, Mayur  and Chowdhury, Sudip  and Agarwal, Puneet  and Bhattacharya, Indrajit  and Shroff, Gautam\",",
        "booktitle": "\"Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume\",",
        "keywords": "Main topic:NLP,   Experiments data:real , QA",
        "month": "apr,",
        "pages": "\"3428--3439\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"Complex Question Answering on knowledge graphs using machine translation and multi-task learning\",",
        "type": "inproceedings",
        "url": "\"https://www.aclweb.org/anthology/2021.eacl-main.300\",",
        "year": "\"2021\","
    },
    "stanley2002evolving": {
        "author": "Stanley, Kenneth O and Miikkulainen, Risto",
        "journal": "Evolutionary computation",
        "keywords": "Main topic:AutoML, AI, Augmentation",
        "number": "2",
        "pages": "99--127",
        "publisher": "MIT Press",
        "title": "Evolving neural networks through augmenting topologies",
        "type": "Article",
        "volume": "10",
        "year": "2002"
    },
    "stanley2009hypercube": {
        "author": "Stanley, Kenneth O and D'Ambrosio, David B and Gauci, Jason",
        "journal": "Artificial life",
        "keywords": "Main topic:AutoML, AI",
        "number": "2",
        "pages": "185--212",
        "publisher": "MIT Press",
        "title": "A hypercube-based encoding for evolving large-scale neural networks",
        "type": "Article",
        "volume": "15",
        "year": "2009"
    },
    "stanley2019designing": {
        "author": "Stanley, Kenneth O and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto",
        "journal": "Nature Machine Intelligence",
        "keywords": "Main topic:AutoML, AI",
        "number": "1",
        "pages": "24--35",
        "publisher": "Nature Publishing Group",
        "title": "Designing neural networks through neuroevolution",
        "type": "Article",
        "volume": "1",
        "year": "2019"
    },
    "stepin2020generation": {
        "abstract": "Data-driven classification algorithms have proven highly effective in a range of complex tasks. However, their output is sometimes questioned, as the reasoning behind it may remain unclear due to a high number of poorly interpretable parameters used during training. Evidence-based (factual) explanations for single classifications answer the question why a particular class is selected in terms of the given observations. On the contrary, counterfactual explanations pay attention to why the rest of classes are not selected. Accordingly, we hypothesize that providing classifiers with a combination of both factual and counterfactual explanations is likely to make them more trustworthy. In order to investigate how such explanations can be produced, we introduce a new method to generate factual and counterfactual explanations for the output of pretrained decision trees and fuzzy rule-based classifiers. Experimental results show that unification of factual and counterfactual explanations under the paradigm of fuzzy inference systems proves promising for explaining the reasoning of classification algorithms.",
        "author": "Stepin, Ilia and Alonso, Jose M and Gatala, Alejandro and Pereira-Fari{\\~n}a, Martin",
        "booktitle": "2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)",
        "keywords": "Main topic:XAI, AI",
        "organization": "IEEE",
        "pages": "1--8",
        "title": "Generation and Evaluation of Factual and Gounterfaetual Explanations for Decision Trees and Fuzzy Rule-based Classifiers",
        "type": "inproceedings",
        "year": "2020"
    },
    "su2021deep": {
        "author": "Su, Zhou and Hui, Yilong and Luan, Tom H and Liu, Qiaorong and Xing, Rui",
        "booktitle": "The Next Generation Vehicular Networks, Modeling, Algorithm and Applications",
        "pages": "131--150",
        "publisher": "Springer",
        "title": "Deep Learning Based Autonomous Driving in Vehicular Networks",
        "type": "incollection",
        "year": "2021"
    },
    "suganuma2017genetic": {
        "author": "Suganuma, Masanori and Shirakawa, Shinichi and Nagao, Tomoharu",
        "booktitle": "Proceedings of the genetic and evolutionary computation conference",
        "keywords": "Main topic:AutoML, AI",
        "pages": "497--504",
        "title": "A genetic programming approach to designing convolutional neural network architectures",
        "type": "InProceedings",
        "year": "2017"
    },
    "sun2002n1": {
        "note": "\"White paper\"",
        "title": "\"Sun Microsystems N1\u2014Introducing just-in-time computing\",",
        "type": "article",
        "year": "\"2002\","
    },
    "sutskever2014sequence": {
        "author": "Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V",
        "journal": "Advances in neural information processing systems",
        "keywords": "Main topic:AutoML, AI",
        "pages": "3104--3112",
        "title": "Sequence to sequence learning with neural networks",
        "type": "Article",
        "volume": "27",
        "year": "2014"
    },
    "tang2020multi": {
        "abstract": "Multi-hop question answering (QA) requires a model to retrieve and integrate information from different parts of a long text to answer a question. Humans answer this kind of complex questions via a divide-and-conquer approach. In this paper, we investigate whether top-performing models for multi-hop questions understand the underlying sub-questions like humans. We adopt a neural decomposition model to generate sub-questions for a multi-hop complex question, followed by extracting the corresponding sub-answers. We show that multiple state-of-the-art multi-hop QA models fail to correctly answer a large portion of sub-questions, although their corresponding multi-hop questions are correctly answered. This indicates that these models manage to answer the multi-hop questions using some partial clues, instead of truly understanding the reasoning paths. We also propose a new model which significantly improves the performance on answering the sub-questions. Our work takes a step forward towards building a more explainable multi-hop QA system.",
        "author": "Tang, Yixuan and Tou Ng, Hwee and Tung, Anthony KH",
        "journal": "arXiv",
        "keywords": "Main topic:NLP, Experiments data:real , QA, AI",
        "pages": "arXiv--2002",
        "title": "Do Multi-Hop Question Answering Systems Know How to Answer the Single-Hop Sub-Questions?",
        "type": "article",
        "year": "2020"
    },
    "tang2020overview": {
        "author": "Tang, Yang and Zhao, Chaoqiang and Wang, Jianrui and Zhang, Chongzhen and Sun, Qiyu and Zheng, Weixing and Du, Wenli and Qian, Feng and Kurths, Juergen",
        "journal": "arXiv preprint arXiv:2001.02319",
        "title": "An overview of perception and decision-making in autonomous systems in the era of learning",
        "type": "article",
        "year": "2020"
    },
    "tang2021grounded": {
        "abstract": "Explainability is essential for autonomous vehicles and other robotics systems interacting with humans and other objects during operation. Humans need to understand and anticipate the actions taken by the machines for trustful and safe cooperation. In this work, we aim to enable the explainability of an autonomous driving system at the design stage by incorporating expert domain knowledge into the model. We propose Grounded Relational Inference (GRI). It models an interactive system's underlying dynamics by inferring an interaction graph representing the agents' relations. We ensure an interpretable interaction graph by grounding the relational latent space into semantic behaviors defined with expert domain knowledge. We demonstrate that it can model interactive traffic scenarios under both simulation and real-world settings, and generate interpretable graphs explaining the vehicle's behavior by their interactions.",
        "author": "Tang, Chen and Srishankar, Nishan and Martin, Sujitha and Tomizuka, Masayoshi",
        "journal": "arXiv preprint arXiv:2102.11905",
        "keywords": "Main topic:XAI, AI",
        "title": "Grounded Relational Inference: Domain Knowledge Driven Explainable Autonomous Driving",
        "type": "article",
        "year": "2021"
    },
    "thakker2020explainable": {
        "abstract": "Traditional Artificial Intelligence (AI) technologies used in developing smart cities solutions, Machine Learning (ML) and recently Deep Learning (DL), rely more on utilising best representative training datasets and features engineering and less on the available domain expertise. We argue that such an approach to solution development makes the outcome of solutions less explainable, i.e., it is often not possible to explain the results of the model. There is a growing concern among policymakers in cities with this lack of explainability of AI solutions, and this is considered a major hindrance in the wider acceptability and trust in such AI-based solutions. In this work, we survey the concept of \u2018explainable deep learning\u2019 as a subset of the \u2018explainable AI\u2019 problem and propose a new solution using Semantic Web technologies, demonstrated with a smart cities flood monitoring application in the context of a European Commission-funded project. Monitoring of gullies and drainage in crucial geographical areas susceptible to flooding issues is an important aspect of any flood monitoring solution. Typical solutions for this problem involve the use of cameras to capture images showing the affected areas in real-time with different objects such as leaves, plastic bottles etc., and building a DL-based classifier to detect such objects and classify blockages based on the presence and coverage of these objects in the images. In this work, we uniquely propose an Explainable AI solution using DL and Semantic Web technologies to build a hybrid classifier. In this hybrid classifier, the DL component detects object presence and coverage level and semantic rules designed with close consultation with experts carry out the classification. By using the expert knowledge in the flooding context, our hybrid classifier provides the flexibility on categorising the image using objects and their coverage relationships. The experimental results demonstrated with a real-world use case showed that this hybrid approach of image classification has on average 11\\% improvement (F-Measure) in image classification performance compared to DL-only classifier. It also has the distinct advantage of integrating experts\u2019 knowledge on defining the decision-making rules to represent the complex circumstances and using such knowledge to explain the results.",
        "author": "Thakker, Dhavalkumar and Mishra, Bhupesh Kumar and Abdullatif, Amr and Mazumdar, Suvodeep and Simpson, Sydney",
        "journal": "Smart Cities",
        "keywords": "Main topic:XAI",
        "number": "4",
        "pages": "1353--1382",
        "publisher": "Multidisciplinary Digital Publishing Institute",
        "title": "Explainable Artificial Intelligence for Developing Smart Cities Solutions",
        "type": "article",
        "volume": "3",
        "year": "2020"
    },
    "thrun2006stanley": {
        "author": "Thrun, Sebastian and Montemerlo, Mike and Dahlkamp, Hendrik and Stavens, David and Aron, Andrei and Diebel, James and Fong, Philip and Gale, John and Halpenny, Morgan and Hoffmann, Gabriel and others",
        "journal": "Journal of field Robotics",
        "number": "9",
        "pages": "661--692",
        "publisher": "Wiley Online Library",
        "title": "Stanley: The robot that won the DARPA Grand Challenge",
        "type": "article",
        "volume": "23",
        "year": "2006"
    },
    "tianfield2003multi": {
        "author": "Tianfield, Huaglory",
        "booktitle": "IEEE International Conference on Industrial Informatics, 2003. INDIN 2003. Proceedings.",
        "organization": "IEEE",
        "pages": "462--469",
        "title": "Multi-agent based autonomic architecture for network management",
        "type": "inproceedings",
        "year": "2003"
    },
    "tsugawa2016review": {
        "author": "Tsugawa, Sadayuki and Jeschke, Sabina and Shladover, Steven E Khalifa, Ahmed and Kermorgant, Olivier and Dominguez, Salvador and Martinet, Philippe",
        "journal": "IEEE Transactions on Intelligent Vehicles IEEE Transactions on Intelligent Transportation Systems",
        "number": "1",
        "pages": "68--77",
        "publisher": "IEEE @article{khalifa2020platooning, IEEE",
        "title": "A review of truck platooning projects for energy savings Platooning of Car-like Vehicles in Urban Environments: An Observer-based Approach Considering Actuator Dynamics and Time delays",
        "type": "article",
        "volume": "1",
        "year": "2016 2020"
    },
    "tulli2020explainability": {
        "abstract": "The research presented herein addresses the topic of explainability in autonomous pedagogical agents. We will be investigating possible ways to explain the decision-making process of such pedagogical agents (which can be embodied as robots) with a focus on the effect of these explanations in concrete learning scenarios for children. The hypothesis is that the agents' explanations about their decision making will support mutual modeling and a better understanding of the learning tasks and how learners perceive them. The objective is to develop a computational model that will allow agents to express internal states and actions and adapt to the human expectations of cooperative behavior accordingly. In addition, we would like to provide a comprehensive taxonomy of both the desiderata and methods in the explainable AI research applied to children's learning scenarios.",
        "author": "Tulli, Silvia",
        "booktitle": "Proceedings of the AAAI Conference on Artificial Intelligence",
        "keywords": "Main topic:XAI, AI",
        "number": "10",
        "pages": "13738--13739",
        "title": "Explainability in Autonomous Pedagogical Agents",
        "type": "inproceedings",
        "volume": "34",
        "year": "2020"
    },
    "van2018robotic": {
        "author": "Van der Aalst, Wil MP and Bichler, Martin and Heinzl, Armin",
        "keywords": " Main topic:NLP, concentration:perception , application:Robotic Process Automation (RPA),  AI",
        "publisher": "Springer",
        "title": "Robotic process automation",
        "type": "misc",
        "year": "2018"
    },
    "vilone2020explainable": {
        "abstract": "Explainable Artificial Intelligence (XAI) has experienced a significant growth over the last few years. This is due to the widespread application of machine learning, particularly deep learning, that has led to the development of highly accurate models but lack explainability and interpretability. A plethora of methods to tackle this problem have been proposed, developed and tested. This systematic review contributes to the body of knowledge by clustering these methods with a hierarchical classification system with four main clusters: review articles, theories and notions, methods and their evaluation. It also summarises the state-of-the-art in XAI and recommends future research directions.",
        "author": "Vilone, Giulia and Longo, Luca",
        "journal": "arXiv preprint arXiv:2006.00093",
        "keywords": "Main topic:XAI, AI",
        "title": "Explainable artificial intelligence: a systematic review",
        "type": "article",
        "year": "2020"
    },
    "wachter2017counterfactual": {
        "abstract": "There has been much discussion of the right to explanation in the EU General Data Protection Regulation, and its existence, merits, and disadvantages. Implementing a right to explanation that opens the black box of algorithmic decision-making faces major legal and technical barriers. Explaining the functionality of complex algorithmic decision-making systems and their rationale in specific cases is a technically challenging problem. Some explanations may offer little meaningful information to data subjects, raising questions around their value. Explanations of automated decisions need not hinge on the general public understanding how algorithmic systems function. Even though such interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the black box. Looking at explanations as a means to help a data subject act rather than merely understand, one could gauge the scope and content of explanations according to the specific goal or action they are intended to support. From the perspective of individuals affected by automated decision-making, we propose three aims for explanations: (1) to inform and help the individual understand why a particular decision was reached, (2) to provide grounds to contest the decision if the outcome is undesired, and (3) to understand what would need to change in order to receive a desired result in the future, based on the current decision-making model. We assess how each of these goals finds support in the GDPR. We suggest data controllers should offer a particular type of explanation, unconditional counterfactual explanations, to support these three aims. These counterfactual explanations describe the smallest change to the world that can be made to obtain a desirable outcome, or to arrive at the closest possible world, without needing to explain the internal logic of the system.",
        "author": "Wachter, Sandra and Mittelstadt, Brent and Russell, Chris",
        "journal": "Harv. JL \\& Tech.",
        "keywords": "Main topic:XAI, AI",
        "pages": "841",
        "publisher": "HeinOnline",
        "title": "Counterfactual explanations without opening the black box: Automated decisions and the GDPR",
        "type": "article",
        "volume": "31",
        "year": "2017"
    },
    "wan2020cognitive": {
        "author": "Wan, Shaohua and Gu, Zonghua and Ni, Qiang",
        "journal": "Computer Communications",
        "pages": "99--106",
        "publisher": "Elsevier",
        "title": "Cognitive computing and wireless communications on the edge for healthcare service robots",
        "type": "article",
        "volume": "149",
        "year": "2020"
    },
    "wang2003multiscale": {
        "author": "Wang, Zhou and Simoncelli, Eero P and Bovik, Alan C",
        "booktitle": "The Thrity-Seventh Asilomar Conference on Signals, Systems \\& Computers, 2003",
        "organization": "Ieee",
        "pages": "1398--1402",
        "title": "Multiscale structural similarity for image quality assessment",
        "type": "inproceedings",
        "volume": "2",
        "year": "2003"
    },
    "wang2018evidence": {
        "abstract": "A popular recent approach to answering open-domain questions is to first search for question-related passages and then apply reading comprehension models to extract answers. Existing methods usually extract answers from single passages independently. But some questions require a combination of evidence from across different sources to answer correctly. In this paper, we propose two models which make use of multiple passages to generate their answers. Both use an answer-reranking approach which reorders the answer candidates generated by an existing state-of-the-art QA model. We propose two methods, namely, strength-based re-ranking and coverage-based re-ranking, to make use of the aggregated evidence from different passages to better determine the answer. Our models have achieved state-of-the-art results on three public open-domain QA datasets: Quasar-T, SearchQA and the open-domain version of TriviaQA, with about 8 percentage points of improvement over the former two datasets.",
        "author": "Wang, Shuohang and Yu, Mo and Jiang, Jing and Zhang, Wei and Guo, Xiaoxiao and Chang, Shiyu and Wang, Zhiguo and Klinger, Tim and Tesauro, Gerald and Campbell, Murray",
        "booktitle": "International Conference on Learning Representations",
        "keywords": "Main topic:NLP,   Experiments data:real , multi-hop, QA, AI",
        "title": "Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering",
        "type": "inproceedings",
        "year": "2018"
    },
    "wang2019autonomous": {
        "author": "Wang, Yingxu and Plataniotis, Konstantinos N and Kwong, Sam and Leung, Henry and Yanushkevich, Svetlana and Karray, Fakhri and Hou, Ming and Howard, Newton and Fiorini, Rodolfo A and Soda, Paolo and others Zhang, Chongzhen and Wang, Jianrui and Yen, Gary G and Zhao, Chaoqiang and Sun, Qiyu and Tang, Yang and Qian, Feng and Kurths, J{\\\"u}rgen",
        "booktitle": "2019 IEEE 18th International Conference on Cognitive Informatics \\& Cognitive Computing (ICCI* CC)",
        "journal": "Patterns",
        "number": "4",
        "organization": "IEEE @article{zhang2020autonomous,",
        "pages": "7--12 100050",
        "publisher": "Elsevier",
        "title": "On autonomous systems: from reflexive, imperative and adaptive intelligence to autonomous and cognitive intelligence When Autonomous Systems Meet Accuracy and Transferability through AI: A Survey",
        "type": "inproceedings",
        "volume": "1",
        "year": "2019 2020"
    },
    "wang2019incremental": {
        "abstract": "Clarifying user needs is essential for existing task-oriented dialogue systems. However, in real-world applications, developers can never guarantee that all possible user demands are taken into account in the design phase. Consequently, existing systems will break down when encountering unconsidered user needs. To address this problem, we propose a novel incremental learning framework to design task-oriented dialogue systems, or for short Incremental Dialogue System (IDS), without pre-defining the exhaustive list of user needs. Specifically, we introduce an uncertainty estimation module to evaluate the confidence of giving correct responses. If there is high confidence, IDS will provide responses to users. Otherwise, humans will be involved in the dialogue process, and IDS can learn from human intervention through an online learning module. To evaluate our method, we propose a new dataset which simulates unanticipated user needs in the deployment stage. Experiments show that IDS is robust to unconsidered user actions, and can update itself online by smartly selecting only the most effective training data, and hence attains better performance with less annotation cost.",
        "author": "Wang, Weikang and Zhang, Jiajun and Li, Qian and Hwang, Mei-Yuh and Zong, Chengqing and Li, Zhifei",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP, dialogue-systems,  AI",
        "pages": "3710--3720",
        "title": "Incremental Learning from Scratch for Task-Oriented Dialogue Systems",
        "type": "inproceedings",
        "year": "2019"
    },
    "wang2019multi": {
        "abstract": " BERT model has been successfully applied to open-domain QA tasks. However, previous work trains BERT by viewing passages corresponding to the same question as independent training instances, which may cause incomparable scores for answers from different passages. To tackle this issue, we propose a multi-passage BERT model to globally normalize answer scores across all passages of the same question, and this change enables our QA model find better answers by utilizing more passages. In addition, we find that splitting articles into passages with the length of 100 words by sliding window improves performance by 4\\%. By leveraging a passage ranker to select high-quality passages, multi-passage BERT gains additional 2\\%. Experiments on four standard benchmarks showed that our multi-passage BERT outperforms all state-of-the-art models on all benchmarks. In particular, on the OpenSQuAD dataset, our model gains 21.4\\% EM and 21.5\\% F1 over all non-BERT models, and 5.8\\% EM and 6.5\\% F1 over BERT-based models.",
        "author": "Wang, Zhiguo and Ng, Patrick and Ma, Xiaofei and Nallapati, Ramesh and Xiang, Bing",
        "booktitle": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
        "keywords": "Main topic:NLP,  Experiments data:real ,  QA, AI",
        "pages": "5881--5885",
        "title": "Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering",
        "type": "inproceedings",
        "year": "2019"
    },
    "wang2020autonomous": {
        "author": "Wang, Tengfei and Wu, Qing and Zhang, Jinfen and Wu, Bing and Wang, Yang",
        "journal": "Ocean Engineering",
        "pages": "106873",
        "publisher": "Elsevier",
        "title": "Autonomous decision-making scheme for multi-ship collision avoidance with iterative observation and inference",
        "type": "article",
        "volume": "197",
        "year": "2020"
    },
    "wang2020autorec": {
        "abstract": "Realistic recommender systems are often required to adapt to ever-changing data and tasks or to explore different models systematically. To address the need, we present AutoRec, an open-source automated machine learning (AutoML) platform extended from the TensorFlow ecosystem and, to our knowledge, the first framework to leverage AutoML for model search and hyperparameter tuning in deep recommendation models. AutoRec also supports a highly flexible pipeline that accommodates both sparse and dense inputs, rating prediction and click-through rate (CTR) prediction tasks, and an array of recommendation models. Lastly, AutoRec provides a simple, user-friendly API. Experiments conducted on the benchmark datasets reveal AutoRec is reliable and can identify models which resemble the best model without prior knowledge.",
        "archiveprefix": "arXiv",
        "author": "Ting-Hsiang Wang and Qingquan Song and Xiaotian Han and Zirui Liu and Haifeng Jin and Xia Hu",
        "eprint": "2007.07224",
        "keywords": "Main topic:AutoML, AI , recommender system",
        "primaryclass": "cs.IR",
        "title": "AutoRec: An Automated Recommender System",
        "type": "Misc",
        "year": "2020"
    },
    "wang2020deceiving": {
        "author": "Wang, Lin and Cho, Wonjune and Yoon, Kuk-Jin",
        "journal": "IEEE Robotics and Automation Letters",
        "number": "2",
        "pages": "1421--1428",
        "publisher": "IEEE",
        "title": "Deceiving image-to-image translation networks for autonomous driving with adversarial perturbations",
        "type": "article",
        "volume": "5",
        "year": "2020"
    },
    "wang2020improving": {
        "author": "Wang, Eason and Cui, Henggang and Yalamanchi, Sai and Moorthy, Mohana and Djuric, Nemanja",
        "booktitle": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining",
        "pages": "2340--2348",
        "title": "Improving Movement Predictions of Traffic Actors in Bird's-Eye View Models using GANs and Differentiable Trajectory Rasterization",
        "type": "inproceedings",
        "year": "2020"
    },
    "wang2021retrieval": {
        "abstract": "Question answering over knowledge bases (KBQA) usually involves three sub-tasks, namely topic entity detection, entity linking and relation detection. Due to the large number of entities and relations inside knowledge bases (KB), previous work usually utilized sophisticated rules to narrow down the search space and managed only a subset of KBs in memory. In this work, we leverage a retrieve-and-rerank framework to access KBs via traditional information retrieval (IR) method, and re-rank retrieved candidates with more powerful neural networks such as the pre-trained BERT model. Considering the fact that directly assigning a different BERT model for each sub-task may incur prohibitive costs, we propose to share a BERT encoder across all three sub-tasks and define task-specific layers on top of the shared layer. The unified model is then trained under a multi-task learning framework. Experiments show that: (1) Our IR-based retrieval method is able to collect high-quality candidates efficiently, thus enables our method adapt to large-scale KBs easily; (2) the BERT model improves the accuracy across all three sub-tasks; and (3) benefiting from multi-task learning, the unified model obtains further improvements with only 1/3 of the original parameters. Our final model achieves competitive results on the SimpleQuestions dataset and superior performance on the FreebaseQA dataset.",
        "author": "Wang, Zhiguo and Ng, Patrick and Nallapati, Ramesh and Xiang, Bing",
        "booktitle": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
        "keywords": "Main topic:NLP,  Experiments data:real ,  QA, KB",
        "pages": "347--357",
        "title": "Retrieval, Re-ranking and Multi-task Learning for Knowledge-Base Question Answering",
        "type": "inproceedings",
        "year": "2021"
    },
    "wei2016network": {
        "author": "Wei, Tao and Wang, Changhu and Rui, Yong and Chen, Chang Wen",
        "booktitle": "International Conference on Machine Learning (ICML) 2016",
        "keywords": "Main topic:AutoML, AI",
        "organization": "PMLR",
        "pages": "564--572",
        "title": "Network morphism",
        "type": "InProceedings",
        "year": "2016"
    },
    "wei2019generalized": {
        "abstract": "This paper considers generalized linear models using rule-based features, also referred to as rule ensembles, for regression and probabilistic classification. Rules facilitate model interpretation while also capturing nonlinear dependences and interactions. Our problem formulation accordingly trades off rule set complexity and prediction accuracy. Column generation is used to optimize over an exponentially large space of rules without pre-generating a large subset of candidates or greedily boosting rules one by one. The column generation subproblem is solved using either integer programming or a heuristic optimizing the same objective. In experiments involving logistic and linear regression, the proposed methods obtain better accuracy-complexity trade-offs than existing rule ensemble algorithms. At one end of the trade-off, the methods are competitive with less interpretable benchmark models.",
        "author": "Wei, Dennis and Dash, Sanjeeb and Gao, Tian and Gunluk, Oktay",
        "booktitle": "International Conference on Machine Learning",
        "keywords": "Main topic:XAI, AI",
        "organization": "PMLR",
        "pages": "6687--6696",
        "title": "Generalized linear rule models",
        "type": "inproceedings",
        "year": "2019"
    },
    "weidele2019deepling": {
        "abstract": "We demonstrate an interactive visualization system to promote interpretability of convolutional neural networks (CNNs). Interpretation of deep learning models acts on the interface between increasingly complex model architectures and model architects, to provide an understanding of how a model operates, where it fails, or why it succeeds. Based on preliminary expert interviews and a careful literature review we design the system to comprehensively support architects on 4 visual dimensions.",
        "author": "Weidele, Daniel and Strobelt, Hendrik and Martino, Mauro",
        "journal": "Proceedings SysML",
        "keywords": "Main topic:XAI, AI",
        "title": "Deepling: Avisual interpretability system for convolutional neural networks",
        "type": "article",
        "year": "2019"
    },
    "welbl2018constructing": {
        "abstract": "Most Reading Comprehension methods limit themselves to queries which can be answered using a single sentence, paragraph, or document. Enabling models to combine disjoint pieces of textual evidence would extend the scope of machine comprehension methods, but currently no resources exist to train and test this capability. We propose a novel task to encourage the development of models for text understanding across multiple documents and to investigate the limits of existing methods. In our task, a model learns to seek and combine evidence \u2014 effectively performing multihop, alias multi-step, inference. We devise a methodology to produce datasets for this task, given a collection of query-answer pairs and thematically linked documents. Two datasets from different domains are induced, and we identify potential pitfalls and devise circumvention strategies. We evaluate two previously proposed competitive models and find that one can integrate information across documents. However, both models struggle to select relevant information; and providing documents guaranteed to be relevant greatly improves their performance. While the models outperform several strong baselines, their best accuracy reaches 54.5\\% on an annotated test set, compared to human performance at 85.0\\%, leaving ample room for improvement.",
        "author": "Welbl, Johannes and Stenetorp, Pontus and Riedel, Sebastian",
        "journal": "Transactions of the Association for Computational Linguistics",
        "keywords": "Multi-hop,  Main topic:NLP,Experiments data:real ,  QA, dataset, AI",
        "pages": "287--302",
        "publisher": "MIT Press",
        "title": "Constructing datasets for multi-hop reading comprehension across documents",
        "type": "article",
        "volume": "6",
        "year": "2018"
    },
    "welleck2019dialogue": {
        "abstract": "Consistency is a long standing issue faced by dialogue models. In this paper, we frame the consistency of dialogue agents as natural language inference (NLI) and create a new natural language inference dataset called Dialogue NLI. We propose a method which demonstrates that a model trained on Dialogue NLI can be used to improve the consistency of a dialogue model, and evaluate the method with human evaluation and with automatic metrics on a suite of evaluation sets designed to measure a dialogue model's consistency.",
        "author": "Welleck, Sean and Weston, Jason and Szlam, Arthur and Cho, Kyunghyun",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP, dialogue-systems,  AI",
        "pages": "3731--3741",
        "title": "Dialogue Natural Language Inference",
        "type": "inproceedings",
        "year": "2019"
    },
    "white2019measurable": {
        "abstract": "We propose a novel method for explaining the predictions of any classifier. In our approach, local explanations are expected to explain both the outcome of a prediction and how that prediction would change if 'things had been different'. Furthermore, we argue that satisfactory explanations cannot be dissociated from a notion and measure of fidelity, as advocated in the early days of neural networks' knowledge extraction. We introduce a definition of fidelity to the underlying classifier for local explanation models which is based on distances to a target decision boundary. A system called CLEAR: Counterfactual Local Explanations via Regression, is introduced and evaluated. CLEAR generates w-counterfactual explanations that state minimum changes necessary to flip a prediction's classification. CLEAR then builds local regression models, using the w-counterfactuals to measure and improve the fidelity of its regressions. By contrast, the popular LIME method, which also uses regression to generate local explanations, neither measures its own fidelity nor generates counterfactuals. CLEAR's regressions are found to have significantly higher fidelity than LIME's, averaging over 45\\% higher in this paper's four case studies.",
        "author": "White, Adam and Garcez, Artur d'Avila",
        "journal": "arXiv preprint arXiv:1908.03020",
        "keywords": "Main topic:XAI, AI",
        "title": "Measurable counterfactual local explanations for any classifier",
        "type": "article",
        "year": "2019"
    },
    "wintersberger2020explainable": {
        "abstract": "Recent research indicates that transparent information on the behavior of automated vehicles positively affects trust, but how such feedback should be composed and if user trust influences the amount of desired feedback is relatively unexplored. Consequently, we conducted an interview study with (N",
        "author": "Wintersberger, Philipp and Nicklas, Hannah and Martlbauer, Thomas and Hammer, Stephan and Riener, Andreas",
        "booktitle": "12th International Conference on Automotive User Interfaces and Interactive Vehicular Applications",
        "keywords": "Main topic:XAI",
        "pages": "252--261",
        "title": "Explainable Automation: Personalized and Adaptive UIs to Foster Trust and Understanding of Driving Automation Systems",
        "type": "inproceedings",
        "year": "2020"
    },
    "wotawa2019reasoning": {
        "author": "Wotawa, Franz",
        "booktitle": "Predictive Maintenance in Dynamic Systems",
        "pages": "427--460",
        "publisher": "Springer",
        "title": "Reasoning from first principles for self-adaptive and autonomous systems",
        "type": "incollection",
        "year": "2019"
    },
    "wu2019self": {
        "abstract": "The sequential order of utterances is often meaningful in coherent dialogues, and the order changes of utterances could lead to low-quality and incoherent conversations. We consider the order information as a crucial supervised signal for dialogue learning, which, however, has been neglected by many previous dialogue systems. Therefore, in this paper, we introduce a self-supervised learning task, inconsistent order detection, to explicitly capture the flow of conversation in dialogues. Given a sampled utterance pair triple, the task is to predict whether it is ordered or misordered. Then we propose a sampling-based self-supervised network SSN to perform the prediction with sampled triple references from previous dialogue history. Furthermore, we design a joint learning framework where SSN can guide the dialogue systems towards more coherent and relevant dialogue learning through adversarial training. We demonstrate that the proposed methods can be applied to both open-domain and task-oriented dialogue scenarios, and achieve the new state-of-the-art performance on the OpenSubtitiles and Movie-Ticket Booking datasets.",
        "author": "Wu, Jiawei and Wang, Xin and Wang, William Yang",
        "booktitle": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
        "keywords": "Main topic:NLP, Experiments data:real , dialogue-systems,  AI",
        "pages": "3857--3867",
        "title": "Self-Supervised Dialogue Learning",
        "type": "inproceedings",
        "year": "2019"
    },
    "xiao2019dynamically": {
        "abstract": "Text-based question answering (TBQA) has been studied extensively in recent years. Most existing approaches focus on finding the answer to a question within a single paragraph. However, many difficult questions require multiple supporting evidence from scattered text among two or more documents. In this paper, we propose Dynamically Fused Graph Network(DFGN), a novel method to answer those questions requiring multiple scattered evidence and reasoning over them. Inspired by human's step-by-step reasoning behavior, DFGN includes a dynamic fusion layer that starts from the entities mentioned in the given query, explores along the entity graph dynamically built from the text, and gradually finds relevant supporting entities from the given documents. We evaluate DFGN on HotpotQA, a public TBQA dataset requiring multi-hop reasoning. DFGN achieves competitive results on the public board. Furthermore, our analysis shows DFGN produces interpretable reasoning chains.",
        "author": "Xiao, Yunxuan and Qu, Yanru and Qiu, Lin and Zhou, Hao and Li, Lei and Zhang, Weinan and Yu, Yong",
        "journal": "arXiv preprint arXiv:1905.06933",
        "keywords": " Main topic:NLP, Experiments data:real , QA, AI",
        "title": "Dynamically Fused Graph Network for Multi-hop Reasoning",
        "type": "article",
        "year": "2019"
    },
    "xie2017genetic": {
        "author": "Xie, Lingxi and Yuille, Alan",
        "booktitle": "Proceedings of the IEEE international conference on computer vision",
        "keywords": "Main topic:AutoML, AI",
        "pages": "1379--1388",
        "title": "Genetic cnn",
        "type": "InProceedings",
        "year": "2017"
    },
    "xiong2020answering": {
        "abstract": "We propose a simple and efficient multi-hop dense retrieval approach for answering complex open-domain questions, which achieves state-of-the-art performance on two multi-hop datasets, HotpotQA and multi-evidence FEVER. Contrary to previous work, our method does not require access to any corpus-specific information, such as inter-document hyperlinks or human-annotated entity markers, and can be applied to any unstructured text corpus. Our system also yields a much better efficiency-accuracy trade-off, matching the best published accuracy on HotpotQA while being 10 times faster at inference time.",
        "author": "Xiong, Wenhan and Li, Xiang Lorraine and Iyer, Srini and Du, Jingfei and Lewis, Patrick and Wang, William Yang and Mehdad, Yashar and Yih, Wen-tau and Riedel, Sebastian and Kiela, Douwe and others",
        "journal": "arXiv preprint arXiv:2009.12756",
        "keywords": "multi-hop,  Experiments data:real , Main topic:NLP, QA, AI",
        "title": "Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval",
        "type": "article",
        "year": "2020"
    },
    "xiong2020progressively": {
        "abstract": " To extract answers from a large corpus, open-domain question answering (QA) systems usually rely on information retrieval (IR) techniques to narrow the search space. Standard inverted index methods such as TF-IDF are commonly used as thanks to their efficiency. However, their retrieval performance is limited as they simply use shallow and sparse lexical features. To break the IR bottleneck, recent studies show that stronger retrieval performance can be achieved by pretraining a effective paragraph encoder that index paragraphs into dense vectors. Once trained, the corpus can be pre-encoded into low-dimensional vectors and stored within an index structure where the retrieval can be efficiently implemented as maximum inner product search. Despite the promising results, pretraining such a dense index is expensive and often requires a very large batch size. In this work, we propose a simple and resource-efficient method to pretrain the paragraph encoder. First, instead of using heuristically created pseudo question-paragraph pairs for pretraining, we utilize an existing pretrained sequence-to-sequence model to build a strong question generator that creates high-quality pretraining data. Second, we propose a progressive pretraining algorithm to ensure the existence of effective negative samples in each batch. Across three datasets, our method outperforms an existing dense retrieval method that uses 7 times more computational resources for pretraining.",
        "author": "Xiong, Wenhan and Wang, Hong and Wang, William Yang",
        "journal": "arXiv preprint arXiv:2005.00038",
        "keywords": "Main topic:NLP,   Experiments data:real , TQA",
        "title": "Progressively pretrained dense corpus index for open-domain question answering",
        "type": "article",
        "year": "2020"
    },
    "xu2019pc": {
        "author": "Xu, Yuhui and Xie, Lingxi and Zhang, Xiaopeng and Chen, Xin and Qi, Guo-Jun and Tian, Qi and Xiong, Hongkai",
        "journal": "arXiv preprint arXiv:1907.05737",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "PC-DARTS: Partial channel connections for memory-efficient architecture search",
        "type": "Article",
        "year": "2019"
    },
    "yadati2021knowledge": {
        "abstract": "Knowledge Base Question Answering (KBQA) is the problem of predicting an answer for a factoid question over a given knowledge base (KB). Answering questions typically requires reasoning over multiple links in the given KB. Humans tend to answer questions by grouping different objects to perform reasoning over acquired knowledge. Hypergraphs provide a natural tool to model group relationships. In this work, inspired by typical human intelligence, we propose a new method for KBQA based on hypergraphs. Existing methods for KBQA, though effective, do not explicitly incorporate the recursive relational group structure in the given KB. Our method, which we name RecHyperNet (Recursive Hypergraph Network), exploits a new way of modelling KBs through recursive hypergraphs to organise such group relationships in KBs. Experiments on multiple KBQA benchmarks demonstrate the effectiveness of the proposed RecHyperNet. We have released the code.",
        "author": "Yadati, Naganand and Dayanidhi, RS and Vaishnavi, S and Indira, KM and Srinidhi, G",
        "booktitle": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
        "keywords": "Main topic:NLP,   Experiments data:real ,  QA, KB",
        "pages": "448--454",
        "title": "Knowledge Base Question Answering through Recursive Hypergraphs",
        "type": "inproceedings",
        "year": "2021"
    },
    "yang2018hotpotqa": {
        "abstract": "Existing question answering (QA) datasets fail to train QA systems to perform complex reasoning and provide explanations for answers. We introduce HotpotQA, a new dataset with 113k Wikipedia-based question-answer pairs with four key features: (1) the questions require finding and reasoning over multiple supporting documents to answer; (2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas; (3) we provide sentence-level supporting facts required for reasoning, allowing QA systems to reason with strong supervision and explain the predictions; (4) we offer a new type of factoid comparison questions to test QA systems' ability to extract relevant facts and perform necessary comparison. We show that HotpotQA is challenging for the latest QA systems, and the supporting facts enable models to improve performance and make explainable predictions.",
        "author": "Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D",
        "journal": "arXiv preprint arXiv:1809.09600",
        "keywords": "Multi-hop,  Main topic:NLP, Experiments data:real , QA, dataset, AI",
        "title": "Hotpotqa: A dataset for diverse, explainable multi-hop question answering",
        "type": "article",
        "year": "2018"
    },
    "yang2019end": {
        "abstract": "We demonstrate an end-to-end question answering system that integrates BERT with the open-source Anserini information retrieval toolkit. In contrast to most question answering and reading comprehension models today, which operate over small amounts of input text, our system integrates best practices from IR with a BERT-based reader to identify answers from a large corpus of Wikipedia articles in an end-to-end fashion. We report large improvements over previous results on a standard benchmark test collection, showing that fine-tuning pretrained BERT with SQuAD is sufficient to achieve high accuracy in identifying answer spans.",
        "author": "Yang, Wei and Xie, Yuqing and Lin, Aileen and Li, Xingyu and Tan, Luchen and Xiong, Kun and Li, Ming and Lin, Jimmy",
        "booktitle": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)",
        "keywords": "Main topic:NLP,   Experiments data:real ,  QA, AI",
        "pages": "72--77",
        "title": "End-to-End Open-Domain Question Answering with BERTserini",
        "type": "inproceedings",
        "year": "2019"
    },
    "yang2020cars": {
        "author": "Yang, Zhaohui and Wang, Yunhe and Chen, Xinghao and Shi, Boxin and Xu, Chao and Xu, Chunjing and Tian, Qi and Xu, Chang",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "1829--1838",
        "title": "Cars: Continuous evolution for efficient neural architecture search",
        "type": "InProceedings",
        "year": "2020"
    },
    "zablocki2021explainability": {
        "abstract": "This survey reviews explainability methods for vision-based self-driving systems. The concept of explainability has several facets and the need for explainability is strong in driving, a safety-critical application. Gathering contributions from several research fields, namely computer vision, deep learning, autonomous driving, explainable AI (X-AI), this survey tackles several points. First, it discusses definitions, context, and motivation for gaining more interpretability and explainability from self-driving systems. Second, major recent state-of-the-art approaches to develop self-driving systems are quickly presented. Third, methods providing explanations to a black-box self-driving system in a post-hoc fashion are comprehensively organized and detailed. Fourth, approaches from the literature that aim at building more interpretable self-driving systems by design are presented and discussed in detail. Finally, remaining open-challenges and potential future research directions are identified and examined.",
        "archiveprefix": "arXiv",
        "author": "\u00c9loi Zablocki and H\u00e9di Ben-Younes and Patrick P\u00e9rez and Matthieu Cord",
        "eprint": "2101.05307",
        "keywords": "Main topic:XAI, AI",
        "title": "Explainability of vision-based autonomous driving systems: Review and challenges",
        "type": "misc",
        "year": "2021"
    },
    "zayats2021representations": {
        "absrtact": "Tables in Web documents are pervasive and can be directly used to answer many of the queries searched on the Web, motivating their integration in question answering. Very often information presented in tables is succinct and hard to interpret with standard language representations. On the other hand, tables often appear within textual context, such as an article describing the table. Using the information from an article as additional context can potentially enrich table representations. In this work we aim to improve question answering from tables by refining table representations based on information from surrounding text. We also present an effective method to combine text and table-based predictions for question answering from full documents, obtaining significant improvements on the Natural Questions dataset.",
        "author": "Zayats, Vicky and Toutanova, Kristina and Ostendorf, Mari",
        "booktitle": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
        "keywords": "Main topic:NLP,   Experiments data:real , QA",
        "pages": "2895--2906",
        "title": "Representations for Question Answering from Documents with Tables and Text",
        "type": "inproceedings",
        "year": "2021"
    },
    "zhang2018deeproad": {
        "author": "Zhang, Mengshi and Zhang, Yuqun and Zhang, Lingming and Liu, Cong and Khurshid, Sarfraz",
        "booktitle": "2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
        "organization": "IEEE",
        "pages": "132--142",
        "title": "DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems",
        "type": "inproceedings",
        "year": "2018"
    },
    "zhang2018graph": {
        "author": "Zhang, Chris and Ren, Mengye and Urtasun, Raquel",
        "journal": "ICLR",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "title": "Graph hypernetworks for neural architecture search",
        "type": "Article",
        "year": "2018"
    },
    "zhang2020overcoming": {
        "author": "Zhang, Miao and Li, Huiqi and Pan, Shirui and Chang, Xiaojun and Su, Steven",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "7809--7818",
        "title": "Overcoming multi-model forgetting in one-shot nas with diversity maximization",
        "type": "InProceedings",
        "year": "2020"
    },
    "zhao2020sparta": {
        "abstract": "We introduce SPARTA, a novel neural retrieval method that shows great promise in performance, generalization, and interpretability for open-domain question answering. Unlike many neural ranking methods that use dense vector nearest neighbor search, SPARTA learns a sparse representation that can be efficiently implemented as an Inverted Index. The resulting representation enables scalable neural retrieval that does not require expensive approximate vector search and leads to better performance than its dense counterpart. We validated our approaches on 4 open-domain question answering (OpenQA) tasks and 11 retrieval question answering (ReQA) tasks. SPARTA achieves new state-of-the-art results across a variety of open-domain question answering tasks in both English and Chinese datasets, including open SQuAD, Natuarl Question, CMRC and etc. Analysis also confirms that the proposed method creates human interpretable representation and allows flexible control over the trade-off between performance and efficiency.",
        "author": "Zhao, Tiancheng and Lu, Xiaopeng and Lee, Kyusong",
        "journal": "arXiv preprint arXiv:2009.13013",
        "keywords": "Main topic:NLP,  Experiments data:real ,  IR, QA, AI",
        "title": "Sparta: Efficient open-domain question answering via sparse transformer matching retrieval",
        "type": "article",
        "year": "2020"
    },
    "zhong2018practical": {
        "author": "Zhong, Zhao and Yan, Junjie and Wu, Wei and Shao, Jing and Liu, Cheng-Lin",
        "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
        "keywords": "Main topic:AutoML, AI",
        "pages": "2423--2432",
        "title": "Practical block-wise neural network architecture generation",
        "type": "InProceedings",
        "year": "2018"
    },
    "zhou2019bayesnas": {
        "author": "Zhou, Hongpeng and Yang, Minghao and Wang, Jun and Pan, Wei",
        "booktitle": "International Conference on Machine Learning",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "organization": "PMLR",
        "pages": "7603--7613",
        "title": "Bayesnas: A bayesian approach for neural architecture search",
        "type": "InProceedings",
        "year": "2019"
    },
    "zhu2019eena": {
        "author": "Zhu, Hui and An, Zhulin and Yang, Chuanguang and Xu, Kaiqiang and Zhao, Erhu and Xu, Yongjun",
        "booktitle": "Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops",
        "keywords": "Main topic:AutoML, AI, concentration :learning",
        "pages": "0--0",
        "title": "EENA: efficient evolution of neural architecture",
        "type": "InProceedings",
        "year": "2019"
    },
    "zoph2018learning": {
        "author": "Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V",
        "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
        "keywords": "Main topic:AutoML, AI, concentration :learning, image recognition",
        "pages": "8697--8710",
        "title": "Learning transferable architectures for scalable image recognition",
        "type": "InProceedings",
        "year": "2018"
    }
}});